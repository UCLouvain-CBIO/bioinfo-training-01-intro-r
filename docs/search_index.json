[["index.html", "Data manipulation and visualisation with R Preamble Training aims Pre-requisites Content Requirements Provisional timetable References and credits About this course material Citation License Setup", " Data manipulation and visualisation with R Laurent Gatto, Manon Martin &amp; Axelle Loriot 2021-09-23 Preamble Training aims Do you want to get started with reproducible data analysis with R, one of the most used software for the analysis of high throughput biology data? R is a free and open-source software. It is one of the most widely used in the bio-medical research field, likely due to the availability of numerous R/Bioconductor packages specifically dedicated to high throughput data. The goal of this training is to initiate wet-lab scientists to reproducible data analysis with R and its RStudio integrated environment, focusing on data manipulation, data visualisation and basic data analysis. Pre-requisites This training doesn’t require any previous knowledge of R. There are no programming or technical pre-requisities for this course, other than basic computer usage, such as general knowledge about files (binary and text files) and folders and as well as downloading files. Familiarity with a spreadsheet editor is helpful for the first chapter. Content Discovering R, and the RStudio environment Importance of tidy data in general and how it translates into dataframes in R Data manipulation and analysis using R standard commands and the tidyverse packages Data visualisation with ggplot2 Requirements Participants must bring a laptop with a Mac, Linux, or Windows operating system (not a tablet, Chromebook, etc.) that they have administrative privileges on. They should have a few specific software packages installed: Download R from the CRAN page: https://cloud.r-project.org/. At the top of that page, choose the Download R link corresponding to your operating system. If you use Windows, follow install R for the first time, then click the link to download R. The installation procedure is like any other software, and you can safely use all default options. If you use Mac (OS X), download the pkg installer that matches you OS version and install like any other software. Linux users are advised to use their package manager. Download and install the Rstudio Desktop Open source edition: https://rstudio.com/products/rstudio/download/#download. Choose the installer for your operating system and version. Install as any other software. For technical assistance https://moodle.uclouvain.be/course/view.php?id=4862 Provisional timetable Tuesday 28-9-21 Thursday 30-9-21 9h-10h30 Data organisation with SpreadsheetsR and Rstudio Data visualization 10h45-12h45 Introduction to RStarting with data Data visualizationJoining tables 13h45-15h45 Starting with dataManipulating and analyzing data with dplyr Summary exercise 16h-17h Manipulating and analyzing data with dplyr Further topics References and credits References are provided throughout the course. Several stand out however, as they cover large parts of the material or provide complementary resources. The material for the first chapters, covering the Introduction to data science with R, is based on the Data Carpentry Ecology curiculum (Michonneau and Fournier 2019). General references for this course are R for Data Science (Grolemund and Wickham 2017) and Bioinformatics Data Skills (Buffalo 2015). The RStudio Cheat Sheets are also a handy resource and readers will be pointed to specific sheets in the respective chapters. This training is organised by the SMCS in partnership with laurent Gatto, from the CBIO Lab in the de Duve Institute and is being taught by Axelle Loriot and Manon Martin at the UCLouvain, Belgium. About this course material This material is written in R markdown (Allaire et al. 2021) and compiled as a book using knitr (Xie 2021b) bookdown (Xie 2021a). The source code is publicly available in a Github repository https://github.com/UCLouvain-CBIO/bioinfo-training-01-intro and the compiled material can be read at https://uclouvain-cbio.github.io/bioinfo-training-01-intro/. Citation If you use this course, please cite it as Laurent Gatto, Kevin Missault &amp; Axelle Loriot. (2019, April 3). UCLouvain-CBIO/WSBIM1207: Introduction to bioinformatics (Version v1.0.0). Zenodo. http://doi.org/10.5281/zenodo.2626733 License This material is licensed under the Creative Commons Attribution-ShareAlike 4.0 License. Setup For chapter 1 about Data organisation with Spreadsheets, a spreadsheet programme is necessary. We will be using the R environment for statistical computing as main data science language. We will also use the RStudio interface to interact with R and write scripts and reports. Both R and RStudio are easy to install and works on all major operating systems. Once R and RStudio are installed, a set of packages will need to be installed. See section 8.1 for details. "],["sec-dataorg.html", "Chapter 1 Data organisation with Spreadsheets 1.1 Spreadsheet programs 1.2 Formatting data tables in spreadsheets 1.3 Common Spreadsheet Errors 1.4 Exporting data 1.5 Summary 1.6 Additional exercises", " Chapter 1 Data organisation with Spreadsheets Learning Objectives Learn about spreadsheets, their strenghts and weaknesses How do we format data in spreadsheets for effective data use? Learn about common spreadsheet errors and how to correct them. Organize your data according to tidy data principles. Learn about text-based spreadsheet formats such as the comma-separated (CSV) or tab-separated formats. 1.1 Spreadsheet programs Question What are basic principles for using spreadsheets for good data organization? Objective Describe best practices for organizing data so computers can make the best use of data sets. Keypoint Good data organization is the foundation of any research project. Good data organization is the foundation of your research project. Most researchers have data or do data entry in spreadsheets. Spreadsheet programs are very useful graphical interfaces for designing data tables and handling very basic data quality control functions. See also Broman and Woo (2018). Spreadsheet outline Spreadsheets are good for data entry. Therefore we have a lot of data in spreadsheets. Much of your time as a researcher will be spent in this ‘data wrangling’ stage. It’s not the most fun, but it’s necessary. We’ll teach you how to think about data organization and some practices for more effective data wrangling. What this lesson will not teach you How to do statistics in a spreadsheet How to do plotting in a spreadsheet How to write code in spreadsheet programs If you’re looking to do this, a good reference is Head First Excel, published by O’Reilly. Why aren’t we teaching data analysis in spreadsheets Data analysis in spreadsheets usually requires a lot of manual work. If you want to change a parameter or run an analysis with a new dataset, you usually have to redo everything by hand. (We do know that you can create macros, but see the next point.) It is also difficult to track or reproduce statistical or plotting analyses done in spreadsheet programs when you want to go back to your work or someone asks for details of your analysis. Many spreadsheet programs are available. Since most participants utilise Excel as their primary spreadsheet program, this lesson will make use of Excel examples. A free spreadsheet program that can also be used is LibreOffice. Commands may differ a bit between programs, but the general idea is the same. Spreadsheet programs encompass a lot of the things we need to be able to do as researchers. We can use them for: Data entry Organizing data Subsetting and sorting data Statistics Plotting Spreadsheet programs use tables to represent and display data. Data formatted as tables is also the main theme of this chapter, and we will see how to organise data into tables in a standardised way to ensure efficient downstream analysis. ► Question Discuss the following points with your neighbour How many people have used spreadsheets, in their research, courses, or at home? What kind of operations do you do in spreadsheets? Which ones do you think spreadsheets are good for? How many people have accidentally done something that made them frustrated or sad? Problems with Spreadsheets Spreadsheets are good for data entry, but in reality we tend to use spreadsheet programs for much more than data entry. We use them to create data tables for publications, to generate summary statistics, and make figures. Generating tables for publications in a spreadsheet is not optimal - often, when formatting a data table for publication, we’re reporting key summary statistics in a way that is not really meant to be read as data, and often involves special formatting (merging cells, creating borders, making it pretty). We advise you to do this sort of operation within your document editing software. The latter two applications, generating statistics and figures, should be used with caution: because of the graphical, drag and drop nature of spreadsheet programs, it can be very difficult, if not impossible, to replicate your steps (much less retrace anyone else’s), particularly if your stats or figures require you to do more complex calculations. Furthermore, in doing calculations in a spreadsheet, it’s easy to accidentally apply a slightly different formula to multiple adjacent cells. When using a command-line based statistics program like R or SAS, it’s practically impossible to apply a calculation to one observation in your dataset but not another unless you’re doing it on purpose. Using Spreadsheets for Data Entry and Cleaning However, there are circumstances where you might want to use a spreadsheet program to produce “quick and dirty” calculations or figures, and data cleaning will help you use some of these features. Data cleaning also puts your data in a better format prior to importation into a statistical analysis program. We will show you how to use some features of spreadsheet programs to check your data quality along the way and produce preliminary summary statistics. In this lesson, we will assume that you are most likely using Excel as your primary spreadsheet program - there are others (gnumeric, Calc from OpenOffice), and their functionality is similar, but Excel seems to be the program most used by biologists and biomedical researchers. In this lesson we’re going to talk about: Formatting data tables in spreadsheets Formatting problems Dates as data Quality control Exporting data 1.2 Formatting data tables in spreadsheets Questions How do we format data in spreadsheets for effective data use? Objectives Describe best practices for data entry and formatting in spreadsheets. Apply best practices to arrange variables and observations in a spreadsheet. Keypoints Never modify your raw data. Always make a copy before making any changes. Keep track of all of the steps you take to clean your data in a plain text file. Organize your data according to tidy data principles. The most common mistake made is treating spreadsheet programs like lab notebooks, that is, relying on context, notes in the margin, spatial layout of data and fields to convey information. As humans, we can (usually) interpret these things, but computers don’t view information the same way, and unless we explain to the computer what every single thing means (and that can be hard!), it will not be able to see how our data fits together. Using the power of computers, we can manage and analyze data in much more effective and faster ways, but to use that power, we have to set up our data for the computer to be able to understand it (and computers are very literal). This is why it’s extremely important to set up well-formatted tables from the outset - before you even start entering data from your very first preliminary experiment. Data organization is the foundation of your research project. It can make it easier or harder to work with your data throughout your analysis, so it’s worth thinking about when you’re doing your data entry or setting up your experiment. You can set things up in different ways in spreadsheets, but some of these choices can limit your ability to work with the data in other programs or have the you-of-6-months-from-now or your collaborator work with the data. Note: the best layouts/formats (as well as software and interfaces) for data entry and data analysis might be different. It is important to take this into account, and ideally automate the conversion from one to another. 1.2.1 Keeping track of your analyses When you’re working with spreadsheets, during data clean up or analyses, it’s very easy to end up with a spreadsheet that looks very different from the one you started with. In order to be able to reproduce your analyses or figure out what you did when a reviewer or instructor asks for a different analysis, you should create a new file with your cleaned or analyzed data. Don’t modify the original dataset, or you will never know where you started! keep track of the steps you took in your clean up or analysis. You should track these steps as you would any step in an experiment. We recommend that you do this in a plain text file stored in the same folder as the data file. This might be an example of a spreadsheet setup: Put these principles in to practice today during your exercises. While versioning is out of scope for this course, you can look at the Carpentries lesson on ‘Git’ to learn how to maintain version control over your data. See also this blog post for a quick tutorial or Perez-Riverol et al. (2016) for a more research-oriented use-case. 1.2.2 Structuring data in spreadsheets The cardinal rules of using spreadsheet programs for data: Put all your variables in columns - the thing you’re measuring, like ‘weight’ or ‘temperature.’ Put each observation in its own row. Don’t combine multiple pieces of information in one cell. Sometimes it just seems like one thing, but think if that’s the only way you’ll want to be able to use or sort that data. Leave the raw data raw - don’t change it! Export the cleaned data to a text-based format like CSV (comma-separated values) format. This ensures that anyone can use the data, and is required by most data repositories. For instance, we have data from patient that visited several hospitals from Brussels, Belgium. They recorded the date the visit, the hospital, the patients gender, weight and blood group. If they were to keep track of the data like this: the problem is that the ABO and rhesus groups are in the same Blood type column. So, if they wanted to look at all observations of the A group or look at weight distributions by ABO group, it would be tricky to do this using this data setup. If instead we put the ABO and rhesus groups in different columns, you can see that it would be much easier. An important rule when setting up a datasheet, is that columns are used for variables and rows are used for observations: columns are variables rows are observations cells are individual values ► Question We’re going to take a messy data and describe how we would clean it up. Download a messy data by clicking here. Open up the data in a spreadsheet program. You can see that there are two tabs. The data contains various clinical variables recorded in various hospitals in Brussels during the first and second COVID-19 waves in 2020. As you can see, the data have been recorded differently during the march and november waves. Now you’re the person in charge of this project and you want to be able to start analyzing the data. With the person next to you, identify what is wrong with this spreadsheet. Also discuss the steps you would need to take to clean up first and second wave tabs, and to put them all together in one spreadsheet. Important: Do not forget our first piece of advice: to create a new file (or tab) for the cleaned data, never modify your original (raw) data. After you go through this exercise, we’ll discuss as a group what was wrong with this data and how you would fix it. ► Question Once you have tidied up the data, answer the following questions: How many men and women took part in the study? How many A, AB, and B types have been tested? As above, but disregarding the contaminated samples? How many Rhesus + and - have been tested? How many universal donors (0-) have been tested? What is the average weight of AB men? How many samples have been tested in the different hospitals? An excellent reference, in particular with regard to R scripting is the Tidy Data paper Wickham (2014). 1.3 Common Spreadsheet Errors Questions What are some common challenges with formatting data in spreadsheets and how can we avoid them? Objectives Recognize and resolve common spreadsheet formatting problems. Keypoints Avoid using multiple tables within one spreadsheet. Avoid spreading data across multiple tabs. Record zeros as zeros. Use an appropriate null value to record missing data. Don’t use formatting to convey information or to make your spreadsheet look pretty. Place comments in a separate column. Record units in column headers. Include only one piece of information in a cell. Avoid spaces, numbers and special characters in column headers. Avoid special characters in your data. Record metadata in a separate plain text file. There are a few potential errors to be on the lookout for in your own data as well as data from collaborators or the Internet. If you are aware of the errors and the possible negative effect on downstream data analysis and result interpretation, it might motivate yourself and your project members to try and avoid them. Making small changes to the way you format your data in spreadsheets, can have a great impact on efficiency and reliability when it comes to data cleaning and analysis. Using multiple tables Using multiple tabs Not filling in zeros Using problematic null values Using formatting to convey information Using formatting to make the data sheet look pretty Placing comments or units in cells Entering more than one piece of information in a cell Using problematic field names Using special characters in data Inclusion of metadata in data table 1.3.1 Using multiple tables A common strategy is creating multiple data tables within one spreadsheet. This confuses the computer, so don’t do this! When you create multiple tables within one spreadsheet, you’re drawing false associations between things for the computer, which sees each row as an observation. You’re also potentially using the same field name in multiple places, which will make it harder to clean your data up into a usable form. The example below depicts the problem: In the example above, the computer will see (for example) row 4 and assume that all columns A-AF refer to the same sample. This row actually represents four distinct samples (sample 1 for each of four different collection dates - May 29th, June 12th, June 19th, and June 26th), as well as some calculated summary statistics (an average (avr) and standard error of measurement (SEM)) for two of those samples. Other rows are similarly problematic. 1.3.2 Using multiple tabs But what about workbook tabs? That seems like an easy way to organize data, right? Well, yes and no. When you create extra tabs, you fail to allow the computer to see connections in the data that are there (you have to introduce spreadsheet application-specific functions or scripting to ensure this connection). Say, for instance, you make a separate tab for each day you take a measurement. This isn’t good practice for two reasons: you are more likely to accidentally add inconsistencies to your data if each time you take a measurement, you start recording data in a new tab, and even if you manage to prevent all inconsistencies from creeping in, you will add an extra step for yourself before you analyze the data because you will have to combine these data into a single datatable. You will have to explicitly tell the computer how to combine tabs - and if the tabs are inconsistently formatted, you might even have to do it manually. The next time you’re entering data, and you go to create another tab or table, ask yourself if you could avoid adding this tab by adding another column to your original spreadsheet. We used multiple tabs in our example of a messy data file, but now you’ve seen how you can reorganize your data to consolidate across tabs. Your data sheet might get very long over the course of the experiment. This makes it harder to enter data if you can’t see your headers at the top of the spreadsheet. But don’t repeat your header row. These can easily get mixed into the data, leading to problems down the road. Instead you can freeze the column headers so that they remain visible even when you have a spreadsheet with many rows. 1.3.3 Not filling in zeros It might be that when you’re measuring something, it’s usually a zero, say the number of times a rabbit is observed in the survey. Why bother writing in the number zero in that column, when it’s mostly zeros? However, there’s a difference between a zero and a blank cell in a spreadsheet. To the computer, a zero is actually data. You measured or counted it. A blank cell means that it wasn’t measured and the computer will interpret it as an unknown value (otherwise known as a null value). The spreadsheets or statistical programs will likely mis-interpret blank cells that you intend to be zeros. By not entering the value of your observation, you are telling your computer to represent that data as unknown or missing (null). This can cause problems with subsequent calculations or analyses. For example, the average of a set of numbers which includes a single null value is always null (because the computer can’t guess the value of the missing observations). Because of this, it’s very important to record zeros as zeros and truly missing data as nulls. 1.3.4 Using problematic null values Example: using -999 or other numerical values (or zero) to represent missing data. Solutions: There are a few reasons why null values get represented differently within a dataset. Sometimes confusing null values are automatically recorded from the measuring device. If that’s the case, there’s not much you can do, but it can be addressed in data cleaning with a tool like OpenRefine before analysis. Other times different null values are used to convey different reasons why the data isn’t there. This is important information to capture, but is in effect using one column to capture two pieces of information. Like for using formatting to convey information((#formatting) it would be good here to create a new column like ‘data_missing’ and use that column to capture the different reasons. Whatever the reason, it’s a problem if unknown or missing data is recorded as -999, 999, or 0. Many statistical programs will not recognize that these are intended to represent missing (null) values. How these values are interpreted will depend on the software you use to analyze your data. It is essential to use a clearly defined and consistent null indicator. Blanks (most applications) and NA (for R) are good choices. White et al. (2013) explain good choices for indicating null values for different software applications in their article: 1.3.5 Using formatting to convey information Example: highlighting cells, rows or columns that should be excluded from an analysis, leaving blank rows to indicate separations in data. Solution: create a new field to encode which data should be excluded. 1.3.6 Using formatting to make the data sheet look pretty Example: merging cells. Solution: If you’re not careful, formatting a worksheet to be more aesthetically pleasing can compromise your computer’s ability to see associations in the data. Merged cells will make your data unreadable by statistics software. Consider restructuring your data in such a way that you will not need to merge cells to organize your data. 1.3.7 Placing comments or units in cells Most analysis software can’t see Excel or LibreOffice comments, and would be confused by comments placed within your data cells. As described above for formatting, create another field if you need to add notes to cells. Similarly, don’t include units in cells: ideally, all the measurements you place in one column should be in the same unit, but if for some reason they aren’t, create another field and specify the units the cell is in. 1.3.8 Entering more than one piece of information in a cell Example: Recording ABO and Rhesus groups in one cell, such as A+, B+, A-, … Solution: Don’t include more than one piece of information in a cell. This will limit the ways in which you can analyze your data. If you need both these measurements, design your data sheet to include this information. For example, include one column the ABO group and one for the Rhesus group. 1.3.9 Using problematic field names Choose descriptive field names, but be careful not to include spaces, numbers, or special characters of any kind. Spaces can be misinterpreted by parsers that use whitespace as delimiters and some programs don’t like field names that are text strings that start with numbers. Underscores (_) are a good alternative to spaces. Consider writing names in camel case (like this: ExampleFileName) to improve readability. Remember that abbreviations that make sense at the moment may not be so obvious in 6 months, but don’t overdo it with names that are excessively long. Including the units in the field names avoids confusion and enables others to readily interpret your fields. Examples Good Name Good Alternative Avoid Max_temp_C MaxTemp Maximum Temp (°C) Precipitation_mm Precipitation precmm Mean_year_growth MeanYearGrowth Mean growth/year sex sex M/F weight weight w. cell_type CellType Cell Type Observation_01 first_observation 1st Obs 1.3.10 Using special characters in data Example: You treat your spreadsheet program as a word processor when writing notes, for example copying data directly from Word or other applications. Solution: This is a common strategy. For example, when writing longer text in a cell, people often include line breaks, em-dashes, etc in their spreadsheet. Also, when copying data in from applications such as Word, formatting and fancy non-standard characters (such as left- and right-aligned quotation marks) are included. When exporting this data into a coding/statistical environment or into a relational database, dangerous things may occur, such as lines being cut in half and encoding errors being thrown. General best practice is to avoid adding characters such as newlines, tabs, and vertical tabs. In other words, treat a text cell as if it were a simple web form that can only contain text and spaces. 1.3.11 Inclusion of metadata in data table Example: You add a legend at the top or bottom of your data table explaining column meaning, units, exceptions, etc. Solution: Recording data about your data (“metadata”) is essential. You may be on intimate terms with your dataset while you are collecting and analysing it, but the chances that you will still remember that the variable “sglmemgp” means single member of group, for example, or the exact algorithm you used to transform a variable or create a derived one, after a few months, a year, or more are slim. As well, there are many reasons other people may want to examine or use your data - to understand your findings, to verify your findings, to review your submitted publication, to replicate your results, to design a similar study, or even to archive your data for access and re-use by others. While digital data by definition are machine-readable, understanding their meaning is a job for human beings. The importance of documenting your data during the collection and analysis phase of your research cannot be overestimated, especially if your research is going to be part of the scholarly record. However, metadata should not be contained in the data file itself. Unlike a table in a paper or a supplemental file, metadata (in the form of legends) should not be included in a data file since this information is not data, and including it can disrupt how computer programs interpret your data file. Rather, metadata should be stored as a separate file in the same directory as your data file, preferably in plain text format with a name that clearly associates it with your data file. Because metadata files are free text format, they also allow you to encode comments, units, information about how null values are encoded, etc. that are important to document but can disrupt the formatting of your data file. Additionally, file or database level metadata describes how files that make up the dataset relate to each other; what format are they in; and whether they supercede or are superceded by previous files. A folder-level readme.txt file is the classic way of accounting for all the files and folders in a project. (Text on metadata adapted from the online course Research Data MANTRA by EDINA and Data Library, University of Edinburgh. MANTRA is licensed under a Creative Commons Attribution 4.0 International License.) 1.4 Exporting data Question How can we export data from spreadsheets in a way that is useful for downstream applications? Objectives Store spreadsheet data in universal file formats. Export data from a spreadsheet to a CSV file. Keypoints Data stored in common spreadsheet formats will often not be read correctly into data analysis software, introducing errors into your data. Exporting data from spreadsheets to formats like CSV or TSV puts it in a format that can be used consistently by most programs. Storing the data you’re going to work with for your analyses in Excel default file format (*.xls or *.xlsx - depending on the Excel version) isn’t a good idea. Why? Because it is a proprietary format, and it is possible that in the future, technology won’t exist (or will become sufficiently rare) to make it inconvenient, if not impossible, to open the file. Other spreadsheet software may not be able to open files saved in a proprietary Excel format. Different versions of Excel may handle data differently, leading to inconsistencies. Dates is a well-documented example of inconsistencies in data storage. Finally, more journals and grant agencies are requiring you to deposit your data in a data repository, and most of them don’t accept Excel format. It needs to be in one of the formats discussed below. The above points also apply to other formats such as open data formats used by LibreOffice / Open Office. These formats are not static and do not get parsed the same way by different software packages. Storing data in a universal, open, and static format will help deal with this problem. Try tab-delimited (tab separated values or TSV) or comma-delimited (comma separated values or CSV). CSV files are plain text files where the columns are separated by commas, hence ‘comma separated values’ or CSV. The advantage of a CSV file over an Excel/SPSS/etc. file is that we can open and read a CSV file using just about any software, including plain text editors like TextEdit or NotePad. Data in a CSV file can also be easily imported into other formats and environments, such as SQLite and R. We’re not tied to a certain version of a certain expensive program when we work with CSV files, so it’s a good format to work with for maximum portability and endurance. Most spreadsheet programs can save to delimited text formats like CSV easily, although they may give you a warning during the file export. To save a file you have opened in Excel in CSV format: From the top menu select ‘File’ and ‘Save as.’ In the ‘Format’ field, from the list, select ‘Comma Separated Values’ (*.csv). Double check the file name and the location where you want to save it and hit ‘Save.’ An important note for backwards compatibility: you can open CSV files in Excel! Figure 1.1: Saving an Excel file to CSV. A note on R and xls: There are R packages that can read xls files (as well as Google spreadsheets). It is even possible to access different worksheets in the xls documents. But some of these only work on Windows this equates to replacing a (simple but manual) export to csv with additional complexity/dependencies in the data analysis R code data formatting best practice still apply Is there really a good reason why csv (or similar) is not adequate? Caveats on commas In some datasets, the data values themselves may include commas (,). In that case, the software which you use (including Excel) will most likely incorrectly display the data in columns. This is because the commas which are a part of the data values will be interpreted as delimiters. For example, our data might look like this: species_id,genus,species,taxa AB,Amphispiza,bilineata,Bird AH,Ammospermophilus,harrisi,Rodent, not censused AS,Ammodramus,savannarum,Bird BA,Baiomys,taylori,Rodent In the record AH,Ammospermophilus,harrisi,Rodent, not censused the value for taxa includes a comma (Rodent, not censused). If we try to read the above into Excel (or other spreadsheet program), we will get something like this: Figure 1.2: The risks of having commas inside comma-separated data. The value for taxa was split into two columns (instead of being put in one column D). This can propagate to a number of further errors. For example, the extra column will be interpreted as a column with many missing values (and without a proper header). In addition to that, the value in column D for the record in row 3 (so the one where the value for ‘taxa’ contained the comma) is now incorrect. If you want to store your data in csv format and expect that your data values may contain commas, you can avoid the problem discussed above by putting the values in quotes (\"\"). Applying this rule, our data might look like this: species_id,genus,species,taxa &quot;AB&quot;,&quot;Amphispiza&quot;,&quot;bilineata&quot;,&quot;Bird&quot; &quot;AH&quot;,&quot;Ammospermophilus&quot;,&quot;harrisi&quot;,&quot;Rodent, not censused&quot; &quot;AS&quot;,&quot;Ammodramus&quot;,&quot;savannarum&quot;,&quot;Bird&quot; &quot;BA&quot;,&quot;Baiomys&quot;,&quot;taylori&quot;,&quot;Rodent&quot; Now opening this file as a csv in Excel will not lead to an extra column, because Excel will only use commas that fall outside of quotation marks as delimiting characters. Alternatively, if you are working with data that contains commas, you likely will need to use another delimiter when working in a spreadsheet1. In this case, consider using tabs as your delimiter and working with TSV files. TSV files can be exported from spreadsheet programs in the same way as CSV files. If you are working with an already existing dataset in which the data values are not included in \"\" but which have commas as both delimiters and parts of data values, you are potentially facing a major problem with data cleaning. If the dataset you’re dealing with contains hundreds or thousands of records, cleaning them up manually (by either removing commas from the data values or putting the values into quotes - \"\") is not only going to take hours and hours but may potentially end up with you accidentally introducing many errors. Cleaning up datasets is one of the major problems in many scientific disciplines. The approach almost always depends on the particular context. However, it is a good practice to clean the data in an automated fashion, for example by writing and running a script. The Python and R lessons will give you the basis for developing skills to build relevant scripts. 1.5 Summary Figure 1.3: A typical data analysis workflow. A typical data analysis worflow is illustrated in figure 1.3, where data is repeatedly tranformed, visualised, modelled. This iteration is repeated multiple times until the data is understood. In many real-life cases, however, most time is spend in clearning up and preparing the data, rather than actually analysing and understanding it. An agile data analysis workflow, with several fast iteration of the transform/visualise/model cycle are only feasible is the data is formatted in a predictable way and one can reason on the data without having to look at it and/or fix it. 1.6 Additional exercises ► Question Download the supplementary table from Geladaki et al. (2019). Using the best practice documented above, export the file to a text-based spreadsheet (csv, tsv, …). If necessary, manually fix the table, but making sure you keep a copy of the original data and document your modifications. ► Question Download this table that presents luminescence read-out of a 96 well plate. Reformat it in a way that makes it amenable to data analysis. Hint: The letters A to H and the numbers 1 to 12 represent respectively the rows and the columns of the plate. ► Question Imagine the following experiment, and produce a data table, making up values for a dozen of observations. Rodents, mice and rats, where collected on various days by operators A and B. Their weight and tail length were measured and assigned to either a control group (and administered water) or a condition group (and administered drug X). Exactly one week later, the body measurements were repeated. This is of course particularly relevant in European countries where the comma is used as a decimal separator. In such cases, the default value separator in a csv file will be the semi-colon (;), or values will be systematically quoted.↩︎ "],["sec-rrstudio.html", "Chapter 2 R and RStudio 2.1 What is R? What is RStudio? 2.2 Why learn R? 2.3 Knowing your way around RStudio 2.4 Getting set up 2.5 Interacting with R 2.6 How to learn more during and after the course? 2.7 Seeking help 2.8 R packages", " Chapter 2 R and RStudio Learning Objectives Describe the purpose of the RStudio Script, Console, Environment, and Plots panes. Organize files and directories for a set of analyses as an R project, and understand the purpose of the working directory. Use the built-in RStudio help interface to search for more information on R functions. Demonstrate how to provide sufficient information for troubleshooting with the R user community. 2.1 What is R? What is RStudio? The term R is used to refer to both the programming language, the environment for statistical computing and the software that interprets the scripts written using it. RStudio is currently a very popular way to not only write your R scripts but also to interact with the R software2. To function correctly, RStudio needs R and therefore both need to be installed on your computer. The RStudio IDE Cheat Sheet provides much more information that will be covered here, but can be useful to learn keyboard shortcuts and discover new features. 2.2 Why learn R? R does not involve lots of pointing and clicking, and that’s a good thing The learning curve might be steeper than with other software, but with R, the results of your analysis do not rely on remembering a succession of pointing and clicking, but instead on a series of written commands, and that’s a good thing! So, if you want to redo your analysis because you collected more data, you don’t have to remember which button you clicked in which order to obtain your results; you just have to run your script again. Working with scripts makes the steps you used in your analysis clear, and the code you write can be inspected by someone else who can give you feedback and spot mistakes. Working with scripts forces you to have a deeper understanding of what you are doing, and facilitates your learning and comprehension of the methods you use. R code is great for reproducibility Reproducibility is when someone else (including your future self) can obtain the same results from the same dataset when using the same analysis. R integrates with other tools to generate manuscripts from your code. If you collect more data, or fix a mistake in your dataset, the figures and the statistical tests in your manuscript are updated automatically. An increasing number of journals and funding agencies expect analyses to be reproducible, so knowing R will give you an edge with these requirements. We will learn more about reproducibility and reproducible research in chapter ??. R is interdisciplinary and extensible With 10000+ packages3 that can be installed to extend its capabilities, R provides a framework that allows you to combine statistical approaches from many scientific disciplines to best suit the analytical framework you need to analyze your data. For instance, R has packages for image analysis, GIS, time series, population genetics, and a lot more. Figure 2.1: Exponential increase of the number of packages available on CRAN, the Comprehensive R Archive Network. From the R Journal, Volume 10/2, December 2018. R works on data of all shapes and sizes The skills you learn with R scale easily with the size of your dataset. Whether your dataset has hundreds or millions of lines, it won’t make much difference to you. R is designed for data analysis. It comes with special data structures and data types that make handling of missing data and statistical factors convenient. R can connect to spreadsheets, databases, and many other data formats, on your computer or on the web. R produces high-quality graphics The plotting functionalities in R are endless, and allow you to adjust any aspect of your graph to convey most effectively the message from your data. R has a large and welcoming community Thousands of people use R daily. Many of them are willing to help you through mailing lists and websites such as Stack Overflow, or on the RStudio community. These broad user community extends to specialised areas such as bioinformatics. Not only is R free, but it is also open-source and cross-platform Anyone can inspect the source code to see how R works. Because of this transparency, there is less chance for mistakes, and if you (or someone else) find some, you can report and fix bugs. 2.3 Knowing your way around RStudio Let’s start by learning about RStudio, which is an Integrated Development Environment (IDE) for working with R. The RStudio IDE open-source product is free under the Affero General Public License (AGPL) v3. The RStudio IDE is also available with a commercial license and priority email support from RStudio, Inc. We will use RStudio IDE to write code, navigate the files on our computer, inspect the variables we are going to create, and visualize the plots we will generate. RStudio can also be used for other things (e.g., version control, developing packages, writing Shiny apps) that we will not cover during the workshop. Figure 2.2: RStudio interface screenshot. Clockwise from top left: Source, Environment/History, Files/Plots/Packages/Help/Viewer, Console. RStudio is divided into 4 “Panes”: the Source for your scripts and documents (top-left, in the default layout) your Environment/History (top-right), your Files/Plots/Packages/Help/Viewer (bottom-right), and the R Console (bottom-left). The placement of these panes and their content can be customized (see menu, Tools -&gt; Global Options -&gt; Pane Layout). One of the advantages of using RStudio is that all the information you need to write code is available in a single window. Additionally, with many shortcuts, autocompletion, and highlighting for the major file types you use while developing in R, RStudio will make typing easier and less error-prone. 2.4 Getting set up It is good practice to keep a set of related data, analyses, and text self-contained in a single folder, called the working directory. All of the scripts within this folder can then use relative paths to files that indicate where inside the project a file is located (as opposed to absolute paths, which point to where a file is on a specific computer). Working this way makes it a lot easier to move your project around on your computer and share it with others without worrying about whether or not the underlying scripts will still work. RStudio provides a helpful set of tools to do this through its “Projects” interface, which not only creates a working directory for you, but also remembers its location (allowing you to quickly navigate to it) and optionally preserves custom settings and open files to make it easier to resume work after a break. Go through the steps for creating an “R Project” for this tutorial below. Start RStudio. Under the File menu, click on New project. Choose New directory, then New project. Enter a name for this new folder (or “directory”), and choose a convenient location for it. This will be your working directory for this session (or whole course) (e.g., wsbim1207). Click on Create project. (Optional) Set Preferences to ‘Never’ save workspace in RStudio. RStudio’s default preferences generally work well, but saving a workspace to .RData can be cumbersome, especially if you are working with larger datasets. To turn that off, go to Tools –&gt; ‘Global Options’ and select the ‘Never’ option for ‘Save workspace to .RData’ on exit.’ Figure 2.3: Set ‘Save workspace to .RData on exit’ to ‘Never’ To avoid character encoding issue between Windows and other operating systems, we are going to set UTF-8 by default: Figure 2.4: Set the default text encoding to UTF-8 to save us headache in the coming future. (Figure from the link above). 2.4.1 Organizing your working directory Using a consistent folder structure across your projects will help keep things organized, and will also make it easy to find/file things in the future. This can be especially helpful when you have multiple projects. In general, you may create directories (folders) for scripts, data, and documents. data/ Use this folder to store your raw data and intermediate datasets you may create for the need of a particular analysis. For the sake of transparency and provenance, you should always keep a copy of your raw data accessible and do as much of your data cleanup and preprocessing programmatically (i.e., with scripts, rather than manually) as possible. Separating raw data from processed data is also a good idea. For example, you could have files data/raw/tree_survey.plot1.txt and ...plot2.txt kept separate from a data/processed/tree.survey.csv file generated by the scripts/01.preprocess.tree_survey.R script. documents/ This would be a place to keep outlines, drafts, and other text. scripts/ (or src) This would be the location to keep your R scripts for different analyses or plotting, and potentially a separate folder for your functions (more on that later). You may want additional directories or subdirectories depending on your project needs, but these should form the backbone of your working directory. Figure 2.5: Example of a working directory structure. For this course, we will need a data/ folder to store our raw data, and we will use data_output/ for when we learn how to export data as CSV files, and fig_output/ folder for the figures that we will save. ► Question Under the Files tab on the right of the screen, click on New Folder and create a folder named data within your newly created working directory (e.g., ~/wsbim1207/data). (Alternatively, type dir.create(\"data\") at your R console.) Repeat these operations to create a data_output/ and a fig_output folders. We are going to keep the script in the root of our working directory because we are only going to use one file and it will make things easier. Your working directory should now look like this: Figure 2.6: How it should look like at the beginning of this lesson Project management is also applicable to bioinformatics projects, of course4. William Noble (Noble (2009)) proposes the following directory structure: Directory names are in large typeface, and filenames are in smaller typeface. Only a subset of the files are shown here. Note that the dates are formatted &lt;year&gt;-&lt;month&gt;-&lt;day&gt; so that they can be sorted in chronological order. The source code src/ms-analysis.c is compiled to create bin/ms-analysis and is documented in doc/ms-analysis.html. The README files in the data directories specify who downloaded the data files from what URL on what date. The driver script results/2009-01-15/runall automatically generates the three subdirectories split1, split2, and split3, corresponding to three cross-validation splits. The bin/parse-sqt.py script is called by both of the runall driver scripts. Figure 2.7: Directory structure for a sample bioinformatics project. The most important aspect of a well defined and well documented project directory is to enable someone unfamiliar with the project5 to understand what the project is about, what data are available, what analyses were run, and what results were produced and, most importantly to repeat the analysis over again - with new data, or changing some analysis parameters. 2.4.2 The working directory The working directory is an important concept to understand. It is the place from where R will be looking for and saving the files. When you write code for your project, it should refer to files in relation to the root of your working directory and only need files within this structure. Using RStudio projects makes this easy and ensures that your working directory is set properly. If you need to check it, you can use getwd(). If for some reason your working directory is not what it should be, you can change it in the RStudio interface by navigating in the file browser where your working directory should be, and clicking on the blue gear icon More, and select Set As Working Directory. Alternatively you can use setwd(\"/path/to/working/directory\") to reset your working directory. However, your scripts should not include this line because it will fail on someone else’s computer. Example The shema below represents the working directory wsbim1207 with the data and fig_output sub-directories, and 2 files in the latter: wsbim1207/data/ /fig_output/fig1.pdf /fig_output/fig2.png If we were in the working directory, we could refer to the fig1.pdf file using the relative path wsbim1207/fig_output/fig1.pdf or the absolute path /home/user/wsbim1207/fig_output/fig1.pdf. If we were in the data directory, we would use the relative path ../fig_output/fig1.pdf or the same absolute path /home/user/wsbim1207/fig_output/fig1.pdf. 2.5 Interacting with R The basis of programming is that we write down instructions for the computer to follow, and then we tell the computer to follow those instructions. We write, or code, instructions in R because it is a common language that both the computer and we can understand. We call the instructions commands and we tell the computer to follow the instructions by executing (also called running) those commands. There are two main ways of interacting with R: by using the console or by using scripts (plain text files that contain your code). The console pane (in RStudio, the bottom left panel) is the place where commands written in the R language can be typed and executed immediately by the computer. It is also where the results will be shown for commands that have been executed. You can type commands directly into the console and press Enter to execute those commands, but they will be forgotten when you close the session. Because we want our code and workflow to be reproducible, it is better to type the commands we want in the script editor, and save the script. This way, there is a complete record of what we did, and anyone (including our future selves!) can easily replicate the results on their computer. RStudio allows you to execute commands directly from the script editor by using the Ctrl + Enter shortcut (on Macs, Cmd + Return will work, too). The command on the current line in the script (indicated by the cursor) or all of the commands in the currently selected text will be sent to the console and executed when you press Ctrl + Enter. You can find other keyboard shortcuts in this RStudio cheatsheet about the RStudio IDE. At some point in your analysis you may want to check the content of a variable or the structure of an object, without necessarily keeping a record of it in your script. You can type these commands and execute them directly in the console. RStudio provides the Ctrl + 1 and Ctrl + 2 shortcuts allow you to jump between the script and the console panes. If R is ready to accept commands, the R console shows a &gt; prompt. If it receives a command (by typing, copy-pasting or sent from the script editor using Ctrl + Enter), R will try to execute it, and when ready, will show the results and come back with a new &gt; prompt to wait for new commands. If R is still waiting for you to enter more data because it isn’t complete yet, the console will show a + prompt. It means that you haven’t finished entering a complete command. This is because you have not ‘closed’ a parenthesis or quotation, i.e. you don’t have the same number of left-parentheses as right-parentheses, or the same number of opening and closing quotation marks. When this happens, and you thought you finished typing your command, click inside the console window and press Esc; this will cancel the incomplete command and return you to the &gt; prompt. 2.6 How to learn more during and after the course? The material we cover during this course will give you an initial taste of how you can use R to analyse data for your own research. However, you will need to learn more to do advanced operations such as cleaning your dataset, using statistical methods, or creating beautiful graphics6. The best way to become proficient and efficient at R, as with any other tool, is to use it to address your actual research questions. As a beginner, it can feel daunting to have to write a script from scratch, and given that many people make their code available online, modifying existing code to suit your purpose might make it easier for you to get started. 2.7 Seeking help Use the built-in RStudio help interface to search for more information on R functions Figure 2.8: RStudio help interface. One of the fastest ways to get help, is to use the RStudio help interface. This panel by default can be found at the lower right hand panel of RStudio. As seen in the screenshot, by typing the word “Mean,” RStudio tries to also give a number of suggestions that you might be interested in. The description is then shown in the display window. I know the name of the function I want to use, but I’m not sure how to use it If you need help with a specific function, let’s say barplot(), you can type: ?barplot If you just need to remind yourself of the names of the arguments, you can use: args(lm) I want to use a function that does X, there must be a function for it but I don’t know which one… If you are looking for a function to do a particular task, you can use the help.search() function, which is called by the double question mark ??. However, this only looks through the installed packages for help pages with a match to your search request ??kruskal If you can’t find what you are looking for, you can use the rdocumentation.org website that searches through the help files across all packages available. Finally, a generic Google or internet search “R &lt;task&gt;” will often either send you to the appropriate package documentation or a helpful forum where someone else has already asked your question. I am stuck… I get an error message that I don’t understand Start by googling the error message. However, this doesn’t always work very well because often, package developers rely on the error catching provided by R. You end up with general error messages that might not be very helpful to diagnose a problem (e.g. “subscript out of bounds”). If the message is very generic, you might also include the name of the function or package you’re using in your query. However, you should check Stack Overflow. Search using the [r] tag. Most questions have already been answered, but the challenge is to use the right words in the search to find the answers: http://stackoverflow.com/questions/tagged/r The Introduction to R can also be dense for people with little programming experience but it is a good place to understand the underpinnings of the R language. The R FAQ is dense and technical but it is full of useful information. Asking for help The key to receiving help from someone is for them to rapidly grasp your problem. You should make it as easy as possible to pinpoint where the issue might be. Try to use the correct words to describe your problem. For instance, a package is not the same thing as a library. Most people will understand what you meant, but others have really strong feelings about the difference in meaning. The key point is that it can make things confusing for people trying to help you. Be as precise as possible when describing your problem. If possible, try to reduce what doesn’t work to a simple reproducible example. If you can reproduce the problem using a very small data frame instead of your 50000 rows and 10000 columns one, provide the small one with the description of your problem. When appropriate, try to generalize what you are doing so even people who are not in your field can understand the question. For instance instead of using a subset of your real dataset, create a small (3 columns, 5 rows) generic one. For more information on how to write a reproducible example see this article by Hadley Wickham. To share an object with someone else, if it’s relatively small, you can use the function dput(). It will output R code that can be used to recreate the exact same object as the one in memory: ## iris is an example data frame that comes with R and head() is a ## function that returns the first part of the data frame dput(head(iris)) ## structure(list(Sepal.Length = c(5.1, 4.9, 4.7, 4.6, 5, 5.4), ## Sepal.Width = c(3.5, 3, 3.2, 3.1, 3.6, 3.9), Petal.Length = c(1.4, ## 1.4, 1.3, 1.5, 1.4, 1.7), Petal.Width = c(0.2, 0.2, 0.2, ## 0.2, 0.2, 0.4), Species = structure(c(1L, 1L, 1L, 1L, 1L, ## 1L), .Label = c(&quot;setosa&quot;, &quot;versicolor&quot;, &quot;virginica&quot;), class = &quot;factor&quot;)), row.names = c(NA, ## 6L), class = &quot;data.frame&quot;) If the object is larger, provide either the raw file (i.e., your CSV file) with your script up to the point of the error (and after removing everything that is not relevant to your issue). Alternatively, in particular if your question is not related to a data frame, you can save any R object to a file7: saveRDS(iris, file=&quot;/tmp/iris.rds&quot;) The content of this file is however not human readable and cannot be posted directly on Stack Overflow. Instead, it can be sent to someone by email who can read it with the readRDS() command (here it is assumed that the downloaded file is in a Downloads folder in the user’s home directory): some_data &lt;- readRDS(file=&quot;~/Downloads/iris.rds&quot;) Last, but certainly not least, always include the output of sessionInfo() as it provides critical information about your platform, the versions of R and the packages that you are using, and other information that can be very helpful to understand your problem. sessionInfo() ## R version 4.1.0 (2021-05-18) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Big Sur 10.16 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib ## ## locale: ## [1] C/UTF-8/C/C/C/C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] bookdown_0.24 msmbstyle_0.0.19 png_0.1-7 digest_0.6.27 ## [5] R6_2.5.1 jsonlite_1.7.2 magrittr_2.0.1 evaluate_0.14 ## [9] highr_0.9 stringi_1.7.4 rlang_0.4.11 rstudioapi_0.13 ## [13] jquerylib_0.1.4 xml2_1.3.2 bslib_0.3.0 rmarkdown_2.11 ## [17] tools_4.1.0 stringr_1.4.0 xfun_0.26 yaml_2.2.1 ## [21] fastmap_1.1.0 compiler_4.1.0 htmltools_0.5.2 knitr_1.34 ## [25] sass_0.4.0 Where to ask for help? The person sitting next to you during the course. Don’t hesitate to talk to your neighbour during the workshop, compare your answers, and ask for help. Your friendly colleagues: if you know someone with more experience than you, they might be able and willing to help you. Stack Overflow: if your question hasn’t been answered before and is well crafted, chances are you will get an answer in less than 5 min. Remember to follow their guidelines on how to ask a good question. The R-help mailing list: it is read by a lot of people (including most of the R core team), a lot of people post to it, but the tone can be pretty dry, and it is not always very welcoming to new users. If your question is valid, you are likely to get an answer very fast but don’t expect that it will come with smiley faces. Also, here more than anywhere else, be sure to use correct vocabulary (otherwise you might get an answer pointing to the misuse of your words rather than answering your question). You will also have more success if your question is about a base function rather than a specific package. If your question is about a specific package, see if there is a mailing list for it. Usually it’s included in the DESCRIPTION file of the package that can be accessed using packageDescription(\"name-of-package\"). You may also want to try to email the author of the package directly, or open an issue on the code repository (e.g., GitHub). There are also some topic-specific mailing lists (GIS, phylogenetics, etc…), the complete list is here. More resources The Posting Guide for the R mailing lists. How to ask for R help useful guidelines This blog post by Jon Skeet has quite comprehensive advice on how to ask programming questions. The reprex package is very helpful to create reproducible examples when asking for help. The rOpenSci community call “How to ask questions so they get answered” (Github link and video recording) includes a presentation of the reprex package and of its philosophy. 2.8 R packages 2.8.1 Loading packages As we have seen above, R packages play a fundamental role in R. The make use of a package’s functionality, assuming it is installed, we first need to load it to be able to use it. This is done with the library() function. Below, we load ggplot2. library(&quot;ggplot2&quot;) 2.8.2 Installing packages The default package repository is The Comprehensive R Archive Network (CRAN), and any package that is available on CRAN can be installed with the install.packages() function. Below, for example, we install the dplyr package that we will learn about late. install.packages(&quot;dplyr&quot;) This command will install the dplyr package as well as all its dependencies, i.e. all the packages that it relies on to function. Github is a general-pupose online software project repository and is well suited for R package development. To install a package from Gtihub, one can use the install_github() function from the devtools package. Below we first install the latter from CRAN (as show above), then we install rWSBIM1207 directly from the user UCLouvain-CBIO github repository. install.packages(&quot;devtools&quot;) library(&quot;devtools&quot;) install_github(&quot;UCLouvain-CBIO/rWSBIM1207&quot;) In section ??, we will see how to install Bioconductor, a project dedicated to bioinformatics and omics packages. As opposed to using R directly from the command line console. There exist other software that interface and integrate with R, but RStudio is particularly well suited for beginners and while providing numerous very advanced features.↩︎ i.e. add-ons that confer R with new functionality, such as bioinformatics data analysis - see chapter ??↩︎ In this course, we consider bioinformatics as data science applied to biological or bio-medical data.↩︎ That someone could be, and very likely will be your future self, a couple of months or years after the analyses were run.↩︎ We will introduce most of these (except statistics) here, but will only manage to scratch the surface of the wealth of what is possible to do with R.↩︎ See section 4.10 for a better introduction about exporting and saving data.↩︎ "],["sec-startr.html", "Chapter 3 Introduction to R 3.1 Creating objects in R 3.2 Comments 3.3 Functions and their arguments 3.4 Vectors and data types 3.5 Subsetting vectors 3.6 Conditional subsetting 3.7 Names 3.8 Missing data 3.9 Generating vectors 3.10 Additional exercises", " Chapter 3 Introduction to R Learning Objectives Define the following terms as they relate to R: object, assign, call, function, arguments, options. Assign values to objects in R. Learn how to name objects Use comments to inform script. Solve simple arithmetic operations in R. Call functions and use arguments to change their default options. Inspect the content of vectors and manipulate their content. Subset and extract values from vectors. Analyze vectors with missing data. 3.1 Creating objects in R You can get output from R simply by typing math in the console: 3 + 5 ## [1] 8 12 / 7 ## [1] 1.714286 However, to do useful and interesting things, we need to assign values to objects. To create an object, we need to give it a name followed by the assignment operator &lt;-, and the value we want to give it: weight_kg &lt;- 55 &lt;- is the assignment operator. It assigns values on the right to objects on the left. So, after executing x &lt;- 3, the value of x is 3. The arrow can be read as 3 goes into x. For historical reasons, you can also use = for assignments, but not in every context. Because of the slight differences in syntax, it is good practice to always use &lt;- for assignments. In RStudio, typing Alt + - (push Alt at the same time as the - key) will write &lt;- in a single keystroke in a PC, while typing Option + - (push Option at the same time as the - key) does the same in a Mac. Naming variables Objects can be given any name such as x, current_temperature, or subject_id. You want your object names to be explicit and not too long. They cannot start with a number (2x is not valid, but x2 is). R is case sensitive (e.g., weight_kg is different from Weight_kg). There are some names that cannot be used because they are the names of fundamental functions in R (e.g., if, else, for, see here for a complete list). In general, even if it’s allowed, it’s best to not use other function names (e.g., c, T, mean, data, df, weights). If in doubt, check the help to see if the name is already in use. It’s also best to avoid dots (.) within an object name as in my.dataset. There are many functions in R with dots in their names for historical reasons, but because dots have a special meaning in R (for methods) and other programming languages, it’s best to avoid them. It is also recommended to use nouns for object names, and verbs for function names. It’s important to be consistent in the styling of your code (where you put spaces, how you name objects, etc.). Using a consistent coding style makes your code clearer to read for your future self and your collaborators. In R, some popular style guides are Google’s, the tidyverse’s style and the Bioconductor style guide. The tidyverse’s is very comprehensive and may seem overwhelming at first. You can install the lintr package to automatically check for issues in the styling of your code. Objects vs. variables What are known as objects in R are known as variables in many other programming languages. Depending on the context, object and variable can have drastically different meanings. However, in this lesson, the two words are used synonymously. For more information see: https://cran.r-project.org/doc/manuals/r-release/R-lang.html#Objects When assigning a value to an object, R does not print anything. You can force R to print the value by using parentheses or by typing the object name: weight_kg &lt;- 55 # doesn&#39;t print anything (weight_kg &lt;- 55) # but putting parenthesis around the call prints the value of `weight_kg` ## [1] 55 weight_kg # and so does typing the name of the object ## [1] 55 Now that R has weight_kg in memory, we can do arithmetic with it. For instance, we may want to convert this weight into pounds (weight in pounds is 2.2 times the weight in kg): 2.2 * weight_kg ## [1] 121 We can also change an object’s value by assigning it a new one: weight_kg &lt;- 57.5 2.2 * weight_kg ## [1] 126.5 This means that assigning a value to one object does not change the values of other objects For example, let’s store the animal’s weight in pounds in a new object, weight_lb: weight_lb &lt;- 2.2 * weight_kg and then change weight_kg to 100. weight_kg &lt;- 100 ► Question What do you think is the current content of the object weight_lb? 126.5 or 220? 3.2 Comments The comment character in R is #, anything to the right of a # in a script will be ignored by R. It is useful to leave notes, and explanations in your scripts. RStudio makes it easy to comment or uncomment a paragraph: after selecting the lines you want to comment, press at the same time on your keyboard Ctrl + Shift + C. If you only want to comment out one line, you can put the cursor at any location of that line (i.e. no need to select the whole line), then press Ctrl + Shift + C. ► Question What are the values after each statement in the following? mass &lt;- 47.5 # mass? age &lt;- 122 # age? mass &lt;- mass * 2.0 # mass? age &lt;- age - 20 # age? mass_index &lt;- mass/age # mass_index? 3.3 Functions and their arguments Functions are “canned scripts” that automate more complicated sets of commands including operations assignments, etc. Many functions are predefined, or can be made available by importing R packages (more on that later). A function usually gets one or more inputs called arguments. Functions often (but not always) return a value. A typical example would be the function sqrt(). The input (the argument) must be a number, and the return value (in fact, the output) is the square root of that number. Executing a function (‘running it’) is called calling the function. An example of a function call is: b &lt;- sqrt(a) Here, the value of a is given to the sqrt() function, the sqrt() function calculates the square root, and returns the value which is then assigned to the object b. This function is very simple, because it takes just one argument. The return ‘value’ of a function need not be numerical (like that of sqrt()), and it also does not need to be a single item: it can be a set of things, or even a dataset. We’ll see that when we read data files into R. Arguments can be anything, not only numbers or filenames, but also other objects. Exactly what each argument means differs per function, and must be looked up in the documentation (see below). Some functions take arguments which may either be specified by the user, or, if left out, take on a default value: these are called options. Options are typically used to alter the way the function operates, such as whether it ignores ‘bad values,’ or what symbol to use in a plot. However, if you want something specific, you can specify a value of your choice which will be used instead of the default. Let’s try a function that can take multiple arguments: round(). round(3.14159) ## [1] 3 Here, we’ve called round() with just one argument, 3.14159, and it has returned the value 3. That’s because the default is to round to the nearest whole number. If we want more digits we can see how to do that by getting information about the round function. We can use args(round) or look at the help for this function using ?round. args(round) ## function (x, digits = 0) ## NULL ?round We see that if we want a different number of digits, we can type digits=2 or however many we want. round(3.14159, digits = 2) ## [1] 3.14 If you provide the arguments in the exact same order as they are defined you don’t have to name them: round(3.14159, 2) ## [1] 3.14 And if you do name the arguments, you can switch their order: round(digits = 2, x = 3.14159) ## [1] 3.14 It’s good practice to put the non-optional arguments (like the number you’re rounding) first in your function call, and to specify the names of all optional arguments. If you don’t, someone reading your code might have to look up the definition of a function with unfamiliar arguments to understand what you’re doing. 3.4 Vectors and data types A vector is the most common and basic data type in R, and is pretty much the workhorse of R. A vector is composed by a series of values, which can be either numbers or characters. We can assign a series of values to a vector using the c() function. For example we can create a vector of animal weights and assign it to a new object weight_g: weight_g &lt;- c(50, 60, 65, 82) weight_g ## [1] 50 60 65 82 A vector can also contain characters: molecules &lt;- c(&quot;dna&quot;, &quot;rna&quot;, &quot;protein&quot;) molecules ## [1] &quot;dna&quot; &quot;rna&quot; &quot;protein&quot; The quotes around “dna,” “rna,” etc. are essential here. Without the quotes R will assume there are objects called dna, rna and protein. As these objects don’t exist in R’s memory, there will be an error message. There are many functions that allow you to inspect the content of a vector. length() tells you how many elements are in a particular vector: length(weight_g) ## [1] 4 length(molecules) ## [1] 3 An important feature of a vector, is that all of the elements are the same type of data. The function class() indicates the class (the type of element) of an object: class(weight_g) ## [1] &quot;numeric&quot; class(molecules) ## [1] &quot;character&quot; The function str() provides an overview of the structure of an object and its elements. It is a useful function when working with large and complex objects: str(weight_g) ## num [1:4] 50 60 65 82 str(molecules) ## chr [1:3] &quot;dna&quot; &quot;rna&quot; &quot;protein&quot; You can use the c() function to add other elements to your vector: weight_g &lt;- c(weight_g, 90) # add to the end of the vector weight_g &lt;- c(30, weight_g) # add to the beginning of the vector weight_g ## [1] 30 50 60 65 82 90 In the first line, we take the original vector weight_g, add the value 90 to the end of it, and save the result back into weight_g. Then we add the value 30 to the beginning, again saving the result back into weight_g. We can do this over and over again to grow a vector, or assemble a dataset. As we program, this may be useful to add results that we are collecting or calculating. An atomic vector is the simplest R data type and is a linear vector of a single type. Above, we saw 2 of the 6 main atomic vector types that R uses: \"character\" and \"numeric\" (or \"double\"). These are the basic building blocks that all R objects are built from. The other 4 atomic vector types are: \"logical\" for TRUE and FALSE (the boolean data type) \"integer\" for integer numbers (e.g., 2L, the L indicates to R that it’s an integer) \"complex\" to represent complex numbers with real and imaginary parts (e.g., 1 + 4i) and that’s all we’re going to say about them \"raw\" for bitstreams that we won’t discuss further You can check the type of your vector using the typeof() function and inputting your vector as the argument. Vectors are one of the many data structures that R uses. Other important ones are lists (list), matrices (matrix), data frames (data.frame), factors (factor) and arrays (array). ► Question We’ve seen that atomic vectors can be of type character, numeric (or double), integer, and logical. But what happens if we try to mix these types in a single vector? ► Solution R implicitly converts them to all be the same type ► Question What will happen in each of these examples? (hint: use class() to check the data type of your objects): num_char &lt;- c(1, 2, 3, &quot;a&quot;) num_logical &lt;- c(1, 2, 3, TRUE) char_logical &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, TRUE) tricky &lt;- c(1, 2, 3, &quot;4&quot;) ► Solution class(num_char) ## [1] &quot;character&quot; class(num_logical) ## [1] &quot;numeric&quot; class(char_logical) ## [1] &quot;character&quot; class(tricky) ## [1] &quot;character&quot; ► Question Why do you think it happens? ► Solution Vectors can be of only one data type. R tries to convert (coerce) the content of this vector to find a common denominator that doesn’t lose any information. ► Question How many values in combined_logical are \"TRUE\" (as a character) in the following example: num_logical &lt;- c(1, 2, 3, TRUE) char_logical &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, TRUE) combined_logical &lt;- c(num_logical, char_logical) ► Solution Only one. There is no memory of past data types, and the coercion happens the first time the vector is evaluated. Therefore, the TRUE in num_logical gets converted into a 1 before it gets converted into \"1\" in combined_logical. combined_logical ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;1&quot; &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;TRUE&quot; ► Question In R, we call converting objects from one class into another class coercion. These conversions happen according to a hierarchy, whereby some types get preferentially coerced into other types. Can you draw a diagram that represents the hierarchy of how these data types are coerced? ► Solution logical → numeric → character ← logical 3.5 Subsetting vectors If we want to extract one or several values from a vector, we must provide one or several indices in square brackets. For instance: molecules &lt;- c(&quot;dna&quot;, &quot;rna&quot;, &quot;peptide&quot;, &quot;protein&quot;) molecules[2] ## [1] &quot;rna&quot; molecules[c(3, 2)] ## [1] &quot;peptide&quot; &quot;rna&quot; We can also repeat the indices to create an object with more elements than the original one: more_molecules &lt;- molecules[c(1, 2, 3, 2, 1, 4)] more_molecules ## [1] &quot;dna&quot; &quot;rna&quot; &quot;peptide&quot; &quot;rna&quot; &quot;dna&quot; &quot;protein&quot; R indices start at 1. Programming languages like Fortran, MATLAB, Julia, and R start counting at 1, because that’s what human beings typically do. Languages in the C family (including C++, Java, Perl, and Python) count from 0 because that’s simpler for computers to do. Finally, it is also possible to get all the elements of a vector except some specified elements using negative indices: molecules ## all molecules ## [1] &quot;dna&quot; &quot;rna&quot; &quot;peptide&quot; &quot;protein&quot; molecules[-1] ## all but the first one ## [1] &quot;rna&quot; &quot;peptide&quot; &quot;protein&quot; molecules[-c(1, 3)] ## all but 1st/3rd ones ## [1] &quot;rna&quot; &quot;protein&quot; molecules[c(-1, -3)] ## all but 1st/3rd ones ## [1] &quot;rna&quot; &quot;protein&quot; 3.6 Conditional subsetting Another common way of subsetting is by using a logical vector. TRUE will select the element with the same index, while FALSE will not: weight_g &lt;- c(21, 34, 39, 54, 55) weight_g[c(TRUE, FALSE, TRUE, TRUE, FALSE)] ## [1] 21 39 54 Typically, these logical vectors are not typed by hand, but are the output of other functions or logical tests. For instance, if you wanted to select only the values above 50: ## will return logicals with TRUE for the indices that meet ## the condition weight_g &gt; 50 ## [1] FALSE FALSE FALSE TRUE TRUE ## so we can use this to select only the values above 50 weight_g[weight_g &gt; 50] ## [1] 54 55 You can combine multiple tests using &amp; (both conditions are true, AND) or | (at least one of the conditions is true, OR): weight_g[weight_g &lt; 30 | weight_g &gt; 50] ## [1] 21 54 55 weight_g[weight_g &gt;= 30 &amp; weight_g == 21] ## numeric(0) Here, &lt; stands for “less than,” &gt; for “greater than,” &gt;= for “greater than or equal to,” and == for “equal to.” The double equal sign == is a test for numerical equality between the left and right hand sides, and should not be confused with the single = sign, which performs variable assignment (similar to &lt;-). A common task is to search for certain strings in a vector. One could use the “or” operator | to test for equality to multiple values, but this can quickly become tedious. The function %in% allows you to test if any of the elements of a search vector are found: molecules &lt;- c(&quot;dan&quot;, &quot;rna&quot;, &quot;protein&quot;, &quot;peptide&quot;) molecules[molecules == &quot;rna&quot; | molecules == &quot;dna&quot;] # returns both rna and dna ## [1] &quot;rna&quot; molecules %in% c(&quot;rna&quot;, &quot;dna&quot;, &quot;metabolite&quot;, &quot;peptide&quot;, &quot;glycerol&quot;) ## [1] FALSE TRUE FALSE TRUE molecules[molecules %in% c(&quot;rna&quot;, &quot;dna&quot;, &quot;metabolite&quot;, &quot;peptide&quot;, &quot;glycerol&quot;)] ## [1] &quot;rna&quot; &quot;peptide&quot; ► Question Can you figure out why \"four\" &gt; \"five\" returns TRUE? ► Solution &quot;four&quot; &gt; &quot;five&quot; ## [1] TRUE When using &gt; or &lt; on strings, R compares their alphabetical order. Here \"four\" comes after \"five\", and therefore is greater than it. 3.7 Names It is possible to name each element of a vector. The code chunk below show a initial vector without any names, how names are set, and retrieved. x &lt;- c(1, 5, 3, 5, 10) names(x) ## no names ## NULL names(x) &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;) names(x) ## now we have names ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; When a vector has names, it is possible to access elements by their name, in addition to their index. x[c(1, 3)] ## A C ## 1 3 x[c(&quot;A&quot;, &quot;C&quot;)] ## A C ## 1 3 3.8 Missing data As R was designed to analyze datasets, it includes the concept of missing data (which is uncommon in other programming languages). Missing data are represented in vectors as NA. When doing operations on numbers, most functions will return NA if the data you are working with include missing values. This feature makes it harder to overlook the cases where you are dealing with missing data. You can add the argument na.rm = TRUE to calculate the result while ignoring the missing values. heights &lt;- c(2, 4, 4, NA, 6) mean(heights) ## [1] NA max(heights) ## [1] NA mean(heights, na.rm = TRUE) ## [1] 4 max(heights, na.rm = TRUE) ## [1] 6 If your data include missing values, you may want to become familiar with the functions is.na(), na.omit(), and complete.cases(). See below for examples. ## Extract those elements which are not missing values. heights[!is.na(heights)] ## [1] 2 4 4 6 ## Returns the object with incomplete cases removed. ## The returned object is an atomic vector of type `&quot;numeric&quot;` ## (or `&quot;double&quot;`). na.omit(heights) ## [1] 2 4 4 6 ## attr(,&quot;na.action&quot;) ## [1] 4 ## attr(,&quot;class&quot;) ## [1] &quot;omit&quot; ## Extract those elements which are complete cases. ## The returned object is an atomic vector of type `&quot;numeric&quot;` ## (or `&quot;double&quot;`). heights[complete.cases(heights)] ## [1] 2 4 4 6 ► Question Using this vector of heights in inches, create a new vector with the NAs removed. heights &lt;- c(63, 69, 60, 65, NA, 68, 61, 70, 61, 59, 64, 69, 63, 63, NA, 72, 65, 64, 70, 63, 65) Use the function median() to calculate the median of the heights vector. Use R to figure out how many people in the set are taller than 67 inches. ► Solution heights_no_na &lt;- heights[!is.na(heights)] ## or heights_no_na &lt;- na.omit(heights) median(heights, na.rm = TRUE) ## [1] 64 heights_above_67 &lt;- heights_no_na[heights_no_na &gt; 67] length(heights_above_67) ## [1] 6 3.9 Generating vectors Constructors There exists some functions to generate vectors of different type. To generate a vector of numerics, one can use the numerics() constructor, providing the length of the output vector as parameter. The values will be initialised with 0. numeric(3) ## [1] 0 0 0 numeric(10) ## [1] 0 0 0 0 0 0 0 0 0 0 Note that if we ask for a vector of numerics of length 0, we obtain exactly that: numeric(0) ## numeric(0) There are similar constructors for characters and logicals, named character() and logical() respectively. ► Question What are the defaults for character and logical vectors? ► Solution character(2) ## the empty charater ## [1] &quot;&quot; &quot;&quot; logical(2) ## FALSE ## [1] FALSE FALSE Replicate elements The rep function allow to repeat a value a certain number of times. If we want to initiate a vector of numerics of length 5 with the value -1, for example, we could do the following: rep(-1, 5) ## [1] -1 -1 -1 -1 -1 Similarly, to generate a vector populated with missing values, which is often a good way to start, without setting assumptions on the data to be collected: rep(NA, 5) ## [1] NA NA NA NA NA rep can take vectors of any length as input (above, we used vectors of length 1) and any type. For example, if we want to repeat the values 1, 2 and 3 five times, we would do the following: rep(c(1, 2, 3), 5) ## [1] 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 ► Question What if we wanted to repeat the values 1, 2 and 3 five times, but obtain five 1s, five 2s and five 3s in that order? There are two possibilities - see ?rep or ?sort for help. ► Solution rep(c(1, 2, 3), each = 5) ## [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 sort(rep(c(1, 2, 3), 5)) ## [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 Sequence generation Another very useful function is seq, to generate a sequence of numbers. For example, to generate a sequence of integers from 1 to 20 by steps of 2, one would use: seq(from = 1, to = 20, by = 2) ## [1] 1 3 5 7 9 11 13 15 17 19 The default value of by is 1 and, given that the generate of a sequence of one value to another with steps of 1 is frequently used, there’s a shortcut: seq(1, 5, 1) ## [1] 1 2 3 4 5 seq(1, 5) ## default by ## [1] 1 2 3 4 5 1:5 ## [1] 1 2 3 4 5 To generate a sequence of numbers from 1 to 20 of final length of 3, one would use: seq(from = 1, to = 20, length.out = 3) ## [1] 1.0 10.5 20.0 Random samples and permutations A last group of useful functions are those that generate random data. The first one, sample, generates a random permutation of another vector. For example, to draw a random order to 10 students oral example, I first assign each student a number from 1 to then (for instance based on the alphabetic order of their name) and then: sample(1:10) ## [1] 9 4 7 1 2 5 3 10 6 8 Without further arguments, sample will return a permutation of all elements of the vector. If I want a random sample of a certain size, I would set this value as second argument. Below, I sample 5 random letters from the alphabet contained in the pre-defined letters vector: sample(letters, 5) ## [1] &quot;s&quot; &quot;a&quot; &quot;u&quot; &quot;x&quot; &quot;j&quot; If I wanted an output larger than the input vector, or being able to draw some elements multiple times, I would need to set the replace argument to TRUE: sample(1:5, 10, replace = TRUE) ## [1] 2 1 5 5 1 1 5 5 2 2 ► Question When trying the functions above out, you will have realised that the samples are indeed random and that one doesn’t get the same permutation twice. To be able to reproduce these random draws, one can set the random number generation seed manually with set.seed() before drawing the random sample. Test this feature with your neighbour. First draw two random permutations of 1:10 independently and observe that you get different results. Now set the seed with, for example, set.seed(123) and repeat the random draw. Observe that you now get the same random draws. Repeat by setting a different seed. ► Solution Different permutations sample(1:10) ## [1] 9 1 4 3 6 2 5 8 10 7 sample(1:10) ## [1] 4 9 7 6 1 10 8 3 2 5 Same permutations with seed 123 set.seed(123) sample(1:10) ## [1] 3 10 2 8 6 9 1 7 5 4 set.seed(123) sample(1:10) ## [1] 3 10 2 8 6 9 1 7 5 4 A different seed set.seed(1) sample(1:10) ## [1] 9 4 7 1 2 5 3 10 6 8 set.seed(1) sample(1:10) ## [1] 9 4 7 1 2 5 3 10 6 8 Drawing samples from a normal distribution The last function we are going to see is rnorm, that draws a random sample from a normal distribution. Two normal distributions of means 0 and 100 and standard deviations 1 and 5, noted noted N(0, 1) and N(100, 5), are shown below Figure 3.1: Two normal distributions: N(0, 1) on the left and N(100, 5) on the right. The three arguments, n, mean and sd, define the size of the sample, and the parameters of the normal distribution, i.e the mean and its standard deviation. The defaults of the latter are 0 and 1. rnorm(5) ## [1] 0.69641761 0.05351568 -1.31028350 -2.12306606 -0.20807859 rnorm(5, 2, 2) ## [1] 1.3744268 -0.1164714 2.8344472 1.3690969 3.6510983 rnorm(5, 100, 5) ## [1] 106.45636 96.87448 95.62427 100.71678 107.12595 Now that we have learned how to write scripts, and the basics of R’s data structures, we are ready to start working with larger data, and learn about data frames. 3.10 Additional exercises ► Question Create two vectors x and y containing the numbers 1 to 10 and 10 to 1 respectively. You can use the seq or : functions rather than constructing them by hand. Check their type. Depending how they were created, they can be integers or doubles. Take the sum (see the sum() function) of each vector and verify they are identical. Sum vectors element-wise, and verify that all results are identical. Swap the value or x and y. ► Question Create a vector named x containing the numbers 20 to 2. Retrieve elements that are strictly larger than 5 and smaller or equal than 15. Remove the first 8 elements from x and store the result in x2. ► Question You’re doing an colony counting experiment, counting every day, from Monday to Friday how many molds you see in your cell cultures. Create a vector named molds containing the results of your counts: 1, 2, 5, 8 and 10. Set the names of molds using week days and extract the number of molds identified on Wednesday. ► Question Calculate the mean of a random distribution N(15, 1) of size 100 and store it in variable m1. Calculate the mean of a random distribution N(0, 1) of size 100 and store it in variable m2. Calculate the mean of another random distribution N(15, 1) of size 1000 and store it in variable m3. Can you guess which one of m1 and m2 will be larger? Verify in R. Can you guess which one of m1 and m3 will be larger? Verify in R. ► Question Using the sample function, simulate a set of 100 students voting (randomly) for 1, 2 or 3 breaks during the WSBIM1207 course. Display the values as a table of votes. Compute the number of students that wanted more that 1 break. Bonus: as above, but setting the probability for votes to 1/5, 2/5 and 2/5 respectively. Read ?sample to find out how to do that. ► Question Given vectors v1, v2 and v3 below v1 &lt;- c(1, 2, 3, &quot;4&quot;) v2 &lt;- c(45, 23, TRUE, 21, 12, 34) v3 &lt;- c(v1, v2) What is the class of v3? What is the length of v3? Assign names \"a\", \"b\", .. to the v3. What is the value of v3[\"e\"]? Re-using v1, create a vector v4 containing [1] &quot;2&quot; &quot;1&quot; &quot;NEW&quot; &quot;3&quot; &quot;4&quot; What is the command to round 3.1234 to two decimanl digits? If you execute round(3.1234), you get 3. Why? The WSBIM1207 students were asked how many breaks they wanted during the four-hour Thursday morning sessions. The answers are stored in vectors p1 (only one break of 30 minutes), p2 (two breaks of 15 minutes) and p3 (three breaks of 10 minutes). p1 &lt;- c(1, 1, 1) names(p1) &lt;- c(&quot;A34&quot;, &quot;D3&quot;, &quot;F12&quot;) p2 &lt;- c(2, 2, 2, 2) names(p2) &lt;- c(&quot;W4&quot;, &quot;A21&quot;, &quot;K7&quot;, &quot;K8&quot;) p3 &lt;- c(3, 3, 3, 3, 3, 3, 3) names(p3) &lt;- c(&quot;D1&quot;, &quot;D2&quot;, &quot;A10&quot;, &quot;D5&quot;, &quot;D15&quot;, &quot;A16&quot;, &quot;B22&quot;) What command would you use to identify the number of respective answers? Concatenate all answers into a single vector p. What command would you use to get the vote for student D2 from vector p? ► Question Copy and paset the code chunk below to generate a vector of marks, including some students with missing values that didn’t take that test. c(student1 = 12, student2 = 11, student3 = 4, student4 = 6, student5 = 7, student6 = 8.5, student7 = 13.5, student8 = 5.5, student9 = 13.5, student10 = 2.5, student11 = 17, student12 = 18, student13 = 15, student14 = 8, student15 = 7, student16 = 12, student17 = 18.5, student18 = 7.5, student19 = 13.5, student20 = 6, student21 = 9, student22 = 16, student23 = 8.5, student24 = 9, student25 = NA, student26 = NA, student27 = 14, student28 = 16.5, student29 = 12, student30 = NA, student31 = 12.5, student32 = 3, student33 = NA, student34 = 17, student35 = 16, student36 = 9, student37 = 6, student38 = 7, student39 = 8.5, student40 = 8.5, student41 = 8, student42 = 16.5, student43 = 4.5, student44 = NA, student45 = 8, student46 = 8, student47 = 7.5, student48 = 8.5, student49 = 2, student50 = 14, student51 = 6.5, student52 = 12, student53 = 16.5, student54 = 7, student55 = 9.5, student56 = 12, student57 = 8.5, student58 = 15.5, student59 = 9, student60 = 13.5, student61 = 18, student62 = 12.5, student63 = 19.5, student64 = 13, student65 = 17.5, student66 = 8.5, student67 = 9, student68 = 7, student69 = 12.5, student70 = NA, student71 = 19, student72 = 11.5, student73 = 9, student74 = 9.5, student75 = 12, student76 = 11, student77 = 12, student78 = 14, student79 = 17, student80 = 8.5, student81 = 10, student82 = 10, student83 = NA, student84 = 10.5, student85 = 14, student86 = 7.5, student87 = 4, student88 = 9, student89 = 6.5, student90 = 10.5, student91 = 9.5, student92 = 13, student93 = 11.5, student94 = NA, student95 = 6, student96 = 12.5, student97 = 11.5, student98 = 4, student99 = 11.5, student100 = 8) What is the number of students that have a mark &gt; 10? What is the number of students that have a mark greater than the average score? "],["sec-startdata.html", "Chapter 4 Starting with data 4.1 Presentation of the gene expression data 4.2 What are data frames? 4.3 Inspecting data.frame Objects 4.4 Indexing and subsetting data frames 4.5 Factors 4.6 Matrices 4.7 Formatting Dates 4.8 Summary of R objects 4.9 Lists 4.10 Exporting and saving data 4.11 Additional exercises", " Chapter 4 Starting with data Learning Objectives Describe what a data frame is. Load external data from a .csv file into a data frame. Summarize the contents of a data frame. Describe what a factor is. Convert between strings and factors. Reorder and rename factors. Format dates. Export and save data. 4.1 Presentation of the gene expression data We are going to use part of the data published by Blackmore et al. (2017), The effect of upper-respiratory infection on transcriptomic changes in the CNS. The goal of the study was to determine the effect of an upper-respiratory infection on changes in RNA transcription occuring in the cerebellum and spinal cord post infection. Gender matched eight week old C57BL/6 mice were inoculated saline or with Influenza A by intranasal route and transcriptomic changes in the cerebellum and spinal cord tissues were evaluated by RNA-seq at days 0 (non-infected), 4 and 8. The dataset is stored as a comma separated value (CSV) file. Each row holds information for a single RNA expression measurement, and the columns represent: Column Description gene The name of the gene that was measured sample The name of the sample the gene expression was measured in expression The value of the gene expression organism The organism/species - here all data stem from mice age The age of the mouse (all mice were 8 weeks here) sex The sex of the mouse infection The infection state of the mouse, i.e. infected with Influenza A or not infected. strain The Influenza A strain; C57BL/6 in all cases. time The duration of the infection (in days). tissue The tissue that was used for the gene expression experiment, i.e. cerebellum or spinal cord. mouse The mouse unique identifier. ENTREZID The gene ID for the ENTREZ database product The gene product external_gene_name The name of the gene in the ENSEMBL database ensembl_gene_id The ID of the gene from the ENSEMBL database external_synonym A name synonym for the gene chromosome_name The chromosome name of the gene gene_biotype The gene biotype phenotype_description The phenotype description of the gene hsapiens_homolog_associated_gene_name The human homologous gene We are going to use the R function download.file() to download the CSV file that contains the gene expression data, and we will use read.csv() to load into memory the content of the CSV file as an object of class data.frame. Inside the download.file command, the first entry is a character string with the source URL. This source URL downloads a CSV file from a GitHub repository. The text after the comma (\"data/rnaseq.csv\") is the destination of the file on your local machine. You’ll need to have a folder on your machine called \"data\" where you’ll download the file. So this command downloads the remote file, names it \"rnaseq.csv\" and adds it to a preexisting folder named \"data\". if (!file.exists(&quot;data/rnaseq.csv&quot;)) download.file(url = &quot;https://raw.githubusercontent.com/UCLouvain-CBIO/WSBIM1207/scrnadata/data/rnaseq.csv&quot;, destfile = &quot;data/rnaseq.csv&quot;) You are now ready to load the data: rna &lt;- read.csv(&quot;data/rnaseq.csv&quot;) This statement doesn’t produce any output because, as you might recall, assignments don’t display anything. If we want to check that our data has been loaded, we can see the contents of the data frame by typing its name rna Wow… that was a lot of output. At least it means the data loaded properly. Let’s check the top (the first 6 lines) of this data frame using the function head(): head(rna) ## gene sample expression organism age sex infection strain time ## 1 Asl GSM2545336 1170 Mus musculus 8 Female InfluenzaA C57BL/6 8 ## 2 Apod GSM2545336 36194 Mus musculus 8 Female InfluenzaA C57BL/6 8 ## 3 Cyp2d22 GSM2545336 4060 Mus musculus 8 Female InfluenzaA C57BL/6 8 ## 4 Klk6 GSM2545336 287 Mus musculus 8 Female InfluenzaA C57BL/6 8 ## 5 Fcrls GSM2545336 85 Mus musculus 8 Female InfluenzaA C57BL/6 8 ## 6 Slc2a4 GSM2545336 782 Mus musculus 8 Female InfluenzaA C57BL/6 8 ## tissue mouse ENTREZID ## 1 Cerebellum 14 109900 ## 2 Cerebellum 14 11815 ## 3 Cerebellum 14 56448 ## 4 Cerebellum 14 19144 ## 5 Cerebellum 14 80891 ## 6 Cerebellum 14 20528 ## product ## 1 argininosuccinate lyase transcript variant X1 ## 2 apolipoprotein D transcript variant 3 ## 3 cytochrome P450 family 2 subfamily d polypeptide 22 transcript variant 2 ## 4 kallikrein related-peptidase 6 transcript variant 2 ## 5 Fc receptor-like S scavenger receptor transcript variant X1 ## 6 solute carrier family 2 (facilitated glucose transporter) member 4 ## ensembl_gene_id external_synonym chromosome_name gene_biotype ## 1 ENSMUSG00000025533 2510006M18Rik 5 protein_coding ## 2 ENSMUSG00000022548 &lt;NA&gt; 16 protein_coding ## 3 ENSMUSG00000061740 2D22 15 protein_coding ## 4 ENSMUSG00000050063 Bssp 7 protein_coding ## 5 ENSMUSG00000015852 2810439C17Rik 3 protein_coding ## 6 ENSMUSG00000018566 Glut-4 11 protein_coding ## phenotype_description ## 1 abnormal circulating amino acid level ## 2 abnormal lipid homeostasis ## 3 abnormal skin morphology ## 4 abnormal cytokine level ## 5 decreased CD8-positive alpha-beta T cell number ## 6 abnormal circulating glucose level ## hsapiens_homolog_associated_gene_name ## 1 ASL ## 2 APOD ## 3 CYP2D6 ## 4 KLK6 ## 5 FCRL4 ## 6 SLC2A4 ## Try also ## View(rna) Note read.csv() assumes that fields are delineated by commas, however, in several countries, the comma is used as a decimal separator and the semicolon (;) is used as a field delineator. If you want to read in this type of files in R, you can use the read.csv2() function. It behaves exactly like read.csv() but uses different parameters for the decimal and the field separators. If you are working with another format, they can be both specified by the user. Check out the help for read.csv() by typing ?read.csv to learn more. There is also the read.delim() for in tab separated data files. It is important to note that all of these functions are actually wrapper functions for the main read.table() function with different arguments. As such, the data above could have also been loaded by using read.table() with the separation argument as ,. The code is as follows: rna &lt;- read.table(file = &quot;data/rnaseq.csv&quot;, sep = &quot;,&quot;, quote = &quot;\\&quot;&quot;, header = TRUE) The header argument has to be set to TRUE to be able to read the headers as by default read.table() has the header argument set to FALSE. The quote argument has to be set to \"\\\"\" to only allow \" as a quoting character (see how is written the product variable for gene Rtca in rnaseq.csv). 4.2 What are data frames? Data frames are the de facto data structure for most tabular data, and what we use for statistics and plotting. A data frame can be created by hand, but most commonly they are generated by the functions read.csv() or read.table(); in other words, when importing spreadsheets from your hard drive (or the web). A data frame is the representation of data in the format of a table where the columns are vectors that all have the same length. Because columns are vectors, each column must contain a single type of data (e.g., characters, integers, factors). For example, here is a figure depicting a data frame comprising a numeric, a character, and a logical vector. We can see this when inspecting the structure of a data frame with the function str(): str(rna) ## &#39;data.frame&#39;: 32428 obs. of 19 variables: ## $ gene : chr &quot;Asl&quot; &quot;Apod&quot; &quot;Cyp2d22&quot; &quot;Klk6&quot; ... ## $ sample : chr &quot;GSM2545336&quot; &quot;GSM2545336&quot; &quot;GSM2545336&quot; &quot;GSM2545336&quot; ... ## $ expression : int 1170 36194 4060 287 85 782 1619 288 43217 1071 ... ## $ organism : chr &quot;Mus musculus&quot; &quot;Mus musculus&quot; &quot;Mus musculus&quot; &quot;Mus musculus&quot; ... ## $ age : int 8 8 8 8 8 8 8 8 8 8 ... ## $ sex : chr &quot;Female&quot; &quot;Female&quot; &quot;Female&quot; &quot;Female&quot; ... ## $ infection : chr &quot;InfluenzaA&quot; &quot;InfluenzaA&quot; &quot;InfluenzaA&quot; &quot;InfluenzaA&quot; ... ## $ strain : chr &quot;C57BL/6&quot; &quot;C57BL/6&quot; &quot;C57BL/6&quot; &quot;C57BL/6&quot; ... ## $ time : int 8 8 8 8 8 8 8 8 8 8 ... ## $ tissue : chr &quot;Cerebellum&quot; &quot;Cerebellum&quot; &quot;Cerebellum&quot; &quot;Cerebellum&quot; ... ## $ mouse : int 14 14 14 14 14 14 14 14 14 14 ... ## $ ENTREZID : int 109900 11815 56448 19144 80891 20528 97827 118454 18823 14696 ... ## $ product : chr &quot;argininosuccinate lyase transcript variant X1&quot; &quot;apolipoprotein D transcript variant 3&quot; &quot;cytochrome P450 family 2 subfamily d polypeptide 22 transcript variant 2&quot; &quot;kallikrein related-peptidase 6 transcript variant 2&quot; ... ## $ ensembl_gene_id : chr &quot;ENSMUSG00000025533&quot; &quot;ENSMUSG00000022548&quot; &quot;ENSMUSG00000061740&quot; &quot;ENSMUSG00000050063&quot; ... ## $ external_synonym : chr &quot;2510006M18Rik&quot; NA &quot;2D22&quot; &quot;Bssp&quot; ... ## $ chromosome_name : chr &quot;5&quot; &quot;16&quot; &quot;15&quot; &quot;7&quot; ... ## $ gene_biotype : chr &quot;protein_coding&quot; &quot;protein_coding&quot; &quot;protein_coding&quot; &quot;protein_coding&quot; ... ## $ phenotype_description : chr &quot;abnormal circulating amino acid level&quot; &quot;abnormal lipid homeostasis&quot; &quot;abnormal skin morphology&quot; &quot;abnormal cytokine level&quot; ... ## $ hsapiens_homolog_associated_gene_name: chr &quot;ASL&quot; &quot;APOD&quot; &quot;CYP2D6&quot; &quot;KLK6&quot; ... 4.3 Inspecting data.frame Objects We already saw how the functions head() and str() can be useful to check the content and the structure of a data frame. Here is a non-exhaustive list of functions to get a sense of the content/structure of the data. Let’s try them out! Size: dim(rna) - returns a vector with the number of rows in the first element, and the number of columns as the second element (the dimensions of the object) nrow(rna) - returns the number of rows ncol(rna) - returns the number of columns Content: head(rna) - shows the first 6 rows tail(rna) - shows the last 6 rows Names: names(rna) - returns the column names (synonym of colnames() for data.frame objects) rownames(rna) - returns the row names Summary: str(rna) - structure of the object and information about the class, length and content of each column summary(rna) - summary statistics for each column Note: most of these functions are “generic,” they can be used on other types of objects besides data.frame. ► Question Based on the output of str(rna), can you answer the following questions? What is the class of the object rna? How many rows and how many columns are in this object? How many genes (as defined by the gene variable) have been measured in this experiment? ► Solution class: data frame how many rows: 32428, how many columns: 21 how many genes: 1474 4.4 Indexing and subsetting data frames Our rna data frame has rows and columns (it has 2 dimensions), if we want to extract some specific data from it, we need to specify the “coordinates” we want from it. Row numbers come first, followed by column numbers. However, note that different ways of specifying these coordinates lead to results with different classes. # first element in the first column of the data frame (as a vector) rna[1, 1] # first element in the 6th column (as a vector) rna[1, 6] # first column of the data frame (as a vector) rna[, 1] # first column of the data frame (as a data.frame) rna[1] # first three elements in the 7th column (as a vector) rna[1:3, 7] # the 3rd row of the data frame (as a data.frame) rna[3, ] # equivalent to head_rna &lt;- head(rna) head_rna &lt;- rna[1:6, ] head_rna : is a special function that creates numeric vectors of integers in increasing or decreasing order, test 1:10 and 10:1 for instance. See section 3.9 for details. You can also exclude certain indices of a data frame using the “-” sign: rna[, -1] ## The whole data frame, except the first column rna[-c(7:32428), ] ## Equivalent to head(surveys) Data frames can be subset by calling indices (as shown previously), but also by calling their column names directly: rna[&quot;gene&quot;] # Result is a data.frame rna[, &quot;gene&quot;] # Result is a vector rna[[&quot;gene&quot;]] # Result is a vector rna$gene # Result is a vector In RStudio, you can use the autocompletion feature to get the full and correct names of the columns. When we inspect the elements of the column hsapiens_homolog_associated_gene_name (for example with View(rna)), we can see that some cells contain NA values. If we wanted to extract only mouse genes of this table that have a human homologous, we could combine is.na() and data frames subsetting: is_missing_hsapiens_homolog &lt;- is.na(rna$hsapiens_homolog_associated_gene_name) rna_hsapiens_homolog &lt;- rna[!is_missing_hsapiens_homolog,] head(rna_hsapiens_homolog) ► Question How many mouse genes do not have a human homologous? ► Solution rna_missing_hsapiens_homolog &lt;- rna[is_missing_hsapiens_homolog,] nrow(rna_missing_hsapiens_homolog) ## [1] 4774 ► Question Create a data.frame (rna_200) containing only the data in row 200 of the rna dataset. Notice how nrow() gave you the number of rows in a data.frame? Use that number to pull out just that last row in the inital rna data frame. Compare that with what you see as the last row using tail() to make sure it’s meeting expectations. Pull out that last row using nrow() instead of the row number. Create a new data frame (rna_last) from that last row. Use nrow() to extract the row that is in the middle of the rna dataframe. Store the content of this row in an object named rna_middle. Combine nrow() with the - notation above to reproduce the behavior of head(rna), keeping just the first through 6th rows of the rna dataset. ► Solution ## 1. rna_200 &lt;- rna[200, ] ## 2. ## Saving `n_rows` to improve readability and reduce duplication n_rows &lt;- nrow(rna) rna_last &lt;- rna[n_rows, ] ## 3. rna_middle &lt;- rna[n_rows / 2, ] ## 4. rna_head &lt;- rna[-(7:n_rows), ] 4.5 Factors Factors represent categorical data. They are stored as integers associated with labels and they can be ordered or unordered. While factors look (and often behave) like character vectors, they are actually treated as integer vectors by R. So you need to be very careful when treating them as strings. Once created, factors can only contain a pre-defined set of values, known as levels. By default, R always sorts levels in alphabetical order. For instance, if you have a factor with 2 levels: sex &lt;- factor(c(&quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;female&quot;)) R will assign 1 to the level \"female\" and 2 to the level \"male\" (because f comes before m, even though the first element in this vector is \"male\"). You can see this by using the function levels() and you can find the number of levels using nlevels(): levels(sex) ## [1] &quot;female&quot; &quot;male&quot; nlevels(sex) ## [1] 2 Sometimes, the order of the factors does not matter, other times you might want to specify the order because it is meaningful (e.g., “low,” “medium,” “high”), it improves your visualization, or it is required by a particular type of analysis. Here, one way to reorder our levels in the sex vector would be: sex ## current order ## [1] male female female male female ## Levels: female male sex &lt;- factor(sex, levels = c(&quot;male&quot;, &quot;female&quot;)) sex ## after re-ordering ## [1] male female female male female ## Levels: male female In R’s memory, these factors are represented by integers (1, 2, 3), but are more informative than integers because factors are self describing: \"female\", \"male\" is more descriptive than 1, 2. Which one is “male?” You wouldn’t be able to tell just from the integer data. Factors, on the other hand, have this information built in. It is particularly helpful when there are many levels (like the species names in our example dataset). Converting to factors If you need to convert a factor to a character vector, you use as.character(x). as.character(sex) ## [1] &quot;male&quot; &quot;female&quot; &quot;female&quot; &quot;male&quot; &quot;female&quot; Renaming factors When your data is stored as a factor, you can use the plot() function to get a quick glance at the number of observations represented by each factor level. Let’s look at the number of males and females in our data. plot(sex) Figure 4.1: Bar plot of the number of females and males. If we want to rename these factor, it is sufficient to change its levels: levels(sex) ## [1] &quot;male&quot; &quot;female&quot; levels(sex) &lt;- c(&quot;M&quot;, &quot;F&quot;) sex ## [1] M F F M F ## Levels: M F plot(sex) ► Question Rename “female” and “male” to “Female” and “Male” respectively. ► Question We have seen how data frames are created when using read.csv(), but they can also be created by hand with the data.frame() function. There are a few mistakes in this hand-crafted data.frame. Can you spot and fix them? Don’t hesitate to experiment! animal_data &lt;- data.frame( animal = c(dog, cat, sea cucumber, sea urchin), feel = c(&quot;furry&quot;, &quot;squishy&quot;, &quot;spiny&quot;), weight = c(45, 8 1.1, 0.8)) ► Solution missing quotations around the names of the animals missing one entry in the “feel” column (probably for one of the furry animals) missing one comma in the weight column ► Question Can you predict the class for each of the columns in the following example? Check your guesses using str(country_climate): Are they what you expected? Why? Why not? Try again by adding stringsAsFactors = TRUE after the last variable when creating the data frame? What is happening now? stringsAsFactors can also be set when reading text-based spreadsheets into R using read.csv(). country_climate &lt;- data.frame( country = c(&quot;Canada&quot;, &quot;Panama&quot;, &quot;South Africa&quot;, &quot;Australia&quot;), climate = c(&quot;cold&quot;, &quot;hot&quot;, &quot;temperate&quot;, &quot;hot/temperate&quot;), temperature = c(10, 30, 18, &quot;15&quot;), northern_hemisphere = c(TRUE, TRUE, FALSE, &quot;FALSE&quot;), has_kangaroo = c(FALSE, FALSE, FALSE, 1) ) The automatic conversion of data type is sometimes a blessing, sometimes an annoyance. Be aware that it exists, learn the rules, and double check that data you import in R are of the correct type within your data frame. If not, use it to your advantage to detect mistakes that might have been introduced during data entry (a letter in a column that should only contain numbers for instance). Learn more in this RStudio tutorial 4.6 Matrices Before proceeding, now that we have learnt about dataframes, let’s recap package installation and learn about a new data type, namely the matrix. Like a data.frame, a matrix has two dimensions, rows and columns. But the major difference is that all cells in a matrix must be of the same type: numeric, character, logical, … In that respect, matrices are closer to a vector than a data.frame. The default constructor for a matrix is matrix. It takes a vector of values to populate the matrix and the number of row and/or columns8. The values are sorted along the columns, as illustrated below. m &lt;- matrix(1:9, ncol = 3, nrow = 3) m ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 ► Question Using the function installed.packages(), create a character matrix containing the information about all packages currently installed on your computer. Explore it. ► Solution ## create the matrix ip &lt;- installed.packages() head(ip) ## try also View(ip) ## number of package nrow(ip) ## names of all installed packages rownames(ip) ## type of information we have about each package colnames(ip) It is often useful to create large random data matrices as test data. The exercise below asks you to create such a matrix with random data drawn from a normal distribution of mean 0 and standard deviation 1, which can be done with the rnorm() function. ► Question Construct a matrix of dimension 1000 by 3 of normally distributed data (mean 0, standard deviation 1). ► Solution set.seed(123) m &lt;- matrix(rnorm(3000), ncol = 3) dim(m) ## [1] 1000 3 head(m) ## [,1] [,2] [,3] ## [1,] -0.56047565 -0.99579872 -0.5116037 ## [2,] -0.23017749 -1.03995504 0.2369379 ## [3,] 1.55870831 -0.01798024 -0.5415892 ## [4,] 0.07050839 -0.13217513 1.2192276 ## [5,] 0.12928774 -2.54934277 0.1741359 ## [6,] 1.71506499 1.04057346 -0.6152683 4.7 Formatting Dates One of the most common issues that new (and experienced!) R users have is converting date and time information into a variable that is appropriate and usable during analyses. Note on dates in spreadsheet programs Dates in spreadsheets are generally stored in a single column. While this seems the most natural way to record dates, it actually is not best practice. A spreadsheet application will display the dates in a seemingly correct way (to a human observer) but how it actually handles and stores the dates may be problematic. It is often much safer to store dates with YEAR, MONTH and DAY in separate columns or as YEAR and DAY-OF-YEAR in separate columns. Spreadsheet programs such as LibreOffice, Microsoft Excel, OpenOffice, Gnumeric, … have different (and often incompatible) ways of encoding dates (even for the same program between versions and operating systems). Additionally, Excel can turn things that aren’t dates into dates (Zeeberg et al. (2004)), for example names or identifiers like MAR1, DEC1, OCT4. So if you’re avoiding the date format overall, it’s easier to identify these issues. The Dates as data section of the Data Carpentry lesson provides additional insights about pitfalls of dates with spreadsheets. We are going to use the ymd() function from the package lubridate (which belongs to the tidyverse; learn more here). . lubridate gets installed as part as the tidyverse installation. When you load the tidyverse (library(tidyverse)), the core packages (the packages used in most data analyses) get loaded. lubridate however does not belong to the core tidyverse, so you have to load it explicitly with library(lubridate) Start by loading the required package: library(&quot;lubridate&quot;) ymd() takes a vector representing year, month, and day, and converts it to a Date vector. Date is a class of data recognized by R as being a date and can be manipulated as such. The argument that the function requires is flexible, but, as a best practice, is a character vector formatted as “YYYY-MM-DD.” Let’s create a date object and inspect the structure: my_date &lt;- ymd(&quot;2015-01-01&quot;) str(my_date) ## Date[1:1], format: &quot;2015-01-01&quot; Now let’s paste the year, month, and day separately - we get the same result: # sep indicates the character to use to separate each component my_date &lt;- ymd(paste(&quot;2015&quot;, &quot;1&quot;, &quot;1&quot;, sep = &quot;-&quot;)) str(my_date) ## Date[1:1], format: &quot;2015-01-01&quot; Let’s now familiarise ourselves with a typical date manipulation pipeline. The small data below has stored dates in different year, month and day columns. x &lt;- data.frame(year = c(1996, 1992, 1987, 1986, 2000, 1990, 2002, 1994, 1997, 1985), month = c(2, 3, 3, 10, 1, 8, 3, 4, 5, 5), day = c(24, 8, 1, 5, 8, 17, 13, 10, 11, 24), value = c(4, 5, 1, 9, 3, 8, 10, 2, 6, 7)) x ## year month day value ## 1 1996 2 24 4 ## 2 1992 3 8 5 ## 3 1987 3 1 1 ## 4 1986 10 5 9 ## 5 2000 1 8 3 ## 6 1990 8 17 8 ## 7 2002 3 13 10 ## 8 1994 4 10 2 ## 9 1997 5 11 6 ## 10 1985 5 24 7 Now we apply this function to the x dataset. We first dreate a character vector from the year, month, and day columns of x using paste(): paste(x$year, x$month, x$day, sep = &quot;-&quot;) ## [1] &quot;1996-2-24&quot; &quot;1992-3-8&quot; &quot;1987-3-1&quot; &quot;1986-10-5&quot; &quot;2000-1-8&quot; &quot;1990-8-17&quot; ## [7] &quot;2002-3-13&quot; &quot;1994-4-10&quot; &quot;1997-5-11&quot; &quot;1985-5-24&quot; This character vector can be used as the argument for ymd(): ymd(paste(x$year, x$month, x$day, sep = &quot;-&quot;)) ## [1] &quot;1996-02-24&quot; &quot;1992-03-08&quot; &quot;1987-03-01&quot; &quot;1986-10-05&quot; &quot;2000-01-08&quot; ## [6] &quot;1990-08-17&quot; &quot;2002-03-13&quot; &quot;1994-04-10&quot; &quot;1997-05-11&quot; &quot;1985-05-24&quot; The resulting Date vector can be added to x as a new column called date: x$date &lt;- ymd(paste(x$year, x$month, x$day, sep = &quot;-&quot;)) str(x) # notice the new column, with &#39;date&#39; as the class ## &#39;data.frame&#39;: 10 obs. of 5 variables: ## $ year : num 1996 1992 1987 1986 2000 ... ## $ month: num 2 3 3 10 1 8 3 4 5 5 ## $ day : num 24 8 1 5 8 17 13 10 11 24 ## $ value: num 4 5 1 9 3 8 10 2 6 7 ## $ date : Date, format: &quot;1996-02-24&quot; &quot;1992-03-08&quot; ... Let’s make sure everything worked correctly. One way to inspect the new column is to use summary(): summary(x$date) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## &quot;1985-05-24&quot; &quot;1988-01-11&quot; &quot;1993-03-24&quot; &quot;1993-03-18&quot; &quot;1997-01-20&quot; &quot;2002-03-13&quot; Note that ymd() expects to have the year, month and day, in that order. If you have for instance day, month and year, you would need dmy(). dmy(paste(x$day, x$month, x$month, sep = &quot;-&quot;)) ## [1] &quot;2002-02-24&quot; &quot;2003-03-08&quot; &quot;2003-03-01&quot; &quot;2010-10-05&quot; &quot;2001-01-08&quot; ## [6] &quot;2008-08-17&quot; &quot;2003-03-13&quot; &quot;2004-04-10&quot; &quot;2005-05-11&quot; &quot;2005-05-24&quot; lubdridate has many functions to address all date variations. 4.8 Summary of R objects So far, we have seen several types of R object varying in the number of dimensions and whether they could store a single of multiple data types: vector: one dimension (they have a length), single type of data. matrix: two dimensions, single type of data. data.frame: two dimensions, one type per column. 4.9 Lists A data type that we haven’t seen yet, but that is useful to know, and follows from the summary that we have just seen are lists: list: one dimension, every item can be of a different data type. Below, let’s create a list containing a vector of numbers, characters, a matrix, a dataframe and another list: l &lt;- list(1:10, ## numeric letters, ## character installed.packages(), ## a matrix cars, ## a data.frame list(1, 2, 3)) ## a list length(l) ## [1] 5 str(l) ## List of 5 ## $ : int [1:10] 1 2 3 4 5 6 7 8 9 10 ## $ : chr [1:26] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; ... ## $ : chr [1:574, 1:16] &quot;ALL&quot; &quot;ALS&quot; &quot;AnnotationDbi&quot; &quot;AnnotationFilter&quot; ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:574] &quot;ALL&quot; &quot;ALS&quot; &quot;AnnotationDbi&quot; &quot;AnnotationFilter&quot; ... ## .. ..$ : chr [1:16] &quot;Package&quot; &quot;LibPath&quot; &quot;Version&quot; &quot;Priority&quot; ... ## $ :&#39;data.frame&#39;: 50 obs. of 2 variables: ## ..$ speed: num [1:50] 4 4 7 7 8 9 10 10 10 11 ... ## ..$ dist : num [1:50] 2 10 4 22 16 10 18 26 34 17 ... ## $ :List of 3 ## ..$ : num 1 ## ..$ : num 2 ## ..$ : num 3 List subsetting is done using [] to subset a new sub-list or [[]] to extract a single element of that list (using indices or names, of the list is named). l[[1]] ## first element ## [1] 1 2 3 4 5 6 7 8 9 10 l[1:2] ## a list of length 2 ## [[1]] ## [1] 1 2 3 4 5 6 7 8 9 10 ## ## [[2]] ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;j&quot; &quot;k&quot; &quot;l&quot; &quot;m&quot; &quot;n&quot; &quot;o&quot; &quot;p&quot; &quot;q&quot; &quot;r&quot; &quot;s&quot; ## [20] &quot;t&quot; &quot;u&quot; &quot;v&quot; &quot;w&quot; &quot;x&quot; &quot;y&quot; &quot;z&quot; l[1] ## a list of length 1 ## [[1]] ## [1] 1 2 3 4 5 6 7 8 9 10 4.10 Exporting and saving data Exporting tabular data We have seen how to read a text-based spreadsheet into R using the read.table family of functions. To export a data.frame to a text-based spreadsheet, we can use the write.table set of functions (write.csv, write.delim, …). They all take the variable to be exported and the file to be exported to. For example, to export the rna data to the my_rnaseq.csv file in the data_output directory, we would execute: write.csv(rna, file = &quot;data_output/my_rnaseq.csv&quot;) This new csv file can now be shared with other collaborators who aren’t familiar with R. Saving data Exporting data to a spreadsheet has several limitations, such as those described in the first chapter such as possible inconsistencies with , and . for decimal separators and lack of variable type definitions. Furthermore, exporting data to a spreadsheet is only relevant for rectangular data such as dataframes and matrices. A more general way to save data, that is specific to R and is guaranteed to work on any operating system, is to use the save function. Saving objects will generate a binary representation of the object on disk, a R Data file (rda extension) that guarantees to produce the same object once loaded back into R using the load function. save(rna, file = &quot;data_output/rnaseq.rda&quot;) rm(rna) load(&quot;data_output/rnaseq.rda&quot;) head(rna) Note about how the function load loads the object in the file directly in the global environment. There is also the saveRDS and readRDS functions that save R objects to binary files (using the rds extension here) and read these back into R. From a user’s perspective, main different is that, load loads an object in the global environment while readRDS reads the data from disk and returns it. It is this necessary to store the output of readRDS in a variable: saveRDS(rna, file = &quot;data_output/rnaseq.rds&quot;) rm(rna) rna &lt;- readRDS(&quot;data_output/rnaseq.rds&quot;) head(rna) ## gene sample expression organism age sex infection strain time ## 1 Asl GSM2545336 1170 Mus musculus 8 Female InfluenzaA C57BL/6 8 ## 2 Apod GSM2545336 36194 Mus musculus 8 Female InfluenzaA C57BL/6 8 ## 3 Cyp2d22 GSM2545336 4060 Mus musculus 8 Female InfluenzaA C57BL/6 8 ## 4 Klk6 GSM2545336 287 Mus musculus 8 Female InfluenzaA C57BL/6 8 ## 5 Fcrls GSM2545336 85 Mus musculus 8 Female InfluenzaA C57BL/6 8 ## 6 Slc2a4 GSM2545336 782 Mus musculus 8 Female InfluenzaA C57BL/6 8 ## tissue mouse ENTREZID ## 1 Cerebellum 14 109900 ## 2 Cerebellum 14 11815 ## 3 Cerebellum 14 56448 ## 4 Cerebellum 14 19144 ## 5 Cerebellum 14 80891 ## 6 Cerebellum 14 20528 ## product ## 1 argininosuccinate lyase transcript variant X1 ## 2 apolipoprotein D transcript variant 3 ## 3 cytochrome P450 family 2 subfamily d polypeptide 22 transcript variant 2 ## 4 kallikrein related-peptidase 6 transcript variant 2 ## 5 Fc receptor-like S scavenger receptor transcript variant X1 ## 6 solute carrier family 2 (facilitated glucose transporter) member 4 ## ensembl_gene_id external_synonym chromosome_name gene_biotype ## 1 ENSMUSG00000025533 2510006M18Rik 5 protein_coding ## 2 ENSMUSG00000022548 &lt;NA&gt; 16 protein_coding ## 3 ENSMUSG00000061740 2D22 15 protein_coding ## 4 ENSMUSG00000050063 Bssp 7 protein_coding ## 5 ENSMUSG00000015852 2810439C17Rik 3 protein_coding ## 6 ENSMUSG00000018566 Glut-4 11 protein_coding ## phenotype_description ## 1 abnormal circulating amino acid level ## 2 abnormal lipid homeostasis ## 3 abnormal skin morphology ## 4 abnormal cytokine level ## 5 decreased CD8-positive alpha-beta T cell number ## 6 abnormal circulating glucose level ## hsapiens_homolog_associated_gene_name ## 1 ASL ## 2 APOD ## 3 CYP2D6 ## 4 KLK6 ## 5 FCRL4 ## 6 SLC2A4 To conclude, when it comes to saving data from R that will be loaded again in R, saving and loading is the preferred approach. If tabular data need to be shared with somebody that is not using R, then exporting to a text-based spreadsheet is a good alternative. 4.11 Additional exercises ► Question You’re doing an colony counting experiment, counting every day how many molds you see in your cell cultures. Create a vector named molds containing the results of your counts: 1, 2, 5, 8 and 10. Create a vector days containing the week day, from Monday to Friday. Use these two vector to create a data.frame named molds_study containing two variables, Day and Molds_count. Create a new data.frame that contains the observations where more than 2 colonies were counted. How many observations are there? How many counts are there in total for these observations. You repeat the molds study experiment the following week and count the following numbers of molds: 1, 6, 6, 5 and 4. Add these data as a third column to the molds_study data.frame and rename the variables as Day, Molds_1 and Molds_2. Calculate for each experiment the total number of molds counted. Check if the first experiment counted more molds than the second one. Save the molds_study variable in a file named molds_study.rda. ► Question We are going to analyse beer consumption in 48 individuals. The data are available in the rWSBIM1207 package. The data illustrated the fictive beer consumption in liters per year at different age according to gender and employment. Load the rWSBIM1207 package. If the package isn’t installed of its version is greater than 0.1.1, install it from the UCLouvain-CBIO/rWSBIM1207 GitHub repository using the remotes::install_github() function. If you use a recent Renku enironment, the package is already available. Using the beers.csv() function from rWSBIM1207, find the path the beers.csv file and read it to produce a data.frame named beers. The spreadsheet uses semi-colons ; to separate cells. Use read.csv2() and read.delim() and set the separator appropriately, and verify that the two variables are identical. Check the number of observations and identify the variables that are available. Calculate a summary of each variable using the summary function directly on the data.frame. Calculate the mean and the median age and consumption. Do men consume more beer than women on average? To answer this question, calculate the mean consumption for men only, selecting the observations with Gender equal to Male. Then do the same for observations with Gender equal to Female. Calculate a two-way table of gender and employment status. Remove observations with missing values and export the data into a new csv file called beers_no_na.csv. ► Question We are going to analyse clinical data from The Cancer Genome Atlas (TCGA). The data are available in the rWSBIM1207 package. Load the rWSBIM1207 package. If the package isn’t installed of its version is greater than 0.1.1, install it from the UCLouvain-CBIO/rWSBIM1207 GitHub repository using the remotes::install_github() function. If you use a recent Renku enironment, the package is already available. Obtain the path to th csv file containing the clinical data need for this exercise using the clinical1.csv function and read it into R as a data.frame called clinical. Inspect the data using str and View. How many patients are recorded in the table? Print the column names using two different functions. Create a smaller data frame called clinical_mini containing only the columns corresponding to the patientID, gender, age_at_diagnosis and smoking_history. Try to do this using column indices and column names. Inspect the smoking_history column. How many categories are recorded? How many observations are there for each category? The column age at diagnosis is recorded in days. Create a new column years_at_diagnosis corresponding to the age at diagnosis converted in years. Calculate the mean and median age at diagnosis. Hint: pay attention to missing values! Is there a difference between the years_at_diagnosis for male and female patients? Use the quantile function to calculate the first and last quartile of age at diagnosis. Use the help function (?quantile) to see how to use the quantile function. Use the summary function to confirm your previous results. Either the number of rows or columns are enough, as the other one can be deduced from the length of the values. Try out what happens if the values and number of rows/columns don’t add up.↩︎ "],["sec-dplyr.html", "Chapter 5 Manipulating and analyzing data with dplyr 5.1 Data Manipulation using dplyr and tidyr 5.2 What are dplyr and tidyr? 5.3 Selecting columns and filtering rows 5.4 Pipes 5.5 Mutate 5.6 Split-apply-combine data analysis 5.7 Reshaping data 5.8 Exporting data 5.9 Additional exercises", " Chapter 5 Manipulating and analyzing data with dplyr Learning Objectives Describe the purpose of the dplyr and tidyr packages. Select certain columns in a data frame with the dplyr function select. Select certain rows in a data frame according to filtering conditions with the dplyr function filter . Link the output of one dplyr function to the input of another function with the ‘pipe’ operator %&gt;%. Add new columns to a data frame that are functions of existing columns with mutate. Use the split-apply-combine concept for data analysis. Use summarize, group_by, and count to split a data frame into groups of observations, apply summary statistics for each group, and then combine the results. Describe the concept of a wide and a long table format and for which purpose those formats are useful. Reshape a data frame from long to wide format and back with the pivot_wider() and pivot_longer() commands from the tidyr package. 5.1 Data Manipulation using dplyr and tidyr Bracket subsetting is handy, but it can be cumbersome and difficult to read, especially for complicated operations. Enter dplyr. dplyr is a package for making tabular data manipulation easier. It pairs nicely with tidyr which enables you to swiftly convert between different data formats for plotting and analysis. Packages in R are basically sets of additional functions that let you do more stuff. The functions we’ve been using so far, like str() or data.frame(), come built into R; packages give you access to more of them. Before you use a package for the first time you need to install it on your machine, and then you should import it in every subsequent R session when you need it. You should already have installed the tidyverse package. This is an “umbrella-package” that installs several packages useful for data analysis which work together well such as tidyr, dplyr, ggplot2, tibble, etc. The tidyverse package tries to address 3 common issues that arise when doing data analysis with some of functions that come with R: The results from a base R function sometimes depend on the type of data. Using R expressions in a non standard way, which can be confusing for new learners. Hidden arguments, having default operations that new learners are not aware of. We have seen in our previous lesson that when building or importing a data frame, the columns that contain characters (i.e., text) are coerced (=converted) into the factor data type. We had to set stringsAsFactors to FALSE to avoid this hidden argument to convert our data type. This time will use the tidyverse package to read the data and avoid having to set stringsAsFactors to FALSE To load the package type: ## load the tidyverse packages, incl. dplyr library(&quot;tidyverse&quot;) The Data Transformation Cheat Sheet provides an overview of the dplyr grammar, offering more details and functions that we will see in this chapter. 5.2 What are dplyr and tidyr? The package dplyr provides easy tools for the most common data manipulation tasks. It is built to work directly with data frames, with many common tasks optimized by being written in a compiled language (C++). An additional feature is the ability to work directly with data stored in an external database. The benefits of doing this are that the data can be managed natively in a relational database, queries can be conducted on that database, and only the results of the query are returned. This addresses a common problem with R in that all operations are conducted in-memory and thus the amount of data you can work with is limited by available memory. The database connections essentially remove that limitation in that you can connect to a database of many hundreds of GB, conduct queries on it directly, and pull back into R only what you need for analysis. The package tidyr addresses the common problem of wanting to reshape your data for plotting and use by different R functions. Sometimes we want data sets where we have one row per measurement. Sometimes we want a data frame where each measurement type has its own column, and rows are instead more aggregated groups - like plots or aquaria. Moving back and forth between these formats is nontrivial, and tidyr gives you tools for this and more sophisticated data manipulation. To learn more about dplyr and tidyr after the workshop, you may want to check out this handy data transformation with dplyr cheatsheet and this one about tidyr. We’ll read in our data using the read_csv() function, from the tidyverse package readr, instead of read.csv(). rna &lt;- read_csv(&quot;data/rnaseq.csv&quot;) ## Rows: 32428 Columns: 19 ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (14): gene, sample, organism, sex, infection, strain, tissue, product, e... ## dbl (5): expression, age, time, mouse, ENTREZID ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ## inspect the data str(rna) ## preview the data # View(rna) Notice that the class of the data is now tbl_df This is referred to as a “tibble.” Tibbles tweak some of the behaviors of the data frame objects we introduced in the previous episode. The data structure is very similar to a data frame. For our purposes the only differences are that: In addition to displaying the data type of each column under its name, it only prints the first few rows of data and only as many columns as fit on one screen. Columns of class character are never converted into factors. We’re going to learn some of the most common dplyr functions: select(): subset columns filter(): subset rows on conditions mutate(): create new columns by using information from other columns group_by() and summarize(): create summary statisitcs on grouped data arrange(): sort results count(): count discrete values 5.3 Selecting columns and filtering rows To select columns of a data frame, use select(). The first argument to this function is the data frame (rna), and the subsequent arguments are the columns to keep. select(rna, gene, sample, tissue, expression) ## # A tibble: 32,428 × 4 ## gene sample tissue expression ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Asl GSM2545336 Cerebellum 1170 ## 2 Apod GSM2545336 Cerebellum 36194 ## 3 Cyp2d22 GSM2545336 Cerebellum 4060 ## 4 Klk6 GSM2545336 Cerebellum 287 ## 5 Fcrls GSM2545336 Cerebellum 85 ## 6 Slc2a4 GSM2545336 Cerebellum 782 ## 7 Exd2 GSM2545336 Cerebellum 1619 ## 8 Gjc2 GSM2545336 Cerebellum 288 ## 9 Plp1 GSM2545336 Cerebellum 43217 ## 10 Gnb4 GSM2545336 Cerebellum 1071 ## # … with 32,418 more rows To select all columns except certain ones, put a “-” in front of the variable to exclude it. select(rna, -organism, -strain) ## # A tibble: 32,428 × 17 ## gene sample expression age sex infection time tissue mouse ENTREZID ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asl GSM2545336 1170 8 Female Influenz… 8 Cereb… 14 109900 ## 2 Apod GSM2545336 36194 8 Female Influenz… 8 Cereb… 14 11815 ## 3 Cyp2d22 GSM2545336 4060 8 Female Influenz… 8 Cereb… 14 56448 ## 4 Klk6 GSM2545336 287 8 Female Influenz… 8 Cereb… 14 19144 ## 5 Fcrls GSM2545336 85 8 Female Influenz… 8 Cereb… 14 80891 ## 6 Slc2a4 GSM2545336 782 8 Female Influenz… 8 Cereb… 14 20528 ## 7 Exd2 GSM2545336 1619 8 Female Influenz… 8 Cereb… 14 97827 ## 8 Gjc2 GSM2545336 288 8 Female Influenz… 8 Cereb… 14 118454 ## 9 Plp1 GSM2545336 43217 8 Female Influenz… 8 Cereb… 14 18823 ## 10 Gnb4 GSM2545336 1071 8 Female Influenz… 8 Cereb… 14 14696 ## # … with 32,418 more rows, and 7 more variables: product &lt;chr&gt;, ## # ensembl_gene_id &lt;chr&gt;, external_synonym &lt;chr&gt;, chromosome_name &lt;chr&gt;, ## # gene_biotype &lt;chr&gt;, phenotype_description &lt;chr&gt;, ## # hsapiens_homolog_associated_gene_name &lt;chr&gt; This will select all the variables in rna except organism and strain. To choose rows based on a specific criteria, use filter(): filter(rna, sex == &quot;Male&quot;) ## # A tibble: 14,740 × 19 ## gene sample expression organism age sex infection strain time tissue ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Asl GSM254… 626 Mus mus… 8 Male Influenz… C57BL… 4 Cereb… ## 2 Apod GSM254… 13021 Mus mus… 8 Male Influenz… C57BL… 4 Cereb… ## 3 Cyp2d22 GSM254… 2171 Mus mus… 8 Male Influenz… C57BL… 4 Cereb… ## 4 Klk6 GSM254… 448 Mus mus… 8 Male Influenz… C57BL… 4 Cereb… ## 5 Fcrls GSM254… 180 Mus mus… 8 Male Influenz… C57BL… 4 Cereb… ## 6 Slc2a4 GSM254… 313 Mus mus… 8 Male Influenz… C57BL… 4 Cereb… ## 7 Exd2 GSM254… 2366 Mus mus… 8 Male Influenz… C57BL… 4 Cereb… ## 8 Gjc2 GSM254… 310 Mus mus… 8 Male Influenz… C57BL… 4 Cereb… ## 9 Plp1 GSM254… 53126 Mus mus… 8 Male Influenz… C57BL… 4 Cereb… ## 10 Gnb4 GSM254… 1355 Mus mus… 8 Male Influenz… C57BL… 4 Cereb… ## # … with 14,730 more rows, and 9 more variables: mouse &lt;dbl&gt;, ENTREZID &lt;dbl&gt;, ## # product &lt;chr&gt;, ensembl_gene_id &lt;chr&gt;, external_synonym &lt;chr&gt;, ## # chromosome_name &lt;chr&gt;, gene_biotype &lt;chr&gt;, phenotype_description &lt;chr&gt;, ## # hsapiens_homolog_associated_gene_name &lt;chr&gt; filter(rna, sex == &quot;Male&quot; &amp; infection == &quot;NonInfected&quot;) ## # A tibble: 4,422 × 19 ## gene sample expression organism age sex infection strain time tissue ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Asl GSM254… 535 Mus mus… 8 Male NonInfec… C57BL… 0 Cereb… ## 2 Apod GSM254… 13668 Mus mus… 8 Male NonInfec… C57BL… 0 Cereb… ## 3 Cyp2d22 GSM254… 2008 Mus mus… 8 Male NonInfec… C57BL… 0 Cereb… ## 4 Klk6 GSM254… 1101 Mus mus… 8 Male NonInfec… C57BL… 0 Cereb… ## 5 Fcrls GSM254… 375 Mus mus… 8 Male NonInfec… C57BL… 0 Cereb… ## 6 Slc2a4 GSM254… 249 Mus mus… 8 Male NonInfec… C57BL… 0 Cereb… ## 7 Exd2 GSM254… 3126 Mus mus… 8 Male NonInfec… C57BL… 0 Cereb… ## 8 Gjc2 GSM254… 791 Mus mus… 8 Male NonInfec… C57BL… 0 Cereb… ## 9 Plp1 GSM254… 98658 Mus mus… 8 Male NonInfec… C57BL… 0 Cereb… ## 10 Gnb4 GSM254… 2437 Mus mus… 8 Male NonInfec… C57BL… 0 Cereb… ## # … with 4,412 more rows, and 9 more variables: mouse &lt;dbl&gt;, ENTREZID &lt;dbl&gt;, ## # product &lt;chr&gt;, ensembl_gene_id &lt;chr&gt;, external_synonym &lt;chr&gt;, ## # chromosome_name &lt;chr&gt;, gene_biotype &lt;chr&gt;, phenotype_description &lt;chr&gt;, ## # hsapiens_homolog_associated_gene_name &lt;chr&gt; 5.4 Pipes What if you want to select and filter at the same time? There are three ways to do this: use intermediate steps, nested functions, or pipes. With intermediate steps, you create a temporary data frame and use that as input to the next function, like this: rna2 &lt;- filter(rna, sex == &quot;Male&quot;) rna3 &lt;- select(rna2, gene, sample, tissue, expression) rna3 ## # A tibble: 14,740 × 4 ## gene sample tissue expression ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Asl GSM2545340 Cerebellum 626 ## 2 Apod GSM2545340 Cerebellum 13021 ## 3 Cyp2d22 GSM2545340 Cerebellum 2171 ## 4 Klk6 GSM2545340 Cerebellum 448 ## 5 Fcrls GSM2545340 Cerebellum 180 ## 6 Slc2a4 GSM2545340 Cerebellum 313 ## 7 Exd2 GSM2545340 Cerebellum 2366 ## 8 Gjc2 GSM2545340 Cerebellum 310 ## 9 Plp1 GSM2545340 Cerebellum 53126 ## 10 Gnb4 GSM2545340 Cerebellum 1355 ## # … with 14,730 more rows This is readable, but can clutter up your workspace with lots of objects that you have to name individually. With multiple steps, that can be hard to keep track of. You can also nest functions (i.e. one function inside of another), like this: rna3 &lt;- select(filter(rna, sex == &quot;Male&quot;), gene, sample, tissue, expression) rna3 ## # A tibble: 14,740 × 4 ## gene sample tissue expression ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Asl GSM2545340 Cerebellum 626 ## 2 Apod GSM2545340 Cerebellum 13021 ## 3 Cyp2d22 GSM2545340 Cerebellum 2171 ## 4 Klk6 GSM2545340 Cerebellum 448 ## 5 Fcrls GSM2545340 Cerebellum 180 ## 6 Slc2a4 GSM2545340 Cerebellum 313 ## 7 Exd2 GSM2545340 Cerebellum 2366 ## 8 Gjc2 GSM2545340 Cerebellum 310 ## 9 Plp1 GSM2545340 Cerebellum 53126 ## 10 Gnb4 GSM2545340 Cerebellum 1355 ## # … with 14,730 more rows This is handy, but can be difficult to read if too many functions are nested, as R evaluates the expression from the inside out (in this case, filtering, then selecting). The last option, pipes, are a recent addition to R. Pipes let you take the output of one function and send it directly to the next, which is useful when you need to do many things to the same dataset. Pipes in R look like %&gt;% and are made available via the magrittr package, installed automatically with dplyr. If you use RStudio, you can type the pipe with Ctrl + Shift + M if you have a PC or Cmd + Shift + M if you have a Mac. rna %&gt;% filter(sex == &quot;Male&quot;) %&gt;% select(gene, sample, tissue, expression) ## # A tibble: 14,740 × 4 ## gene sample tissue expression ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Asl GSM2545340 Cerebellum 626 ## 2 Apod GSM2545340 Cerebellum 13021 ## 3 Cyp2d22 GSM2545340 Cerebellum 2171 ## 4 Klk6 GSM2545340 Cerebellum 448 ## 5 Fcrls GSM2545340 Cerebellum 180 ## 6 Slc2a4 GSM2545340 Cerebellum 313 ## 7 Exd2 GSM2545340 Cerebellum 2366 ## 8 Gjc2 GSM2545340 Cerebellum 310 ## 9 Plp1 GSM2545340 Cerebellum 53126 ## 10 Gnb4 GSM2545340 Cerebellum 1355 ## # … with 14,730 more rows In the above code, we use the pipe to send the rna dataset first through filter() to keep rows where sex is Male, then through select() to keep only the gene, sample, tissue, and expressioncolumns. Since %&gt;% takes the object on its left and passes it as the first argument to the function on its right, we don’t need to explicitly include the data frame as an argument to the filter() and select() functions any more. Some may find it helpful to read the pipe like the word “then.” For instance, in the above example, we took the data frame rna, then we filtered for rows with sex == \"Male\", then we selected columns gene, sample, tissue, and expression. The dplyr functions by themselves are somewhat simple, but by combining them into linear workflows with the pipe, we can accomplish more complex manipulations of data frames. If we want to create a new object with this smaller version of the data, we can assign it a new name: rna3 &lt;- rna %&gt;% filter(sex == &quot;Male&quot;) %&gt;% select(gene, sample, tissue, expression) rna3 ## # A tibble: 14,740 × 4 ## gene sample tissue expression ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Asl GSM2545340 Cerebellum 626 ## 2 Apod GSM2545340 Cerebellum 13021 ## 3 Cyp2d22 GSM2545340 Cerebellum 2171 ## 4 Klk6 GSM2545340 Cerebellum 448 ## 5 Fcrls GSM2545340 Cerebellum 180 ## 6 Slc2a4 GSM2545340 Cerebellum 313 ## 7 Exd2 GSM2545340 Cerebellum 2366 ## 8 Gjc2 GSM2545340 Cerebellum 310 ## 9 Plp1 GSM2545340 Cerebellum 53126 ## 10 Gnb4 GSM2545340 Cerebellum 1355 ## # … with 14,730 more rows Note that the final data frame is the leftmost part of this expression. ► Question Using pipes, subset the rna data to genes with an expression higher than 50000 in male mice at time 0, and retain only the columns gene, sample, time, expression and age ► Solution rna %&gt;% filter(expression &gt; 50000, sex == &quot;Male&quot;, time == 0 ) %&gt;% select(gene, sample, time, expression, age) ## # A tibble: 8 × 5 ## gene sample time expression age ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Plp1 GSM2545343 0 98658 8 ## 2 Glul GSM2545343 0 54808 8 ## 3 Atp1b1 GSM2545343 0 60083 8 ## 4 Plp1 GSM2545349 0 82722 8 ## 5 Atp1b1 GSM2545349 0 59094 8 ## 6 Plp1 GSM2545354 0 84540 8 ## 7 Glul GSM2545354 0 50584 8 ## 8 Atp1b1 GSM2545354 0 57409 8 5.5 Mutate Frequently you’ll want to create new columns based on the values in existing columns, for example to do unit conversions, or to find the ratio of values in two columns. For this we’ll use mutate(). To create a new column of time in hours: rna %&gt;% mutate(time_hours = time * 24) %&gt;% select(time, time_hours) ## # A tibble: 32,428 × 2 ## time time_hours ## &lt;dbl&gt; &lt;dbl&gt; ## 1 8 192 ## 2 8 192 ## 3 8 192 ## 4 8 192 ## 5 8 192 ## 6 8 192 ## 7 8 192 ## 8 8 192 ## 9 8 192 ## 10 8 192 ## # … with 32,418 more rows You can also create a second new column based on the first new column within the same call of mutate(): rna %&gt;% mutate(time_hours = time * 24, time_mn = time_hours * 60) %&gt;% select(time, time_hours, time_mn) ## # A tibble: 32,428 × 3 ## time time_hours time_mn ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 8 192 11520 ## 2 8 192 11520 ## 3 8 192 11520 ## 4 8 192 11520 ## 5 8 192 11520 ## 6 8 192 11520 ## 7 8 192 11520 ## 8 8 192 11520 ## 9 8 192 11520 ## 10 8 192 11520 ## # … with 32,418 more rows If this runs off your screen and you just want to see the first few rows, you can use a pipe to view the head() of the data. (Pipes work with non-dplyr functions, too, as long as the dplyr or magrittr package is loaded). rna %&gt;% mutate(time_hours = time * 24, time_mn = time_hours * 60) %&gt;% select(time, time_hours, time_mn) %&gt;% head() ## # A tibble: 6 × 3 ## time time_hours time_mn ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 8 192 11520 ## 2 8 192 11520 ## 3 8 192 11520 ## 4 8 192 11520 ## 5 8 192 11520 ## 6 8 192 11520 Let’s imagine we are interested in the human homologs of the mouse genes analysed in this dataset. This information can be found in the last column of the rna tibble, named hsapiens_homolog_associated_gene_name. rna %&gt;% select(gene, hsapiens_homolog_associated_gene_name) ## # A tibble: 32,428 × 2 ## gene hsapiens_homolog_associated_gene_name ## &lt;chr&gt; &lt;chr&gt; ## 1 Asl ASL ## 2 Apod APOD ## 3 Cyp2d22 CYP2D6 ## 4 Klk6 KLK6 ## 5 Fcrls FCRL4 ## 6 Slc2a4 SLC2A4 ## 7 Exd2 EXD2 ## 8 Gjc2 GJC2 ## 9 Plp1 PLP1 ## 10 Gnb4 GNB4 ## # … with 32,418 more rows Some mouse gene have no human homologs. These can be retrieved using a filter() in the chain, and the is.na() function that determines whether something is an NA. rna %&gt;% select(gene, hsapiens_homolog_associated_gene_name) %&gt;% filter(is.na(hsapiens_homolog_associated_gene_name)) ## # A tibble: 4,774 × 2 ## gene hsapiens_homolog_associated_gene_name ## &lt;chr&gt; &lt;chr&gt; ## 1 Prodh &lt;NA&gt; ## 2 Icosl &lt;NA&gt; ## 3 Tssk5 &lt;NA&gt; ## 4 Vmn2r1 &lt;NA&gt; ## 5 Gm10654 &lt;NA&gt; ## 6 Hexa &lt;NA&gt; ## 7 Sult1a1 &lt;NA&gt; ## 8 Gm6277 &lt;NA&gt; ## 9 Amt &lt;NA&gt; ## 10 Tmem198b &lt;NA&gt; ## # … with 4,764 more rows If we want to keep only mouse gene that have a human homolog, we can insert a ! symbol that negates the result, so we’re asking for every row where hsapiens_homolog_associated_gene_name is not an NA. The first few rows of the output are full of NAs, so if we wanted to remove those we could insert a filter() in the chain: rna %&gt;% select(gene, hsapiens_homolog_associated_gene_name) %&gt;% filter(!is.na(hsapiens_homolog_associated_gene_name)) ## # A tibble: 27,654 × 2 ## gene hsapiens_homolog_associated_gene_name ## &lt;chr&gt; &lt;chr&gt; ## 1 Asl ASL ## 2 Apod APOD ## 3 Cyp2d22 CYP2D6 ## 4 Klk6 KLK6 ## 5 Fcrls FCRL4 ## 6 Slc2a4 SLC2A4 ## 7 Exd2 EXD2 ## 8 Gjc2 GJC2 ## 9 Plp1 PLP1 ## 10 Gnb4 GNB4 ## # … with 27,644 more rows ► Question Create a new data frame from the rna data that meets the following criteria: contains only the gene, chromosome_name, phenotype_description, sample, and expression columns and a new column giving the log expression the gene. This data frame must only contain gene located on autosomes and associated with a phenotype_description. Hint: think about how the commands should be ordered to produce this data frame! ► Solution rna %&gt;% filter(chromosome_name != &quot;X&quot;, chromosome_name != &quot;Y&quot;) %&gt;% mutate(log_expression = log(expression)) %&gt;% select(gene, chromosome_name, phenotype_description, sample, log_expression) %&gt;% filter(!is.na(phenotype_description)) ## # A tibble: 20,592 × 5 ## gene chromosome_name phenotype_description sample log_expression ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Asl 5 abnormal circulating amino ac… GSM254… 7.06 ## 2 Apod 16 abnormal lipid homeostasis GSM254… 10.5 ## 3 Cyp2d22 15 abnormal skin morphology GSM254… 8.31 ## 4 Klk6 7 abnormal cytokine level GSM254… 5.66 ## 5 Fcrls 3 decreased CD8-positive alpha-… GSM254… 4.44 ## 6 Slc2a4 11 abnormal circulating glucose … GSM254… 6.66 ## 7 Gjc2 11 Purkinje cell degeneration GSM254… 5.66 ## 8 Gnb4 3 abnormal behavior GSM254… 6.98 ## 9 Tnc 4 abnormal CNS synaptic transmi… GSM254… 5.39 ## 10 Trf 9 abnormal embryo size GSM254… 9.18 ## # … with 20,582 more rows 5.6 Split-apply-combine data analysis Many data analysis tasks can be approached using the split-apply-combine paradigm: split the data into groups, apply some analysis to each group, and then combine the results. dplyr makes this very easy through the use of the group_by() function. rna %&gt;% group_by(gene) ## # A tibble: 32,428 × 19 ## # Groups: gene [1,474] ## gene sample expression organism age sex infection strain time tissue ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Asl GSM254… 1170 Mus mus… 8 Fema… Influenz… C57BL… 8 Cereb… ## 2 Apod GSM254… 36194 Mus mus… 8 Fema… Influenz… C57BL… 8 Cereb… ## 3 Cyp2d22 GSM254… 4060 Mus mus… 8 Fema… Influenz… C57BL… 8 Cereb… ## 4 Klk6 GSM254… 287 Mus mus… 8 Fema… Influenz… C57BL… 8 Cereb… ## 5 Fcrls GSM254… 85 Mus mus… 8 Fema… Influenz… C57BL… 8 Cereb… ## 6 Slc2a4 GSM254… 782 Mus mus… 8 Fema… Influenz… C57BL… 8 Cereb… ## 7 Exd2 GSM254… 1619 Mus mus… 8 Fema… Influenz… C57BL… 8 Cereb… ## 8 Gjc2 GSM254… 288 Mus mus… 8 Fema… Influenz… C57BL… 8 Cereb… ## 9 Plp1 GSM254… 43217 Mus mus… 8 Fema… Influenz… C57BL… 8 Cereb… ## 10 Gnb4 GSM254… 1071 Mus mus… 8 Fema… Influenz… C57BL… 8 Cereb… ## # … with 32,418 more rows, and 9 more variables: mouse &lt;dbl&gt;, ENTREZID &lt;dbl&gt;, ## # product &lt;chr&gt;, ensembl_gene_id &lt;chr&gt;, external_synonym &lt;chr&gt;, ## # chromosome_name &lt;chr&gt;, gene_biotype &lt;chr&gt;, phenotype_description &lt;chr&gt;, ## # hsapiens_homolog_associated_gene_name &lt;chr&gt; The group_by() function doesn’t perform any data processing, it groups the data into subsets: in the example above, our initial tibble of 32428 observations is split into 1474 groups based on the gene variable. Once the data have been combined, subsequent operations will be applied on each group independently. 5.6.1 The summarize() function group_by() is often used together with summarize(), which collapses each group into a single-row summary of that group. group_by() takes as arguments the column names that contain the categorical variables for which you want to calculate the summary statistics. So to compute the mean expression by gene: rna %&gt;% group_by(gene) %&gt;% summarize(mean_expression = mean(expression)) ## # A tibble: 1,474 × 2 ## gene mean_expression ## &lt;chr&gt; &lt;dbl&gt; ## 1 AI504432 1053. ## 2 AW046200 131. ## 3 AW551984 295. ## 4 Aamp 4751. ## 5 Abca12 4.55 ## 6 Abcc8 2498. ## 7 Abhd14a 525. ## 8 Abi2 4909. ## 9 Abi3bp 1002. ## 10 Abl2 2124. ## # … with 1,464 more rows You may also have noticed that the output from these calls doesn’t run off the screen anymore. It’s one of the advantages of tbl_df over data frame. You can also group by multiple columns: rna %&gt;% group_by(gene, infection, time) %&gt;% summarize(mean_expression = mean(expression)) ## `summarise()` has grouped output by &#39;gene&#39;, &#39;infection&#39;. You can override using the `.groups` argument. ## # A tibble: 4,422 × 4 ## # Groups: gene, infection [2,948] ## gene infection time mean_expression ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AI504432 InfluenzaA 4 1104. ## 2 AI504432 InfluenzaA 8 1014 ## 3 AI504432 NonInfected 0 1034. ## 4 AW046200 InfluenzaA 4 152. ## 5 AW046200 InfluenzaA 8 81 ## 6 AW046200 NonInfected 0 155. ## 7 AW551984 InfluenzaA 4 302. ## 8 AW551984 InfluenzaA 8 342. ## 9 AW551984 NonInfected 0 238 ## 10 Aamp InfluenzaA 4 4870 ## # … with 4,412 more rows Here, again, the output from these calls doesn’t run off the screen anymore. If you want to display more data, you can use the print() function at the end of your chain with the argument n specifying the number of rows to display: rna %&gt;% group_by(gene, infection, time) %&gt;% summarize(mean_expression = mean(expression)) %&gt;% print(n = 15) ## `summarise()` has grouped output by &#39;gene&#39;, &#39;infection&#39;. You can override using the `.groups` argument. ## # A tibble: 4,422 × 4 ## # Groups: gene, infection [2,948] ## gene infection time mean_expression ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AI504432 InfluenzaA 4 1104. ## 2 AI504432 InfluenzaA 8 1014 ## 3 AI504432 NonInfected 0 1034. ## 4 AW046200 InfluenzaA 4 152. ## 5 AW046200 InfluenzaA 8 81 ## 6 AW046200 NonInfected 0 155. ## 7 AW551984 InfluenzaA 4 302. ## 8 AW551984 InfluenzaA 8 342. ## 9 AW551984 NonInfected 0 238 ## 10 Aamp InfluenzaA 4 4870 ## 11 Aamp InfluenzaA 8 4763. ## 12 Aamp NonInfected 0 4603. ## 13 Abca12 InfluenzaA 4 4.25 ## 14 Abca12 InfluenzaA 8 4.14 ## 15 Abca12 NonInfected 0 5.29 ## # … with 4,407 more rows Once the data is grouped, you can also summarize multiple variables at the same time (and not necessarily on the same variable). For instance, we could add columns indicating the median expression by gene and by condition: rna %&gt;% group_by(gene, infection, time) %&gt;% summarize(mean_expression = mean(expression), median_expression = median(expression)) ## `summarise()` has grouped output by &#39;gene&#39;, &#39;infection&#39;. You can override using the `.groups` argument. ## # A tibble: 4,422 × 5 ## # Groups: gene, infection [2,948] ## gene infection time mean_expression median_expression ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AI504432 InfluenzaA 4 1104. 1094. ## 2 AI504432 InfluenzaA 8 1014 985 ## 3 AI504432 NonInfected 0 1034. 1016 ## 4 AW046200 InfluenzaA 4 152. 144. ## 5 AW046200 InfluenzaA 8 81 82 ## 6 AW046200 NonInfected 0 155. 163 ## 7 AW551984 InfluenzaA 4 302. 245 ## 8 AW551984 InfluenzaA 8 342. 287 ## 9 AW551984 NonInfected 0 238 265 ## 10 Aamp InfluenzaA 4 4870 4708 ## # … with 4,412 more rows It is sometimes useful to rearrange the result of a query to inspect the values. For instance, we can sort on mean_expression to put the genes lowly expressed first: rna %&gt;% group_by(gene, infection, time) %&gt;% summarize(mean_expression = mean(expression), median_expression = median(expression)) %&gt;% arrange(mean_expression) ## `summarise()` has grouped output by &#39;gene&#39;, &#39;infection&#39;. You can override using the `.groups` argument. ## # A tibble: 4,422 × 5 ## # Groups: gene, infection [2,948] ## gene infection time mean_expression median_expression ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Gm5415 InfluenzaA 4 0.375 0 ## 2 Selp NonInfected 0 0.429 0 ## 3 Ascl5 NonInfected 0 0.571 1 ## 4 Gm28178 NonInfected 0 0.571 1 ## 5 Il18r1 NonInfected 0 0.571 0 ## 6 Pdcd1 InfluenzaA 8 0.571 0 ## 7 Rln3 NonInfected 0 0.571 0 ## 8 Gm19637 InfluenzaA 4 0.625 0.5 ## 9 Gm6177 InfluenzaA 4 0.625 1 ## 10 Gm7241 InfluenzaA 4 0.625 0.5 ## # … with 4,412 more rows To sort in descending order, we need to add the desc() function: rna %&gt;% group_by(gene, infection, time) %&gt;% summarize(mean_expression = mean(expression), median_expression = median(expression)) %&gt;% arrange(desc(mean_expression)) ## `summarise()` has grouped output by &#39;gene&#39;, &#39;infection&#39;. You can override using the `.groups` argument. ## # A tibble: 4,422 × 5 ## # Groups: gene, infection [2,948] ## gene infection time mean_expression median_expression ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Plp1 NonInfected 0 91103. 96534 ## 2 Glul InfluenzaA 8 73948. 71706 ## 3 Plp1 InfluenzaA 4 67198. 63840 ## 4 Atp1b1 InfluenzaA 4 60364. 56546. ## 5 Atp1b1 InfluenzaA 8 59229 61672 ## 6 Atp1b1 NonInfected 0 57351. 59094 ## 7 Sparc InfluenzaA 8 56106. 57409 ## 8 Glul InfluenzaA 4 55358. 52836. ## 9 Glul NonInfected 0 48123. 49099 ## 10 Nrep NonInfected 0 40060. 37493 ## # … with 4,412 more rows 5.6.2 Counting When working with data, we often want to know the number of observations found for each factor or combination of factors. For this task, dplyr provides count(). For example, if we wanted to count the number of rows of data for each infected and non infected, we would do: rna %&gt;% count(infection) ## # A tibble: 2 × 2 ## infection n ## &lt;chr&gt; &lt;int&gt; ## 1 InfluenzaA 22110 ## 2 NonInfected 10318 The count() function is shorthand for something we’ve already seen: grouping by a variable, and summarizing it by counting the number of observations in that group. In other words, rna %&gt;% count() is equivalent to: rna %&gt;% group_by(infection) %&gt;% summarise(count = n()) ## # A tibble: 2 × 2 ## infection count ## &lt;chr&gt; &lt;int&gt; ## 1 InfluenzaA 22110 ## 2 NonInfected 10318 For convenience, count() provides the sort argument: rna %&gt;% count(infection, sort = TRUE) ## # A tibble: 2 × 2 ## infection n ## &lt;chr&gt; &lt;int&gt; ## 1 InfluenzaA 22110 ## 2 NonInfected 10318 Previous example shows the use of count() to count the number of rows/observations for one factor (i.e., infection). If we wanted to count combination of factors, such as infection and time, we would specify the first and the second factor as the arguments of count(): rna %&gt;% count(infection, time) ## # A tibble: 3 × 3 ## infection time n ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 InfluenzaA 4 11792 ## 2 InfluenzaA 8 10318 ## 3 NonInfected 0 10318 With the above code, we can proceed with arrange() to sort the table according to a number of criteria so that we have a better comparison. For instance, we might want to arrange the table above by time: rna %&gt;% count(infection, time) %&gt;% arrange(time) ## # A tibble: 3 × 3 ## infection time n ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 NonInfected 0 10318 ## 2 InfluenzaA 4 11792 ## 3 InfluenzaA 8 10318 or by counts: rna %&gt;% count(infection, time) %&gt;% arrange(n) ## # A tibble: 3 × 3 ## infection time n ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 InfluenzaA 8 10318 ## 2 NonInfected 0 10318 ## 3 InfluenzaA 4 11792 ► Question How many genes were analysed in each sample? Use group_by() and summarize() to evaluate the sequencing depth (the sum of all counts) in each sample. Which sample has the highest sequencing depth? Calculate the mean expression level of gene “Dok3” by timepoints. Pick one sample and evaluate the number of genes by biotype Identify genes associated with “abnormal DNA methylation” phenotype description, and calculate their mean expression (in log) at time 0, time 4 and time 8. ► Solution How many genes were analysed in each sample? rna %&gt;% count(sample) ## # A tibble: 22 × 2 ## sample n ## &lt;chr&gt; &lt;int&gt; ## 1 GSM2545336 1474 ## 2 GSM2545337 1474 ## 3 GSM2545338 1474 ## 4 GSM2545339 1474 ## 5 GSM2545340 1474 ## 6 GSM2545341 1474 ## 7 GSM2545342 1474 ## 8 GSM2545343 1474 ## 9 GSM2545344 1474 ## 10 GSM2545345 1474 ## # … with 12 more rows Use group_by() and summarize() to evaluate the sequencing depth (the sum of all counts) in each sample. Which sample has the highest sequencing depth? rna %&gt;% group_by(sample) %&gt;% summarize(seq_depth = sum(expression)) %&gt;% arrange(desc(seq_depth)) ## # A tibble: 22 × 2 ## sample seq_depth ## &lt;chr&gt; &lt;dbl&gt; ## 1 GSM2545350 3257043 ## 2 GSM2545352 3218773 ## 3 GSM2545343 3107171 ## 4 GSM2545336 3042972 ## 5 GSM2545380 3039279 ## 6 GSM2545353 2955334 ## 7 GSM2545362 2915742 ## 8 GSM2545348 2915189 ## 9 GSM2545351 2784988 ## 10 GSM2545349 2760409 ## # … with 12 more rows Calculate the mean expression level of gene “Dok3” by timepoints. rna %&gt;% filter(gene == &quot;Dok3&quot;) %&gt;% group_by(time) %&gt;% summarize(mean = mean(expression)) %&gt;% arrange(time) ## # A tibble: 3 × 2 ## time mean ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0 169 ## 2 4 156. ## 3 8 61 Pick one sample and evaluate the number of genes by biotype rna %&gt;% filter(sample == &quot;GSM2545336&quot;) %&gt;% group_by(gene_biotype) %&gt;% count(gene_biotype) %&gt;% arrange(desc(n)) ## # A tibble: 13 × 2 ## # Groups: gene_biotype [13] ## gene_biotype n ## &lt;chr&gt; &lt;int&gt; ## 1 protein_coding 1321 ## 2 lncRNA 69 ## 3 processed_pseudogene 59 ## 4 miRNA 7 ## 5 snoRNA 5 ## 6 TEC 4 ## 7 polymorphic_pseudogene 2 ## 8 unprocessed_pseudogene 2 ## 9 IG_C_gene 1 ## 10 scaRNA 1 ## 11 transcribed_processed_pseudogene 1 ## 12 transcribed_unitary_pseudogene 1 ## 13 transcribed_unprocessed_pseudogene 1 Identify genes associated with “abnormal DNA methylation” phenotype description, and calculate their mean expression (in log) at time 0, time 4 and time 8. rna %&gt;% filter(phenotype_description == &quot;abnormal DNA methylation&quot;) %&gt;% group_by(gene, time) %&gt;% summarize(mean_expression = mean(log(expression))) %&gt;% arrange() ## `summarise()` has grouped output by &#39;gene&#39;. You can override using the `.groups` argument. ## # A tibble: 6 × 3 ## # Groups: gene [2] ## gene time mean_expression ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Xist 0 6.95 ## 2 Xist 4 6.34 ## 3 Xist 8 7.13 ## 4 Zdbf2 0 6.27 ## 5 Zdbf2 4 6.27 ## 6 Zdbf2 8 6.19 5.7 Reshaping data In rna, the rows contain expression values (the unit) that are associated with a combination of 2 other variables: gene and sample. All the other columns correspond to variables describing either the sample (age, sex, organism…) or the gene (gene_biotype, ENTREZ_ID, product…). The variables that don’t change genes or samples will have the same value in all the rows. This structure is called a long-format, as one column contains all the values, and other column(s) list(s) the context of the value. In certain cases, the long-format is not really “human-readable,” and another format, a wide-format is preferred, as a more compact way of representing the data. This is typically the case with gene expression values that scientists are used to look as matrices, were rows represent genes and columns represent samples. To convert the gene expression values from rna into a wide-format, we need to create a new table where each row (the units) is composed of expression values associated with each gene. In practical terms this means the values of the sample column in rna would become the names of column variables, and the cells would contain the expression values measured on each gene. The key point here is that we are still following a tidy data structure, but we have reshaped the data according to the observations of interest: expression levels per gene instead of recording them per gene and per sample. With this new table, it would become therefore straightforward to explore the relationship between the gene expression levels within, and between, the samples. The opposite transformation would be to transform column names into values of a new variable. We can do both these of transformations with two tidyr functions, pivot_longer() and pivot_wider() (see here for details). 5.7.1 Pivoting the data into a wider format Let’s first select the 3 first columns of rna and use pivot_wider() to transform data in a wide-format. rna_exp &lt;- rna %&gt;% select(gene, sample, expression) rna_exp ## # A tibble: 32,428 × 3 ## gene sample expression ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Asl GSM2545336 1170 ## 2 Apod GSM2545336 36194 ## 3 Cyp2d22 GSM2545336 4060 ## 4 Klk6 GSM2545336 287 ## 5 Fcrls GSM2545336 85 ## 6 Slc2a4 GSM2545336 782 ## 7 Exd2 GSM2545336 1619 ## 8 Gjc2 GSM2545336 288 ## 9 Plp1 GSM2545336 43217 ## 10 Gnb4 GSM2545336 1071 ## # … with 32,418 more rows pivot_wider takes three main arguments: the data to be transformed; the names_from column name whose values will become new column names; the values_from column name whose values will fill the new columns. Note also the values_fill argument which, if set, fills in missing values with the value provided. Using pivot_wider(), using new columns from the sample variable and values from expression, this becomes 1474 gene expression measurements of 22 variables, one row for each gene, one column for each sample. We again use pipes: rna_wide &lt;- rna_exp %&gt;% pivot_wider(names_from = sample, values_from = expression) rna_wide ## # A tibble: 1,474 × 23 ## gene GSM2545336 GSM2545337 GSM2545338 GSM2545339 GSM2545340 GSM2545341 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asl 1170 361 400 586 626 988 ## 2 Apod 36194 10347 9173 10620 13021 29594 ## 3 Cyp2d22 4060 1616 1603 1901 2171 3349 ## 4 Klk6 287 629 641 578 448 195 ## 5 Fcrls 85 233 244 237 180 38 ## 6 Slc2a4 782 231 248 265 313 786 ## 7 Exd2 1619 2288 2235 2513 2366 1359 ## 8 Gjc2 288 595 568 551 310 146 ## 9 Plp1 43217 101241 96534 58354 53126 27173 ## 10 Gnb4 1071 1791 1867 1430 1355 798 ## # … with 1,464 more rows, and 16 more variables: GSM2545342 &lt;dbl&gt;, ## # GSM2545343 &lt;dbl&gt;, GSM2545344 &lt;dbl&gt;, GSM2545345 &lt;dbl&gt;, GSM2545346 &lt;dbl&gt;, ## # GSM2545347 &lt;dbl&gt;, GSM2545348 &lt;dbl&gt;, GSM2545349 &lt;dbl&gt;, GSM2545350 &lt;dbl&gt;, ## # GSM2545351 &lt;dbl&gt;, GSM2545352 &lt;dbl&gt;, GSM2545353 &lt;dbl&gt;, GSM2545354 &lt;dbl&gt;, ## # GSM2545362 &lt;dbl&gt;, GSM2545363 &lt;dbl&gt;, GSM2545380 &lt;dbl&gt; We can now easily plot the comparisons between the gene expression levels in different samples. Note that the pivot_wider() function comes with an optional values_fill argument that can be usefull when dealing with missing values. Let’s imagine that for some reason, we had some missing expression values for some genes in certain samples. In the following fictive example, the gene Cyp2d22 has only one expression value, in GSM2545338 sample. rna_with_missing_values ## # A tibble: 7 × 3 ## gene sample expression ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Asl GSM2545336 1170 ## 2 Apod GSM2545336 36194 ## 3 Asl GSM2545337 361 ## 4 Apod GSM2545337 10347 ## 5 Asl GSM2545338 400 ## 6 Apod GSM2545338 9173 ## 7 Cyp2d22 GSM2545338 1603 By default, the pivot_wider() function will add NA for missing values. rna_with_missing_values %&gt;% pivot_wider(names_from = sample, values_from = expression) ## # A tibble: 3 × 4 ## gene GSM2545336 GSM2545337 GSM2545338 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asl 1170 361 400 ## 2 Apod 36194 10347 9173 ## 3 Cyp2d22 NA NA 1603 But in some cases, we may wish to fill in the missing values by setting values_fill to a specific value. rna_with_missing_values %&gt;% pivot_wider(names_from = sample, values_from = expression, values_fill = 0) ## # A tibble: 3 × 4 ## gene GSM2545336 GSM2545337 GSM2545338 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asl 1170 361 400 ## 2 Apod 36194 10347 9173 ## 3 Cyp2d22 0 0 1603 5.7.2 Pivoting data into a longer format The opposing situation could occur if we had been provided with data in the form of rna_wide, where the sample IDs are column names, but we wish to treat them as values of a sample variable instead. In this situation we are using the column names and turning them into a pair of new variables. One variable represents the column names as values, and the other variable contains the values previously associated with the column names. pivot_longer() takes four main arguments: the data to be transformed; the new names_to column we wish to create and populate with the current column names; the new values_to column we wish to create and populate with current values; the names of the columns to be used to populate the names_to and values_to variables (or to drop). To recreate rna_long from rna_long we would create a key called sample and value called expression and use all columns except gene for the key variable. Here we drop gene column with a minus sign. Notice how the new variable names are to be quoted here. rna_long &lt;- rna_wide %&gt;% pivot_longer(names_to = &quot;sample&quot;, values_to = &quot;expression&quot;, -gene) rna_long ## # A tibble: 32,428 × 3 ## gene sample expression ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Asl GSM2545336 1170 ## 2 Asl GSM2545337 361 ## 3 Asl GSM2545338 400 ## 4 Asl GSM2545339 586 ## 5 Asl GSM2545340 626 ## 6 Asl GSM2545341 988 ## 7 Asl GSM2545342 836 ## 8 Asl GSM2545343 535 ## 9 Asl GSM2545344 586 ## 10 Asl GSM2545345 597 ## # … with 32,418 more rows Note that if we had missing values in the wide-format, the NA would be included in the new wide format. Pivoting to wider and longer formats can be a useful way to balance out a dataset so every replicate has the same composition. wide_with_NA &lt;- rna_with_missing_values %&gt;% pivot_wider(names_from = sample, values_from = expression) wide_with_NA ## # A tibble: 3 × 4 ## gene GSM2545336 GSM2545337 GSM2545338 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asl 1170 361 400 ## 2 Apod 36194 10347 9173 ## 3 Cyp2d22 NA NA 1603 wide_with_NA %&gt;% pivot_longer(names_to = &quot;sample&quot;, values_to = &quot;expression&quot;, -gene) ## # A tibble: 9 × 3 ## gene sample expression ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Asl GSM2545336 1170 ## 2 Asl GSM2545337 361 ## 3 Asl GSM2545338 400 ## 4 Apod GSM2545336 36194 ## 5 Apod GSM2545337 10347 ## 6 Apod GSM2545338 9173 ## 7 Cyp2d22 GSM2545336 NA ## 8 Cyp2d22 GSM2545337 NA ## 9 Cyp2d22 GSM2545338 1603 We could also have used a specification for what columns to include. This can be useful if you have a large number of identifying columns, and it’s easier to specify what to gather than what to leave alone. Here the starts_with() function can help to retrieve sample names without having to list them all! Another possibility would be to use the : operator! rna_wide %&gt;% pivot_longer(names_to = &quot;sample&quot;, values_to = &quot;expression&quot;, cols = starts_with(&quot;GSM&quot;)) ## # A tibble: 32,428 × 3 ## gene sample expression ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Asl GSM2545336 1170 ## 2 Asl GSM2545337 361 ## 3 Asl GSM2545338 400 ## 4 Asl GSM2545339 586 ## 5 Asl GSM2545340 626 ## 6 Asl GSM2545341 988 ## 7 Asl GSM2545342 836 ## 8 Asl GSM2545343 535 ## 9 Asl GSM2545344 586 ## 10 Asl GSM2545345 597 ## # … with 32,418 more rows rna_wide %&gt;% pivot_longer(names_to = &quot;sample&quot;, values_to = &quot;expression&quot;, GSM2545336:GSM2545380) ## # A tibble: 32,428 × 3 ## gene sample expression ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Asl GSM2545336 1170 ## 2 Asl GSM2545337 361 ## 3 Asl GSM2545338 400 ## 4 Asl GSM2545339 586 ## 5 Asl GSM2545340 626 ## 6 Asl GSM2545341 988 ## 7 Asl GSM2545342 836 ## 8 Asl GSM2545343 535 ## 9 Asl GSM2545344 586 ## 10 Asl GSM2545345 597 ## # … with 32,418 more rows ► Question Subset genes located on X and Y chromosomes from the rna data frame and spread the data frame with sex as columns, chromosome_name as rows, and the mean expression of genes located in each chromosome as the values. You will need to summarize before reshaping! ► Solution Let’s have a look to variables of interest rna %&gt;% filter(chromosome_name == &quot;Y&quot; | chromosome_name == &quot;X&quot;) %&gt;% select(gene, sample, sex, expression, chromosome_name) %&gt;% arrange(gene) ## # A tibble: 1,298 × 5 ## gene sample sex expression chromosome_name ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Armcx5 GSM2545336 Female 1189 X ## 2 Armcx5 GSM2545337 Female 513 X ## 3 Armcx5 GSM2545338 Female 414 X ## 4 Armcx5 GSM2545339 Female 543 X ## 5 Armcx5 GSM2545340 Male 666 X ## 6 Armcx5 GSM2545341 Male 1172 X ## 7 Armcx5 GSM2545342 Female 857 X ## 8 Armcx5 GSM2545343 Male 559 X ## 9 Armcx5 GSM2545344 Female 570 X ## 10 Armcx5 GSM2545345 Male 545 X ## # … with 1,288 more rows rna_1 &lt;- rna %&gt;% filter(chromosome_name == &quot;Y&quot; | chromosome_name == &quot;X&quot;) %&gt;% group_by(sex, chromosome_name) %&gt;% summarize(mean = mean(expression)) %&gt;% pivot_wider(names_from = sex, values_from = mean) ## `summarise()` has grouped output by &#39;sex&#39;. You can override using the `.groups` argument. rna_1 ## # A tibble: 2 × 3 ## chromosome_name Female Male ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 X 3504. 2497. ## 2 Y 3 2117. ► Question Now take that data frame and transform it with pivot_longer() so each row is a unique chromosome_name by gender combination. ► Solution rna_1 %&gt;% pivot_longer(names_to = &quot;gender&quot;, values_to = &quot;mean&quot;, - chromosome_name) ## # A tibble: 4 × 3 ## chromosome_name gender mean ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 X Female 3504. ## 2 X Male 2497. ## 3 Y Female 3 ## 4 Y Male 2117. ► Question Use the rna dataset to create an expression matrix were each row represents the mean expression levels of genes and columns represent the different timepoints. ► Solution rna %&gt;% group_by(gene, time) %&gt;% summarize(mean_exp = mean(expression)) %&gt;% pivot_wider(names_from = time, values_from = mean_exp) ## `summarise()` has grouped output by &#39;gene&#39;. You can override using the `.groups` argument. ## # A tibble: 1,474 × 4 ## # Groups: gene [1,474] ## gene `0` `4` `8` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AI504432 1034. 1104. 1014 ## 2 AW046200 155. 152. 81 ## 3 AW551984 238 302. 342. ## 4 Aamp 4603. 4870 4763. ## 5 Abca12 5.29 4.25 4.14 ## 6 Abcc8 2576. 2609. 2292. ## 7 Abhd14a 591. 547. 432. ## 8 Abi2 4881. 4903. 4945. ## 9 Abi3bp 1175. 1061. 762. ## 10 Abl2 2170. 2078. 2131. ## # … with 1,464 more rows Notice that this generates a tibble with some column names starting by a number. If we wanted to select the column corresponding to the timepoints, we could not use the column names directly… What happens when we select the colum 4? rna %&gt;% group_by(gene, time) %&gt;% summarize(mean_exp = mean(expression)) %&gt;% pivot_wider(names_from = time, values_from = mean_exp) %&gt;% select(gene, 4) ## `summarise()` has grouped output by &#39;gene&#39;. You can override using the `.groups` argument. ## # A tibble: 1,474 × 2 ## # Groups: gene [1,474] ## gene `8` ## &lt;chr&gt; &lt;dbl&gt; ## 1 AI504432 1014 ## 2 AW046200 81 ## 3 AW551984 342. ## 4 Aamp 4763. ## 5 Abca12 4.14 ## 6 Abcc8 2292. ## 7 Abhd14a 432. ## 8 Abi2 4945. ## 9 Abi3bp 762. ## 10 Abl2 2131. ## # … with 1,464 more rows To select the timepoint 4, we would have to quote the column name, with backticks “`” rna %&gt;% group_by(gene, time) %&gt;% summarize(mean_exp = mean(expression)) %&gt;% pivot_wider(names_from = time, values_from = mean_exp) %&gt;% select(gene, `4`) ## `summarise()` has grouped output by &#39;gene&#39;. You can override using the `.groups` argument. ## # A tibble: 1,474 × 2 ## # Groups: gene [1,474] ## gene `4` ## &lt;chr&gt; &lt;dbl&gt; ## 1 AI504432 1104. ## 2 AW046200 152. ## 3 AW551984 302. ## 4 Aamp 4870 ## 5 Abca12 4.25 ## 6 Abcc8 2609. ## 7 Abhd14a 547. ## 8 Abi2 4903. ## 9 Abi3bp 1061. ## 10 Abl2 2078. ## # … with 1,464 more rows Another possibility would be to rename the column, choosing a name that doesn’t start by a number : rna %&gt;% group_by(gene, time) %&gt;% summarize(mean_exp = mean(expression)) %&gt;% pivot_wider(names_from = time, values_from = mean_exp) %&gt;% rename(&quot;time0&quot; = `0`, &quot;time4&quot; = `4`, &quot;time8&quot; = `8`) %&gt;% select(gene, time4) ## `summarise()` has grouped output by &#39;gene&#39;. You can override using the `.groups` argument. ## # A tibble: 1,474 × 2 ## # Groups: gene [1,474] ## gene time4 ## &lt;chr&gt; &lt;dbl&gt; ## 1 AI504432 1104. ## 2 AW046200 152. ## 3 AW551984 302. ## 4 Aamp 4870 ## 5 Abca12 4.25 ## 6 Abcc8 2609. ## 7 Abhd14a 547. ## 8 Abi2 4903. ## 9 Abi3bp 1061. ## 10 Abl2 2078. ## # … with 1,464 more rows ► Question Use the previous data frame containing mean expression levels per timepoint and create a new column containing fold-changes between timepoint 8 and timepoint 0, and fold-changes between timepoint 8 and timepoint 4. Convert this table in a long-format table gathering the foldchanges calculated. ► Solution rna_FC &lt;- rna %&gt;% group_by(gene, time) %&gt;% summarize(mean_exp = mean(expression)) %&gt;% pivot_wider(names_from = time, values_from = mean_exp) %&gt;% mutate(time_8_vs_0 = `8` / `0`, time_8_vs_4 = `8` / `4`) ## `summarise()` has grouped output by &#39;gene&#39;. You can override using the `.groups` argument. rna_FC ## # A tibble: 1,474 × 6 ## # Groups: gene [1,474] ## gene `0` `4` `8` time_8_vs_0 time_8_vs_4 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AI504432 1034. 1104. 1014 0.981 0.918 ## 2 AW046200 155. 152. 81 0.522 0.532 ## 3 AW551984 238 302. 342. 1.44 1.13 ## 4 Aamp 4603. 4870 4763. 1.03 0.978 ## 5 Abca12 5.29 4.25 4.14 0.784 0.975 ## 6 Abcc8 2576. 2609. 2292. 0.889 0.878 ## 7 Abhd14a 591. 547. 432. 0.731 0.791 ## 8 Abi2 4881. 4903. 4945. 1.01 1.01 ## 9 Abi3bp 1175. 1061. 762. 0.649 0.719 ## 10 Abl2 2170. 2078. 2131. 0.982 1.03 ## # … with 1,464 more rows rna_FC %&gt;% pivot_longer(names_to = &quot;comparisons&quot;, values_to = &quot;Fold_changes&quot;, time_8_vs_0:time_8_vs_4) ## # A tibble: 2,948 × 6 ## # Groups: gene [1,474] ## gene `0` `4` `8` comparisons Fold_changes ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 AI504432 1034. 1104. 1014 time_8_vs_0 0.981 ## 2 AI504432 1034. 1104. 1014 time_8_vs_4 0.918 ## 3 AW046200 155. 152. 81 time_8_vs_0 0.522 ## 4 AW046200 155. 152. 81 time_8_vs_4 0.532 ## 5 AW551984 238 302. 342. time_8_vs_0 1.44 ## 6 AW551984 238 302. 342. time_8_vs_4 1.13 ## 7 Aamp 4603. 4870 4763. time_8_vs_0 1.03 ## 8 Aamp 4603. 4870 4763. time_8_vs_4 0.978 ## 9 Abca12 5.29 4.25 4.14 time_8_vs_0 0.784 ## 10 Abca12 5.29 4.25 4.14 time_8_vs_4 0.975 ## # … with 2,938 more rows 5.8 Exporting data Now that you have learned how to use dplyr to extract information from or summarize your raw data, you may want to export these new data sets to share them with your collaborators or for archival. Similar to the read_csv() function used for reading CSV files into R, there is a write_csv() function that generates CSV files from data frames. Before using write_csv(), we are going to create a new folder, data_output, in our working directory that will store this generated dataset. We don’t want to write generated datasets in the same directory as our raw data. It’s good practice to keep them separate. The data folder should only contain the raw, unaltered data, and should be left alone to make sure we don’t delete or modify it. In contrast, our script will generate the contents of the data_output directory, so even if the files it contains are deleted, we can always re-generate them. In preparation for our next lesson on plotting, we are going to prepare a table representing for each gene, the fold-changes (in log values) between timepoint 8 and timepoint 0, and the fold-changes between timepoint 8 and timepoint 0. rna_FC &lt;- rna %&gt;% mutate(expression_log = log(expression)) %&gt;% group_by(gene, time) %&gt;% summarize(mean_exp = mean(expression_log)) %&gt;% pivot_wider(names_from = time, values_from = mean_exp) %&gt;% mutate(time_8_vs_0 = `8` - `0`, time_4_vs_0 = `4` - `0`) %&gt;% select(gene, time_8_vs_0, time_4_vs_0) ## `summarise()` has grouped output by &#39;gene&#39;. You can override using the `.groups` argument. rna_FC ## # A tibble: 1,474 × 3 ## # Groups: gene [1,474] ## gene time_8_vs_0 time_4_vs_0 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AI504432 -0.0248 0.0523 ## 2 AW046200 -0.650 -0.0348 ## 3 AW551984 0.232 -0.428 ## 4 Aamp 0.0271 0.0522 ## 5 Abca12 -0.116 -0.114 ## 6 Abcc8 -0.114 0.0163 ## 7 Abhd14a -0.309 -0.0800 ## 8 Abi2 0.0110 -0.000894 ## 9 Abi3bp -0.432 -0.107 ## 10 Abl2 -0.0188 -0.0550 ## # … with 1,464 more rows We can save the table as a CSV file in our data_output folder. write_csv(rna_FC, file = &quot;data_output/rna_FC.csv&quot;) 5.9 Additional exercises ► Question We are going to re-analyse beer consumption in 48 individuals using dplyr. The data are available in the rWSBIM1207 package. The data illustrated the fictive beer consumption in litres per year at different age according to gender and employment. Load the rWSBIM1207 package. If the package isn’t installed of its version is older than 0.1.1, install it from the UCLouvain-CBIO/rWSBIM1207' GitHub repository using thedevtools::install_github` function. Directly load the data by typing data(beers) Remove observations with missing values. Using the Year, Month and Year columns, create a new column Date using dplyr::mutate and lubridate::ymd. What is the class of Date ? Create a new table, containing observations for women older than 35 years old, employed, and select all columns except Day, Month and Year, and order in descending value of consumption of beers. Export the new table to a csv file. Beer consumption analysis: Does employment status have an impact on beer consumption? Do men drink more than women? Does employment status have an influence on beer consumption according to gender? Do men drink more than women according to age and employment status? As we can see from the last exercise, it become difficult to read and interpret multiple results. In the next chapter, we will see how to complement such analysis questions with visualisations such as the following one, that clearly highlight important patterns in our data. Figure 5.1: Visualisation of beer consumption, highlighting different patterns of beer consumption in employed and unemployed males and females. ► Question The Cancer Genome Atlas (TCGA) is a large scale effort that has collected high throughput biology data from hundreds of patients samples. In this exercise, we are going to analyse the clinical variables recorded for a subset of the patients. Load the rWSBIM1207 package. If the package isn’t installed of its version is older than 0.1.1, install it from the UCLouvain-CBIO/rWSBIM1207' GitHub repository using thedevtools::install_github` function. Using the clinical1.csv() function from rWSBIM1207, find the path the clinical1.csv file and read it to produce a data.frame named clinical. Familiarise yourself with the data. Create a smaller data frame called clinical_mini containing only the columns corresponding to patientID, gender, age_at_diagnosis, smoking_history, number_pack_years_smoked, year_of_tobacco_smoking_onset, and stopped_smoking_year. Calculate the number of males and females in the cohort. Create a new variable years_at_diagnosis corresponding to the age at diagnosis converted from days into years. Calculate the mean and median age at diagnosis (in years). Pay attention to missing values! Calculate the mean and median age at diagnosis for males and females. How many patient were diagnosed before 50 years? Compare the mean age at diagnosis between current smoker and lifelong non-smoker. Select patients who stopped smoking more than 15 years ago and calculate the number of smoking years for these cases. Display only cases for which you were able to calculate the data. How many of them smoked less than 5 years? Try to recreate the following table, reporting the number of smokers and lifelong-non smoker between males and females. Note: the layout can be different. gender current smoker lifelong non-smoker female 51 55 male 69 20 ► Question Using the interroA.csv() function from the rWSBIM1207 package to get the path to the spreadsheet file, read the data into R using the read_csv function. This data is in the wide format, with the results of each test stored as a separate column. Using the appropriate pivot function, convert the data into a long table with a column interro informing which test that line refers to and a column result with the student’s mark. "],["sec-vis.html", "Chapter 6 Data visualization 6.1 Plotting with ggplot2 6.2 Building your plots iteratively 6.3 Boxplot 6.4 Line plots 6.5 Faceting 6.6 ggplot2 themes 6.7 Customisation 6.8 Composing plots 6.9 Exporting plots 6.10 Other packages for visualisation 6.11 Additional exercises", " Chapter 6 Data visualization Learning Objectives Produce scatter plots, boxplots, and time series plots using ggplot. Set universal plot settings. Describe what faceting is and apply faceting in ggplot. Modify the aesthetics of an existing ggplot plot (including axis labels and color). Build complex and customized plots from data in a data frame. We start by loading the required packages. ggplot2 is included in the tidyverse package. library(&quot;tidyverse&quot;) If not still in the workspace, load the data we saved in the previous lesson. rna &lt;- read.csv(&quot;data/rnaseq.csv&quot;) The Data Visualization Cheat Sheet will cover the basics and more advanced features of ggplot2 and will help, in addition to serve as a reminder, getting an overview of the many data representations available in the package. The following video tutorials (part 1 and 2) by Thomas Lin Pedersen are also very instructive. 6.1 Plotting with ggplot2 ggplot2 is a plotting package that makes it simple to create complex plots from data in a data frame. It provides a more programmatic interface for specifying what variables to plot, how they are displayed, and general visual properties. The theoretical foundation that supports the ggplot2 is the Grammar of Graphics (Wilkinson (2005)). Using this approach, we only need minimal changes if the underlying data change or if we decide to change from a bar plot to a scatterplot. This helps in creating publication quality plots with minimal amounts of adjustments and tweaking. There is a book about ggplot2 (Wickham (2016)) that provides a good overview, but it is outdated. The 3rd edition is in preparation and will be freely available online. The ggplot2 webpage (https://ggplot2.tidyverse.org) provides ample documentation. ggplot2 functions like data in the ‘long’ format, i.e., a column for every dimension, and a row for every observation. Well-structured data will save you lots of time when making figures with ggplot2. ggplot graphics are built step by step by adding new elements. Adding layers in this fashion allows for extensive flexibility and customization of plots. To build a ggplot, we will use the following basic template that can be used for different types of plots: ggplot(data = &lt;DATA&gt;, mapping = aes(&lt;MAPPINGS&gt;)) + &lt;GEOM_FUNCTION&gt;() use the ggplot() function and bind the plot to a specific data frame using the data argument ggplot(data = rna) define a mapping (using the aesthetic (aes) function), by selecting the variables to be plotted and specifying how to present them in the graph, e.g. as x/y positions or characteristics such as size, shape, color, etc. ggplot(data = rna, mapping = aes(x = expression)) add ‘geoms’ – geometries, or graphical representations of the data in the plot (points, lines, bars). ggplot2 offers many different geoms; we will use some common ones today, including: * `geom_point()` for scatter plots, dot plots, etc. * `geom_boxplot()` for, well, boxplots! * `geom_line()` for trend lines, time series, etc. * `geom_histogram()` for histograms To add a geom(etry) to the plot use the + operator. Because we have two continuous variables, let’s use geom_histogram() first: ggplot(data = rna, mapping = aes(x = expression)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. The + in the ggplot2 package is particularly useful because it allows you to modify existing ggplot objects. This means you can easily set up plot templates and conveniently explore different types of plots, so the above plot can also be generated with code like this: # Assign plot to a variable rna_plot &lt;- ggplot(data = rna, mapping = aes(x = expression)) # Draw the plot rna_plot + geom_histogram() ► Question You have probably noticed an automatic message that appears when drawing the histogram: ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Change the arguments bins or binwidth of geom_histogram() to change the number or width of the bins. ► Solution # change bins ggplot(rna, aes(x = expression)) + geom_histogram(bins = 15) # change binwidth ggplot(rna, aes(x = expression)) + geom_histogram(binwidth = 2000) We can observe here that the data are skewed to the right. We can apply log2 transformation to have a more symmetric distribution. Note that we add here a small constant value (+1) to avoid having -Inf values returned for expression values equal to 0. rna &lt;- rna %&gt;% mutate(expression_log = log2(expression + 1)) If we now draw the histogram of the log2-transformed expressions, the distribution is indeed closer to a normal distribution. ggplot(rna, aes(x = expression_log)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. From now on we will work on the log-transformed expression values. ► Question Another way to visualize this transformation is to consider the scale of the observations. For example, it may be worth changing the scale of the axis to better distribute the observations in the space of the plot. Changing the scale of the axes is done similarly to adding/modifying other components (i.e., by incrementally adding commands). Try making these modifications: Represent expression on the log10 scale; see scale_x_log10(). Compare it with the previous graph. Why do you now have a warning message appearing here? ► Solution ggplot(data = rna,mapping = aes(x = expression_log))+ geom_histogram() + scale_x_log10() ## Warning: Transformation introduced infinite values in continuous x-axis ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 507 rows containing non-finite values (stat_bin). Notes Anything you put in the ggplot() function can be seen by any geom layers that you add (i.e., these are global plot settings). This includes the x- and y-axis mapping you set up in aes(). You can also specify mappings for a given geom independently of the mappings defined globally in the ggplot() function. The + sign used to add new layers must be placed at the end of the line containing the previous layer. If, instead, the + sign is added at the beginning of the line containing the new layer, ggplot2 will not add the new layer and will return an error message. # This is the correct syntax for adding layers rna_plot + geom_histogram() # This will not add the new layer and will return an error message rna_plot + geom_histogram() 6.2 Building your plots iteratively We will now draw a scatter plot with two continuous variables and the geom_point() function. This graph will represent the log2 fold changes comparing time 8 versus time 0 and time 4 versus time 0. To this end, we first need to compute the means of the log-transformed expression values by gene and time then the log fold changes by subtracting the mean log expressions between time 8 and time 0 and between time 4 and time 0. Note that we also include here the gene biotype that we will use later on to represent the genes. rna_FC &lt;- rna %&gt;% select(gene, time, gene_biotype, expression_log) %&gt;% group_by(gene, time, gene_biotype) %&gt;% summarize(mean_exp = mean(expression_log)) %&gt;% pivot_wider(names_from = time, values_from = mean_exp) %&gt;% mutate(time_8_vs_0 = `8` - `0`, time_4_vs_0 = `4` - `0`) ## `summarise()` has grouped output by &#39;gene&#39;, &#39;time&#39;. You can override using the `.groups` argument. We can then build a ggplot with the newly created dataset rna_FC. Building plots with ggplot2 is typically an iterative process. We start by defining the dataset we’ll use, lay out the axes, and choose a geom: ggplot(data = rna_FC, mapping = aes(x = time_4_vs_0, y = time_8_vs_0)) + geom_point() Then, we start modifying this plot to extract more information from it. For instance, we can add transparency (alpha) to avoid overplotting: ggplot(data = rna_FC, mapping = aes(x = time_4_vs_0, y = time_8_vs_0)) + geom_point(alpha = 0.3) We can also add colors for all the points: ggplot(data = rna_FC, mapping = aes(x = time_4_vs_0, y = time_8_vs_0)) + geom_point(alpha = 0.3, color = &quot;blue&quot;) Or to color each gene in the plot differently, you could use a vector as an input to the argument color. ggplot2 will provide a different color corresponding to different values in the vector. Here is an example where we color with gene_biotype: ggplot(data = rna_FC, mapping = aes(x = time_4_vs_0, y = time_8_vs_0)) + geom_point(alpha = 0.3, aes(color = gene_biotype)) We can also specify the colors directly inside the mapping provided in the ggplot() function. This will be seen by any geom layers and the mapping will be determined by the x- and y-axis set up in aes(). ggplot(data = rna_FC, mapping = aes(x = time_4_vs_0, y = time_8_vs_0, color = gene_biotype)) + geom_point(alpha = 0.3) Finally, we could also add a diagonal line with the geom_abline() function: ggplot(data = rna_FC, mapping = aes(x = time_4_vs_0, y = time_8_vs_0, color = gene_biotype)) + geom_point(alpha = 0.3) + geom_abline(intercept = 0) Notice that we can change the geom layer and colors will be still determined by gene_biotype ggplot(data = rna_FC, mapping = aes(x = time_4_vs_0, y = time_8_vs_0, color = gene_biotype)) + geom_jitter(alpha = 0.3) + geom_abline(intercept = 0) ► Question Scatter plots can be useful exploratory tools for small datasets. For data sets with large numbers of observations, such as the rna_FC data set, overplotting of points can be a limitation of scatter plots. One strategy for handling such settings is to use hexagonal binning of observations. The plot space is tessellated into hexagons. Each hexagon is assigned a color based on the number of observations that fall within its boundaries. To use hexagonal binning ggplot2, first install the R package hexbin from CRAN and load it. Then use the geom_hex() function to produce the hexbin figure. What are the relative strengths and weaknesses of a hexagonal bin plot compared to a scatter plot? Examine the above scatter plot and compare it with the hexagonal bin plot that you created. ► Solution install.packages(&quot;hexbin&quot;) library(&quot;hexbin&quot;) ggplot(data = rna_FC, mapping = aes(x = time_4_vs_0, y = time_8_vs_0)) + geom_hex() + geom_abline(intercept = 0) ► Question Use what you just learned to create a scatter plot of expression_log over sample from the rna dataset with the time showing in different colors. Is this a good way to show this type of data? ► Solution ggplot(data = rna, mapping = aes(y = expression_log, x = sample)) + geom_point(aes(color = time)) 6.3 Boxplot We can use boxplots to visualize the distribution of gene expressions within each sample: ggplot(data = rna, mapping = aes(y = expression_log, x = sample)) + geom_boxplot() By adding points to boxplot, we can have a better idea of the number of measurements and of their distribution: ggplot(data = rna, mapping = aes(y = expression_log, x = sample)) + geom_jitter(alpha = 0.2, color = &quot;tomato&quot;) + geom_boxplot(alpha = 0) Note how the boxplot layer is in front of the jitter layer? What do you need to change in the code to put the boxplot below the points? You may notice that the values on the x-axis are still not properly readable. Let’s change the orientation of the labels and adjust them vertically and horizontally so they don’t overlap. You can use a 90-degree angle, or experiment to find the appropriate angle for diagonally oriented labels: ggplot(data = rna, mapping = aes(y = expression_log, x = sample)) + geom_jitter(alpha = 0.2, color = &quot;tomato&quot;) + geom_boxplot(alpha = 0) + theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5)) ► Question Add color to the data points on your boxplot according to the duration of the infection (time). Hint: Check the class for time. Consider changing the class of time from integer to factor. Why does this change how R makes the graph? ► Solution # time as integer ggplot(data = rna, mapping = aes(y = expression_log, x = sample)) + geom_jitter(alpha = 0.2, aes(color = time)) + geom_boxplot(alpha = 0) + theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5)) # time as factor ggplot(data = rna, mapping = aes(y = expression_log, x = sample)) + geom_jitter(alpha = 0.2, aes(color = as.factor(time))) + geom_boxplot(alpha = 0) + theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5)) ► Question Boxplots are useful summaries, but hide the shape of the distribution. For example, if the distribution is bimodal, we would not see it in a boxplot. An alternative to the boxplot is the violin plot, where the shape (of the density of points) is drawn. Replace the box plot with a violin plot; see geom_violin(). Fill in the violins according to the time with fill. ► Solution ggplot(data = rna, mapping = aes(y = expression_log, x = sample)) + geom_violin(aes(fill = as.factor(time))) + theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5)) ► Question Modify the violin plot to fill in the violins by sex. ► Solution ggplot(data = rna, mapping = aes(y = expression_log, x = sample)) + geom_violin(aes(fill = sex)) + theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5)) 6.4 Line plots Let’s calculate the mean expression per duration of the infection for the 10 genes having the highest log fold changes comparing time 8 versus time 0. First, we need to select the genes and create a subset of rna called sub_rna containing the 10 selected genes, then we need to group the data and calculate the mean gene expression within each group: rna_FC &lt;- rna_FC %&gt;% arrange(desc(time_8_vs_0)) sub_rna &lt;- rna %&gt;% filter(gene %in% rna_FC[1:10,&quot;gene&quot;, drop=TRUE]) mean_exp_by_time &lt;- sub_rna %&gt;% group_by(gene,time) %&gt;% summarize(mean_exp = mean(expression_log)) ## `summarise()` has grouped output by &#39;gene&#39;. You can override using the `.groups` argument. We can build the line plot with duration of the infection on the x-axis and the mean expression on the y-axis: ggplot(data = mean_exp_by_time, mapping = aes(x = time, y = mean_exp)) + geom_line() Unfortunately, this does not work because we plotted data for all the genes together. We need to tell ggplot to draw a line for each gene by modifying the aesthetic function to include group = gene: ggplot(data = mean_exp_by_time, mapping = aes(x = time, y = mean_exp, group = gene)) + geom_line() We will be able to distinguish genes in the plot if we add colors (using color also automatically groups the data): ggplot(data = mean_exp_by_time, mapping = aes(x = time, y = mean_exp, color = gene)) + geom_line() 6.5 Faceting ggplot2 has a special technique called faceting that allows the user to split one plot into multiple (sub) plots based on a factor included in the dataset. These different subplots inherit the same properties (axes limits, ticks, …) to facilitate their direct comparison. We will use it to make a line plot across time for each gene: ggplot(data = mean_exp_by_time, mapping = aes(x = time, y = mean_exp)) + geom_line() + facet_wrap(~ gene) Here both x- and y-axis have the same scale for all the sub plots. You can change this default behavior by modifying scales in order to allow a free scale for the y-axis: ggplot(data = mean_exp_by_time, mapping = aes(x = time, y = mean_exp)) + geom_line() + facet_wrap(~ gene, scales = &quot;free_y&quot;) Now we would like to split the line in each plot by the sex of the mice. To do that we need to make the mean expression in the data frame grouped by gene, time, and sex: mean_exp_by_time_sex &lt;- sub_rna %&gt;% group_by(gene, time, sex) %&gt;% summarize(mean_exp = mean(expression_log)) ## `summarise()` has grouped output by &#39;gene&#39;, &#39;time&#39;. You can override using the `.groups` argument. We can now make the faceted plot by splitting further by sex using color (within a single plot): ggplot(data = mean_exp_by_time_sex, mapping = aes(x = time, y = mean_exp, color = sex)) + geom_line() + facet_wrap(~ gene, scales = &quot;free_y&quot;) Usually plots with white background look more readable when printed. We can set the background to white using the function theme_bw(). Additionally, we can remove the grid: ggplot(data = mean_exp_by_time_sex, mapping = aes(x = time, y = mean_exp, color = sex)) + geom_line() + facet_wrap(~ gene, scales = &quot;free_y&quot;) + theme_bw() + theme(panel.grid = element_blank()) ► Question Use what you just learned to create a plot that depicts how the average expression of each chromosome changes through the duration of infection. ► Solution mean_exp_by_chromosome &lt;- rna %&gt;% group_by(chromosome_name, time) %&gt;% summarize(mean_exp = mean(expression_log)) ## `summarise()` has grouped output by &#39;chromosome_name&#39;. You can override using the `.groups` argument. ggplot(data = mean_exp_by_chromosome, mapping = aes(x = time, y = mean_exp)) + geom_line() + facet_wrap(~ chromosome_name, scales = &quot;free_y&quot;) The facet_wrap geometry extracts plots into an arbitrary number of dimensions to allow them to cleanly fit on one page. On the other hand, the facet_grid geometry allows you to explicitly specify how you want your plots to be arranged via formula notation (rows ~ columns; a . can be used as a placeholder that indicates only one row or column). Let’s modify the previous plot to compare how the mean gene expression of males and females has changed through time: # One column, facet by rows ggplot(data = mean_exp_by_time_sex, mapping = aes(x = time, y = mean_exp, color = gene)) + geom_line() + facet_grid(sex ~ .) # One row, facet by column ggplot(data = mean_exp_by_time_sex, mapping = aes(x = time, y = mean_exp, color = gene)) + geom_line() + facet_grid(. ~ sex) 6.6 ggplot2 themes In addition to theme_bw(), which changes the plot background to white, ggplot2 comes with several other themes which can be useful to quickly change the look of your visualization. The complete list of themes is available at http://docs.ggplot2.org/current/ggtheme.html. theme_minimal() and theme_light() are popular, and theme_void() can be useful as a starting point to create a new hand-crafted theme. The ggthemes package provides a wide variety of options (including an Excel 2003 theme). The ggplot2 extensions website provides a list of packages that extend the capabilities of ggplot2, including additional themes. 6.7 Customisation Take a look at the ggplot2 cheat sheet, and think of ways you could improve the plot. Now, let’s change names of axes to something more informative than ‘time’ and ‘mean_exp,’ add a title to the figure and change the colour legend title: ggplot(data = mean_exp_by_time_sex, mapping = aes(x = time, y = mean_exp, color = sex)) + geom_line() + facet_wrap(~ gene, scales = &quot;free_y&quot;) + labs(title = &quot;Mean gene expression by duration of the infection&quot;, x = &quot;Duration of the infection (in days)&quot;, y = &quot;Mean gene expression&quot;) + guides(color = guide_legend(title = &quot;Gender&quot;)) + theme_bw() The axes have more informative names, but their readability can be improved by increasing the font size: ggplot(data = mean_exp_by_time_sex, mapping = aes(x = time, y = mean_exp, color = sex)) + geom_line() + facet_wrap(~ gene, scales = &quot;free_y&quot;) + labs(title = &quot;Mean gene expression by duration of the infection&quot;, x = &quot;Duration of the infection (in days)&quot;, y = &quot;Mean gene expression&quot;) + guides(color=guide_legend(title = &quot;Gender&quot;)) + theme_bw() + theme(text = element_text(size = 16)) Note that it is also possible to change the fonts of your plots. If you are on Windows, you may have to install the extrafont package, and follow the instructions included in the README for this package. We can further customize the color of x- and y-axis text, the color of the grid, etc. We can also for example move the legend to the top by setting legend.position to \"top\". ggplot(data = mean_exp_by_time_sex, mapping = aes(x = time, y = mean_exp, color = sex)) + geom_line() + facet_wrap(~ gene, scales = &quot;free_y&quot;) + labs(title = &quot;Mean gene expression by duration of the infection&quot;, x = &quot;Duration of the infection (in days)&quot;, y = &quot;Mean gene expression&quot;) + guides(color=guide_legend(title=&quot;Gender&quot;)) + theme_bw() + theme(text = element_text(size = 16), axis.text.x = element_text(colour = &quot;royalblue4&quot;, size = 12), axis.text.y = element_text(colour = &quot;royalblue4&quot;, size = 12), panel.grid = element_line(colour=&quot;lightsteelblue1&quot;), legend.position = &quot;top&quot;) If you like the changes you created better than the default theme, you can save them as an object to be able to easily apply them to other plots you may create: blue_theme &lt;- theme(axis.text.x = element_text(colour = &quot;royalblue4&quot;, size = 12), axis.text.y = element_text(colour = &quot;royalblue4&quot;, size = 12), text = element_text(size = 16), panel.grid = element_line(colour=&quot;lightsteelblue1&quot;)) ggplot(rna, aes(x = expression_log)) + geom_histogram(bins = 20) + blue_theme ► Question With all of this information in hand, please take another five minutes to either improve one of the plots generated in this exercise or create a beautiful graph of your own. Use the RStudio ggplot2 cheat sheet for inspiration. Here are some ideas: See if you can change the thickness of the lines. Can you find a way to change the name of the legend? What about its labels? Try using a different color palette (see http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/). 6.8 Composing plots Faceting is a great tool for splitting one plot into multiple subplots, but sometimes you may want to produce a single figure that contains multiple independent plots, i.e. plots that are based on different variables or even different data frames. Let’s start by creating the two plots that we want to arrange next to each other: The first graph counts the number of unique genes per chromosome. We first need to reorder the levels of chromosome_name and filter the unique genes per chromosome. We also change the scale of the yaxis to a log10 scale for better readability. rna$chromosome_name &lt;- factor(rna$chromosome_name, levels = c(1:19,&quot;X&quot;,&quot;Y&quot;)) count_gene_chromosome &lt;- rna %&gt;% select(chromosome_name, gene) %&gt;% distinct() %&gt;% ggplot() + geom_bar(aes(x = chromosome_name), fill = &quot;seagreen&quot;, position = &quot;dodge&quot;, stat = &quot;count&quot;) + labs(y = &quot;log10(n genes)&quot;, x = &quot;chromosome&quot;) + scale_y_log10() count_gene_chromosome Below, we also remove the legend altogether by setting the legend.position to \"none\". exp_boxplot_sex &lt;- ggplot(rna, aes(y=expression_log, x = as.factor(time), color=sex)) + geom_boxplot(alpha = 0) + labs(y = &quot;Mean gene exp&quot;, x = &quot;time&quot;) + theme(legend.position = &quot;none&quot;) exp_boxplot_sex The patchwork package provides an elegant approach to combining figures using the + to arrange figures (typically side by side). More specifically the | explicitly arranges them side by side and / stacks them on top of each other. install.packages(&quot;patchwork&quot;) library(&quot;patchwork&quot;) count_gene_chromosome + exp_boxplot_sex ## or count_gene_chromosome | exp_boxplot_sex count_gene_chromosome / exp_boxplot_sex We can combine further control the layout of the final composition with plot_layout to create more complex layouts: count_gene_chromosome + exp_boxplot_sex + plot_layout(ncol = 1) count_gene_chromosome + (count_gene_chromosome + exp_boxplot_sex) + exp_boxplot_sex + plot_layout(ncol = 1) The last plot can also be created using the | and / composers: count_gene_chromosome / (count_gene_chromosome | exp_boxplot_sex) / exp_boxplot_sex Learn more about patchwork on its webpage or in this video. Another option is the gridExtra package that allows to combine separate ggplots into a single figure using grid.arrange(): install.packages(&quot;gridExtra&quot;) library(gridExtra) grid.arrange(count_gene_chromosome, exp_boxplot_sex, ncol = 2) In addition to the ncol and nrow arguments, used to make simple arrangements, there are tools for constructing more complex layouts. 6.9 Exporting plots After creating your plot, you can save it to a file in your favorite format. The Export tab in the Plot pane in RStudio will save your plots at low resolution, which will not be accepted by many journals and will not scale well for posters. Instead, use the ggsave() function, which allows you easily change the dimension and resolution of your plot by adjusting the appropriate arguments (width, height and dpi). Make sure you have the fig_output/ folder in your working directory. my_plot &lt;- ggplot(data = mean_exp_by_time_sex, mapping = aes(x = time, y = mean_exp, color = sex)) + geom_line() + facet_wrap(~ gene, scales = &quot;free_y&quot;) + labs(title = &quot;Mean gene expression by duration of the infection&quot;, x = &quot;Duration of the infection (in days)&quot;, y = &quot;Mean gene expression&quot;) + guides(color=guide_legend(title=&quot;Gender&quot;)) + theme_bw() + theme(axis.text.x = element_text(colour = &quot;royalblue4&quot;, size = 12), axis.text.y = element_text(colour = &quot;royalblue4&quot;, size = 12), text = element_text(size = 16), panel.grid = element_line(colour=&quot;lightsteelblue1&quot;), legend.position = &quot;top&quot;) ggsave(&quot;fig_output/mean_exp_by_time_sex.png&quot;, my_plot, width = 15, height = 10) # This also works for grid.arrange() plots combo_plot &lt;- grid.arrange(count_gene_chromosome, exp_boxplot_sex, ncol = 2, widths = c(4, 6)) ggsave(&quot;fig_output/combo_plot_chromosome_sex.png&quot;, combo_plot, width = 10, dpi = 300) Note: The parameters width and height also determine the font size in the saved plot. 6.10 Other packages for visualisation ggplot2 is a very powerful package that fits very nicely in our tidy data and tidy tools pipeline. There are other visualisation packages in R that shouldn’t be ignored. Base graphics The default graphics system that comes with R, often called base R graphics is simple and fast. It is based on the painter’s or canvas model, where different output are directly overlaid on top of each other (see figure 6.1). This is a fundamental difference with ggplot2 (and with lattice, described below), that returns dedicated objects, that are rendered on screen or in a file, and that can even be updated. par(mfrow = c(1, 3)) plot(1:20, main = &quot;First layer, produced with plot(1:20)&quot;) plot(1:20, main = &quot;A horizontal red line, added with abline(h = 10)&quot;) abline(h = 10, col = &quot;red&quot;) plot(1:20, main = &quot;A rectangle, added with rect(5, 5, 15, 15)&quot;) abline(h = 10, col = &quot;red&quot;) rect(5, 5, 15, 15, lwd = 3) Figure 6.1: Successive layers added on top of each other. Another main difference is that base graphics’ plotting function try to do the right thing based on their input type, i.e. they will adapt their behaviour based on the class of their input. This is again very different from what we have in ggplot2, that only accepts dataframes as input, and that requires plots to be constructed bit by bit. par(mfrow = c(2, 2)) boxplot(rnorm(100), main = &quot;Boxplot of rnorm(100)&quot;) boxplot(matrix(rnorm(100), ncol = 10), main = &quot;Boxplot of matrix(rnorm(100), ncol = 10)&quot;) hist(rnorm(100)) hist(matrix(rnorm(100), ncol = 10)) Figure 6.2: Plotting boxplots (top) and histograms (bottom) vectors (left) or a matrices (right). The out-of-the-box approach in base graphics can be very efficient for simple, standard figures, that can be produced very quickly with a single line of code and a single function such as plot, or hist, or boxplot, … The defaults are however not always the most appealing and tuning of figures, especially when they become more complex (for example to produce facets), can become lengthy and cumbersome. The lattice package The lattice package is similar to ggplot2 in that is uses dataframes as input, returns graphical objects and supports faceting. lattice however isn’t based on the grammar of graphics and has a more convoluted interface. A good reference for the lattice package is Deepayan (2008). 6.11 Additional exercises ► Question Load the beer consuption data with library(&quot;rWSBIM1207&quot;) data(beers) Analyse the data to answer the question Do men drink more than women according to age and working status? Now reproduce the figure below. Figure 6.3: Visualisation of beer consumption, highlighting different patterns of beer consumption in employed and unemployed males and females. ► Question We are now going to analyse transcriptomics data from the TCGA project. Using the file returned by the expression.csv() function from the rWSBIM1207 package, create a table called expression. Inspect the data. The sampleID column gives the TCGA reference of the sample and is unique. The 12 first characters (TCGA-XX-XXXX) of the samples ID are unique to each patient. The 3 last characters of the samples ID indicate the type of sample: samples ending with ‘-01A’ (TCGA-XX-XXXX-01A) correspond to tumors and samples ending with ‘-11A’ (TCGA-XX-XXXX-11A) correspond to normal peritumoral tissues. The patient column gives the reference of each patient. Note that some patient for which both tumor and normal tissue were analysed are recorded twice. The type column gives the nature of each sample (tumor or normal tissue). The 5 next column give the expression levels of 5 genes in each sample. Using geom_point, draw a plot showing distribution of expression levels of A2LD1 in normal tissue samples and in primary tumor samples. Repeat this visualisation using this time the geom_jitter. Which representation is more appropriate? Why? Colour the samples according to the tissue type. Colour the samples according to their expression level in A2ML1. Highlight the points corresponding to patient “TCGA-73-4676.” Add a transparent boxplot to the graph. Change the y scale to log10 scale. Visualise the expression of A1BG against that of A2LD1 setting the x axis on the log10 scale. Colours the observations based on their type and resize the points according to the expression level of the A2ML1 gene. ► Question After gathering the interroA data from the rWSBIM1207 package in a long table format (see additional exercise chapter 5), visualise the result distributions for each test and male/female students group. "],["sec-join.html", "Chapter 7 Joining tables 7.1 Combining tables 7.2 Different types of joins 7.3 Multiple matches 7.4 Matching across multiple keys 7.5 Merge in base R 7.6 Row and column binding 7.7 Additional exercises", " Chapter 7 Joining tables Learning Objectives At the end of this section, students should understand the need and concept of table joins, different between different types of joins, the importance of keys in joins, circumstances leading to the appearance of missing values, the implications of using non-unique keys. In many real life situations, data are spread across multiple tables or spreadsheets. Usually this occurs because different types of information about a subject, e.g. a patient, are collected from different sources. It may be desirable for some analyses to combine data from two or more tables into a single data frame based on a common column, for example, an attribute that uniquely identifies the subject. The dplyr package, that we have already used extensively, provides a set of join functions for combining two data frames based on matches within specified columns. For further reading, please refer to the chapter about table joins in Grolemund and Wickham (2017). The Data Transformation Cheat Sheet also provides a short overview on table joins. 7.1 Combining tables We are going to illustrate join using a common example from the bioinformatics world, where annotations about genes are scattered in different tables that have one or more shared columns. The data we are going to use are available in the course package and can be loaded as shown below. library(&quot;rWSBIM1207&quot;) data(jdf) The example data is composed of pairs of tables (we have tibbles here, but this would equally work with dataframes). The first member of the pair contains protein UniProt9 unique accession number (uniprot variable), the most likely sub-cellular localisation of these respective proteins (organelle variable) as well as the proteins identifier (entry). jdf1 ## # A tibble: 25 × 3 ## uniprot organelle entry ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 P26039 Actin cytoskeleton TLN1_MOUSE ## 2 Q99PL5 Endoplasmic reticulum/Golgi apparatus RRBP1_MOUSE ## 3 Q6PB66 Mitochondrion LPPRC_MOUSE ## 4 P11276 Extracellular matrix FINC_MOUSE ## 5 Q6PR54 Nucleus - Chromatin RIF1_MOUSE ## 6 Q05793 Extracellular matrix PGBM_MOUSE ## 7 P19096 Cytosol FAS_MOUSE ## 8 Q9JKF1 Plasma membrane IQGA1_MOUSE ## 9 Q9QZQ1-2 Plasma membrane AFAD_MOUSE ## 10 Q6NS46 Nucleus - Non-chromatin RRP5_MOUSE ## # … with 15 more rows The second table contains the name of the gene that codes for the protein (gene_name variable), a description of the gene (description variable), the uniprot accession number (this is the common variable that can be used to join tables) and the species the protein information comes from (organism variable). jdf2 ## # A tibble: 25 × 4 ## gene_name description uniprot organism ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Iqgap1 Ras GTPase-activating-like protein IQGAP1 Q9JKF1 Mmus ## 2 Hspa5 78 kDa glucose-regulated protein P20029 Mmus ## 3 Pdcd11 Protein RRP5 homolog Q6NS46 Mmus ## 4 Tfrc Transferrin receptor protein 1 Q62351 Mmus ## 5 Hspd1 60 kDa heat shock protein, mitochondrial P63038 Mmus ## 6 Tln1 Talin-1 P26039 Mmus ## 7 Smc1a Structural maintenance of chromosomes protein 1A Q9CU62 Mmus ## 8 Lamc1 Laminin subunit gamma-1 P02468 Mmus ## 9 Hsp90b1 Endoplasmin P08113 Mmus ## 10 Mia3 Melanoma inhibitory activity protein 3 Q8BI84 Mmus ## # … with 15 more rows We now want to join these two tables into a single one containing all variables. We are going to use dplyr’s full_join function to do so, that finds the common variable (in this case uniprot) to match observations from the first and second table. library(&quot;dplyr&quot;) full_join(jdf1, jdf2) ## Joining, by = &quot;uniprot&quot; ## # A tibble: 25 × 6 ## uniprot organelle entry gene_name description organism ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 P26039 Actin cytoskele… TLN1_M… Tln1 Talin-1 Mmus ## 2 Q99PL5 Endoplasmic ret… RRBP1_… Rrbp1 Ribosome-binding protei… Mmus ## 3 Q6PB66 Mitochondrion LPPRC_… Lrpprc Leucine-rich PPR motif-… Mmus ## 4 P11276 Extracellular m… FINC_M… Fn1 Fibronectin Mmus ## 5 Q6PR54 Nucleus - Chrom… RIF1_M… Rif1 Telomere-associated pro… Mmus ## 6 Q05793 Extracellular m… PGBM_M… Hspg2 Basement membrane-speci… Mmus ## 7 P19096 Cytosol FAS_MO… Fasn Fatty acid synthase Mmus ## 8 Q9JKF1 Plasma membrane IQGA1_… Iqgap1 Ras GTPase-activating-l… Mmus ## 9 Q9QZQ1-2 Plasma membrane AFAD_M… Mllt4 Isoform 1 of Afadin Mmus ## 10 Q6NS46 Nucleus - Non-c… RRP5_M… Pdcd11 Protein RRP5 homolog Mmus ## # … with 15 more rows In the examples above, each observation of the jdf1 and jdf2 tables are uniquely identified by their UniProt accession number. Such variables are called keys. Keys are used to match observations across different tables. In case none of the variable names match, those to be used can be set manually using the by argument, as shown below with the jdf1 (as above) and jdf3 tables, where the UniProt accession number is encoded using a different capitalisation. names(jdf3) ## [1] &quot;gene_name&quot; &quot;description&quot; &quot;UniProt&quot; &quot;organism&quot; full_join(jdf1, jdf3, by = c(&quot;uniprot&quot; = &quot;UniProt&quot;)) ## # A tibble: 25 × 6 ## uniprot organelle entry gene_name description organism ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 P26039 Actin cytoskele… TLN1_M… Tln1 Talin-1 Mmus ## 2 Q99PL5 Endoplasmic ret… RRBP1_… Rrbp1 Ribosome-binding protei… Mmus ## 3 Q6PB66 Mitochondrion LPPRC_… Lrpprc Leucine-rich PPR motif-… Mmus ## 4 P11276 Extracellular m… FINC_M… Fn1 Fibronectin Mmus ## 5 Q6PR54 Nucleus - Chrom… RIF1_M… Rif1 Telomere-associated pro… Mmus ## 6 Q05793 Extracellular m… PGBM_M… Hspg2 Basement membrane-speci… Mmus ## 7 P19096 Cytosol FAS_MO… Fasn Fatty acid synthase Mmus ## 8 Q9JKF1 Plasma membrane IQGA1_… Iqgap1 Ras GTPase-activating-l… Mmus ## 9 Q9QZQ1-2 Plasma membrane AFAD_M… Mllt4 Isoform 1 of Afadin Mmus ## 10 Q6NS46 Nucleus - Non-c… RRP5_M… Pdcd11 Protein RRP5 homolog Mmus ## # … with 15 more rows As can be seen above, the variable name of the first table is retained in the joined one. ► Question Using the full_join function demonstrated above, join tables jdf4 and jdf5. What has happened for observations P26039 and P02468? ► Solution full_join(jdf4, jdf5) ## Joining, by = &quot;uniprot&quot; ## # A tibble: 14 × 6 ## uniprot organelle entry gene_name description organism ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 P26039 Actin cytoskele… TLN1_… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 Q99PL5 Endoplasmic ret… RRBP1… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 3 Q6PB66 Mitochondrion LPPRC… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 4 P11276 Extracellular m… FINC_… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 5 Q6PR54 Nucleus - Chrom… RIF1_… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 6 Q05793 Extracellular m… PGBM_… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 7 P19096 Cytosol FAS_M… Fasn Fatty acid synthase Mmus ## 8 Q9JKF1 Plasma membrane IQGA1… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 9 Q9QZQ1-2 Plasma membrane AFAD_… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 10 Q6NS46 Nucleus - Non-c… RRP5_… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 11 P02468 &lt;NA&gt; &lt;NA&gt; Lamc1 Laminin subunit gamma-1 Mmus ## 12 P08113 &lt;NA&gt; &lt;NA&gt; Hsp90b1 Endoplasmin Mmus ## 13 Q8BI84 &lt;NA&gt; &lt;NA&gt; Mia3 Melanoma inhibitory acti… Mmus ## 14 Q6P5D8 &lt;NA&gt; &lt;NA&gt; Smchd1 Structural maintenance o… Mmus P02468 and P02468 are only present in jdf4 and jdf5 respectively, and their respective values for the variables of the table have been encoded as missing. 7.2 Different types of joins Above, we have used the full_join function, that fully joins two tables and keeps all observations, adding missing values if necessary. Sometimes, we want to be selective, and keep observations that are present in only one or both tables. An inner join keeps observations that are present in both tables. Figure 7.1: An inner join matches pairs of observation matching in both tables, this dropping those that are unique to one table. Figure taken from R for Data Science. A left join keeps observations that are present in the left (first) table, dropping those that are only present in the other. A right join keeps observations that are present in the right (second) table, dropping those that are only present in the other. A full join keeps all observations. Figure 7.2: Outer joins match observations that appear in at least on table, filling up missing values with NA values. Figure taken from R for Data Science. ► Question Join tables jdf4 and jdf5, keeping only observations in jdf4. ► Solution left_join(jdf4, jdf5) ## Joining, by = &quot;uniprot&quot; ## # A tibble: 10 × 6 ## uniprot organelle entry gene_name description organism ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 P26039 Actin cytoskeleton TLN1_MO… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 Q99PL5 Endoplasmic reticulum/G… RRBP1_M… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 3 Q6PB66 Mitochondrion LPPRC_M… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 4 P11276 Extracellular matrix FINC_MO… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 5 Q6PR54 Nucleus - Chromatin RIF1_MO… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 6 Q05793 Extracellular matrix PGBM_MO… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 7 P19096 Cytosol FAS_MOU… Fasn Fatty acid syn… Mmus ## 8 Q9JKF1 Plasma membrane IQGA1_M… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 9 Q9QZQ1-2 Plasma membrane AFAD_MO… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 10 Q6NS46 Nucleus - Non-chromatin RRP5_MO… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ► Question Join tables jdf4 and jdf5, keeping only observations in jdf5. ► Solution right_join(jdf4, jdf5) ## Joining, by = &quot;uniprot&quot; ## # A tibble: 5 × 6 ## uniprot organelle entry gene_name description organism ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 P19096 Cytosol FAS_MOUSE Fasn Fatty acid synthase Mmus ## 2 P02468 &lt;NA&gt; &lt;NA&gt; Lamc1 Laminin subunit gamma-1 Mmus ## 3 P08113 &lt;NA&gt; &lt;NA&gt; Hsp90b1 Endoplasmin Mmus ## 4 Q8BI84 &lt;NA&gt; &lt;NA&gt; Mia3 Melanoma inhibitory activity p… Mmus ## 5 Q6P5D8 &lt;NA&gt; &lt;NA&gt; Smchd1 Structural maintenance of chro… Mmus ► Question Join tables jdf4 and jdf5, keeping observations observed in both tables. ► Solution inner_join(jdf4, jdf5) ## Joining, by = &quot;uniprot&quot; ## # A tibble: 1 × 6 ## uniprot organelle entry gene_name description organism ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 P19096 Cytosol FAS_MOUSE Fasn Fatty acid synthase Mmus 7.3 Multiple matches Sometimes, keys aren’t unique. In the jdf6 table below, we see that the accession number Q99PL5 is repeated twice. According to this table, the ribosomial protein binding protein 1 localises in the endoplasmic reticulum (often abbreviated ER) and in the Golgi apparatus (often abbreviated GA). jdf6 ## # A tibble: 5 × 4 ## uniprot organelle entry isoform ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 P26039 Actin cytoskeleton TLN1_MOUSE 1 ## 2 Q99PL5 Endoplasmic reticulum RRBP1_MOUSE 1 ## 3 Q99PL5 Golgi apparatus RRBP1_MOUSE 2 ## 4 Q6PB66 Mitochondrion LPPRC_MOUSE 1 ## 5 P11276 Extracellular matrix FINC_MOUSE 1 If we now want to join jdf6 and jdf2, the variables of the latter will be duplicated. inner_join(jdf6, jdf2) ## Joining, by = &quot;uniprot&quot; ## # A tibble: 5 × 7 ## uniprot organelle entry isoform gene_name description organism ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 P26039 Actin cytoskeleton TLN1_MOUSE 1 Tln1 Talin-1 Mmus ## 2 Q99PL5 Endoplasmic reticulum RRBP1_MOUSE 1 Rrbp1 Ribosome-b… Mmus ## 3 Q99PL5 Golgi apparatus RRBP1_MOUSE 2 Rrbp1 Ribosome-b… Mmus ## 4 Q6PB66 Mitochondrion LPPRC_MOUSE 1 Lrpprc Leucine-ri… Mmus ## 5 P11276 Extracellular matrix FINC_MOUSE 1 Fn1 Fibronectin Mmus In the case above, repeating is useful, as it completes jdf6 with correct information from jdf2. One needs however to be careful when duplicated keys exist in both tables. Below, we create an inner join between jdf6 and jdf7, both having duplicated Q99PL5 entries. inner_join(jdf6, jdf7) ## Joining, by = &quot;uniprot&quot; ## # A tibble: 4 × 9 ## uniprot organelle entry isoform gene_name description organism isoform_num ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Q99PL5 Endoplasmi… RRBP1… 1 Rrbp1 Ribosome-bi… Mmus 1 ## 2 Q99PL5 Endoplasmi… RRBP1… 1 Rrbp1 Ribosome-bi… Mmus 2 ## 3 Q99PL5 Golgi appa… RRBP1… 2 Rrbp1 Ribosome-bi… Mmus 1 ## 4 Q99PL5 Golgi appa… RRBP1… 2 Rrbp1 Ribosome-bi… Mmus 2 ## # … with 1 more variable: measure &lt;dbl&gt; ► Question Interpret the result of the inner join above, where both tables have duplicated keys. ► Solution jdf6 has two entries, one for each possible sub-cellular localisation of the protein. jdf7 has also two entries, referring to two different quantitative measurements (variable measure). When joining the duplicated keys, you get all possible combinations. Figure 7.3: Joins with duplicated keys in both tables, producing all possible combinations. Figure taken from R for Data Science. In this case, we obtain wrong information: both proteins in the ER and in the GA both have value 102 and 3. 7.4 Matching across multiple keys So far, we have matched tables using a single key (possibly with different names in the two tables). Sometimes, it is necessary to match tables using multiple keys. A typical example is when multiple variables are needed to discriminate different rows in a tables. Following up from the last example, we see that the duplicated UniProt accession numbers in the jdf6 and jdf7 tables refer to different isoforms of the same RRBP1 gene. To uniquely identify isoforms, we need to consider two keys, namely the UniProt accession number (named uniprot in both tables) as well as the isoform number, called isoform and isoform_num respectively. Because the isoform status was encoded using different variable names (which is, of course a source of confusion), jdf6 and jdf7 are only automatically joined based on the shared uniprot key. Here, we need to join using both keys and need to explicitly name the variables used for the join. inner_join(jdf6, jdf7, by = c(&quot;uniprot&quot; = &quot;uniprot&quot;, &quot;isoform&quot; = &quot;isoform_num&quot;)) ## # A tibble: 2 × 8 ## uniprot organelle entry isoform gene_name description organism measure ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Q99PL5 Endoplasmic… RRBP1_… 1 Rrbp1 Ribosome-bind… Mmus 102 ## 2 Q99PL5 Golgi appar… RRBP1_… 2 Rrbp1 Ribosome-bind… Mmus 3 We now see that isoform 1 localised to the ER and has a measured value of 102, while isoform 2, that localised to the GA, has a measured value of 3. ► Question Can you think of another way to merge tables jdf6 and jdf7 using the two keys? ► Solution Ideally, the isoform variables should be named identically in the two tables, which would enable and automatic join with the two keys. Below, we first fix the misnamed variable in jdf7. Instead of updating the variable name by checking its index manually, we grep it programmatically and store it in a new variable i. We can then join the two tables without having to specify the two keys explicitly. i &lt;- grep(&quot;isoform&quot;, names(jdf7)) names(jdf7)[i] &lt;- &quot;isoform&quot; inner_join(jdf6, jdf7) ## Joining, by = c(&quot;uniprot&quot;, &quot;isoform&quot;) ## # A tibble: 2 × 8 ## uniprot organelle entry isoform gene_name description organism measure ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Q99PL5 Endoplasmic… RRBP1_… 1 Rrbp1 Ribosome-bind… Mmus 102 ## 2 Q99PL5 Golgi appar… RRBP1_… 2 Rrbp1 Ribosome-bind… Mmus 3 7.5 Merge in base R Above, we have used several join functions from the dplyr package as they are convenient and easy to remember. The equivalent function in the base package, that is installed with R, is the merge function. The table below shows how these are related: dplyr merge inner_join(x, y) merge(x, y) left_join(x, y) merge(x, y, all.x = TRUE) right_join(x, y) merge(x, y, all.y = TRUE), full_join(x, y) merge(x, y, all.x = TRUE, all.y = TRUE) Even if you decide to stick with one of these alternatives, it is important to be aware of the other one, especially given the widespread usage of merge in many packages and in R itself. 7.6 Row and column binding There are other two important functions in R, that can be used to combine two dataframes, but assume that these already match beforehand, as summerised in figure 7.4 below. Figure 7.4: Matching dimension and names when binding by rows and columns. We are going to illustrate binding by columns with dataframes d1 and d2, and then binding by rows using d2 and d3. Lets start with d1 and d2 shown below; both have the same number of columns but, and this is crucial, do not have the same column names: d1 ## x y ## 1 1 1 ## 2 2 2 ## 3 3 3 d2 ## a b ## 1 4 4 ## 2 5 5 While de number of columns match, the names don’t, which results in an error10 when we use rbind: try(rbind(d1, d2)) ## Error in match.names(clabs, names(xi)) : ## les noms ne correspondent pas aux noms précédents Before rbinding two dataframes, we must assure that their number of columns and rownames match exactly: names(d2) &lt;- names(d1) rbind(d1, d2) ## x y ## 1 1 1 ## 2 2 2 ## 3 3 3 ## 4 4 4 ## 5 5 5 If we want to bind to dataframes along their columns, we must make sure that their number of rows match; rownames not hinder here: cbind(d2, d3) ## x y v1 v2 v3 ## 1 4 4 1 3 5 ## 2 5 5 2 4 6 Note that beyond the dimensions and column names that are required to match, the real meaning of rbind is to bind dataframes that contain observations for the same set of variables - there is more than only the column names. Below, we rbind dataframes with identical column names but different variables, which end up all being coerced into characters. d1 ## x y ## 1 1 1 ## 2 2 2 ## 3 3 3 d4 &lt;- data.frame(x = letters[1:2], y = letters[1:2]) str(rbind(d1, d4)) ## &#39;data.frame&#39;: 5 obs. of 2 variables: ## $ x: chr &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;a&quot; ... ## $ y: chr &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;a&quot; ... Note: rbind and cbind are base R functions. The tidyverse alternatives from the dplyr package are bind_rows and bind_cols and work similarly. 7.7 Additional exercises ► Question Using the jdf4 and jdf5 tables, emulate the left, right and inner joins using a the full join and filter functions. ► Question Load the rWSBIM1207 package. Using the data function, directly load the clinical2 and expression data into your global environment. Inspect the clinical data. What kind of information do we have and how many patients are recorded? Inspect the expression data. How many samples are recorded? Join the expression and clinical2 tables by the patient reference, using the left_join and the right_join functions. Why are the results different? Join expression and clinical2 tables in order to create a table containing merged data exclusively for normal samples. UniProt is the protein information database. Its mission is to provide the scientific community with a comprehensive, high-quality and freely accessible resource of protein sequence and functional information.↩︎ The failing call to rbind is wrapped into a try call here to stop the error from aborting the document compilation.↩︎ "],["session-information.html", "Chapter 8 Session information 8.1 R package setup", " Chapter 8 Session information The following packages have been used to generate this document. sessionInfo() ## R version 4.1.0 (2021-05-18) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Big Sur 10.16 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib ## ## locale: ## [1] C/UTF-8/C/C/C/C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] gridExtra_2.3 patchwork_1.1.1 hexbin_1.28.2 magrittr_2.0.1 ## [5] rWSBIM1207_0.1.14 forcats_0.5.1 stringr_1.4.0 dplyr_1.0.7 ## [9] purrr_0.3.4 readr_2.0.1 tidyr_1.1.3 tibble_3.1.4 ## [13] ggplot2_3.3.5 tidyverse_1.3.1 lubridate_1.7.10 ## ## loaded via a namespace (and not attached): ## [1] Rcpp_1.0.7 lattice_0.20-44 msmbstyle_0.0.19 png_0.1-7 ## [5] assertthat_0.2.1 digest_0.6.27 utf8_1.2.2 R6_2.5.1 ## [9] cellranger_1.1.0 backports_1.2.1 reprex_2.0.1 evaluate_0.14 ## [13] httr_1.4.2 highr_0.9 pillar_1.6.2 rlang_0.4.11 ## [17] readxl_1.3.1 rstudioapi_0.13 jquerylib_0.1.4 rmarkdown_2.11 ## [21] labeling_0.4.2 bit_4.0.4 munsell_0.5.0 broom_0.7.9 ## [25] compiler_4.1.0 modelr_0.1.8 xfun_0.26 pkgconfig_2.0.3 ## [29] htmltools_0.5.2 tidyselect_1.1.1 bookdown_0.24 fansi_0.5.0 ## [33] crayon_1.4.1 tzdb_0.1.2 dbplyr_2.1.1 withr_2.4.2 ## [37] grid_4.1.0 jsonlite_1.7.2 gtable_0.3.0 lifecycle_1.0.0 ## [41] DBI_1.1.1 scales_1.1.1 cli_3.0.1 stringi_1.7.4 ## [45] vroom_1.5.5 farver_2.1.0 fs_1.5.0 xml2_1.3.2 ## [49] bslib_0.3.0 ellipsis_0.3.2 generics_0.1.0 vctrs_0.3.8 ## [53] tools_4.1.0 bit64_4.0.5 glue_1.4.2 hms_1.1.0 ## [57] parallel_4.1.0 fastmap_1.1.0 yaml_2.2.1 colorspace_2.0-2 ## [61] rvest_1.0.1 knitr_1.34 haven_2.4.3 sass_0.4.0 8.1 R package setup To install all necessary packages to run all the code, please execute the following code: pkgs &lt;- c(&quot;base&quot;, &quot;datasets&quot;, &quot;dplyr&quot;, &quot;forcats&quot;, &quot;ggplot2&quot;, &quot;grDevices&quot;, &quot;graphics&quot;, &quot;gridExtra&quot;, &quot;hexbin&quot;, &quot;lubridate&quot;, &quot;magrittr&quot;, &quot;methods&quot;, &quot;patchwork&quot;, &quot;purrr&quot;, &quot;rWSBIM1207&quot;, &quot;readr&quot;, &quot;stats&quot;, &quot;stringr&quot;, &quot;tibble&quot;, &quot;tidyr&quot;, &quot;tidyverse&quot;, &quot;utils&quot;) if (!require(&quot;BiocManager&quot;)) install.packages(&quot;BiocManager&quot;) BiocManager::install(pkgs) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
